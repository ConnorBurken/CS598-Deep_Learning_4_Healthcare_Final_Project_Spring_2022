{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python3 Part of the Data Analysis for the Journal Article Titled:\n",
    "# <i>Natural language processing for cognitive behavioral therapy: extracting schemas from thought records</i>\n",
    "\n",
    ">This script accompanies the journal article with the title stated above. The main aim of the research is to determine whether an algorithm can label utterances expressed in thought records with regard to the schema(s) they reflect. Thought record forms are a tool in cognitive therapy with which patients should gain insight into their maladaptive thought processes. According to the theory underlying cognitive therapy, it is these malaptive thought processes that result in the respective mental illness.  \n",
    "This script complements an R/KnitR script that consists of the following sections:\n",
    "    <ol> \n",
    "    <li>Preparing data for testing Hypothesis 1</li>\n",
    "    <li>Testing Hypothesis 2</li>\n",
    "    <li>Testing Hypothesis 3</li>\n",
    "    <li>Testing Hypothesis 4</li>\n",
    "    </ol>\n",
    "Details concerning the hypotheses, the project background, the raw data, and the data collection process can all be found in the R/KnitR script.<br>\n",
    "<br>\n",
    "The modules below need to be installed before running the code:\n",
    "    <ol>\n",
    "    <li>gensim==3.8.3</li>\n",
    "    <li>talos==0.6.3</li>\n",
    "    <li>tensorflow==2.3.2</li>\n",
    "    <li>statsmodels==0.10.2</li>\n",
    "    <li>scipy==1.4.1</li>\n",
    "    <li>scikit-learn==0.23.2</li>\n",
    "    <li>numpy==1.16.3</li>\n",
    "    <li>pandas==0.25.3</li>\n",
    "    </ol>\n",
    "<br>\n",
    "The following inputs are required and can be found in the DataRepository/AnalysisArticle/Data directory:\n",
    "    <ol>\n",
    "    <li>glove.6B directory</li>\n",
    "    <li>DatasetsForH1 directory</li>\n",
    "    </ol>\n",
    "<br>\n",
    "Additionally, the following output is generated:\n",
    "    <ol>\n",
    "    <li>data_for_H2.csv file</li>\n",
    "    <li>per_schema_models directory</li>\n",
    "    </ol>\n",
    "with the latter containing all trained per-schema RNN models in .h5 file format.  \n",
    "<br>\n",
    "The purpose of this script is to test Hypothesis 1, i.e. to see whether an algorithm can attach the correct schema label to thought record utterances more often than would be expected by chance. A thought record utterance could reflect none, any one, or multiple of 9 possible schemas. Additionally, labels are not binary (does or does not reflect schema) but ordinal (0 - has nothing to do with schema, 1 - has a little bit to do with the schema, 2 - has to do with the schema, 3 - fits perfectly with the schema). <br>\n",
    "Utterances are in natural language format. It is therefore necessary to preprocess these pieces of text, which we do in R. We also split the entire raw dataset into training, validation and test sets. The test set is created by taking 15% of the raw data, the validation set is created by taking another 15% of the remaining data. <br>\n",
    "Three algorithms are explored: k-nearest neighbors, support vector machines, and recurrent neural networks. We arrived at the former two, by following the decision tree presented by scikitLearn (https://scikit-learn.org/stable/tutorial/machine_learning_map/). The data are ordinal, labeled, and we have less than 100k samples. The recurrent neural networks are a logical choice for natural language data, since they allow modelling the temporal aspect that is inherent to sentences as sequences of words.<br>\n",
    "The wall time of runtimes are provided in the first comment of cells of time intensive code. Additionally, the cell magic \"%%time\" in these cells ensures that runtimes are printed so that these can be compared to the reported runtimes to get appropriate estimates when running on a different machine.<br>\n",
    "We import the following packages and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add GPU paths\n",
    "sys.path.append(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.6/bin\")\n",
    "sys.path.append(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.6/extras/CUPTI/lib64\")\n",
    "sys.path.append(\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.6/include\")\n",
    "sys.path.append(\"C:/tools/cuda/bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed\n",
    "seed = 57839\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed)\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "import functools\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn import metrics, preprocessing, svm\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "from tensorflow.python.keras.metrics import Metric\n",
    "from tensorflow import keras\n",
    "import talos\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Flatten, Embedding, SimpleRNN, LSTM, GRU, Bidirectional,Dropout,Input\n",
    "\n",
    "from keras import backend as K\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "import joblib \n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text  # Imports TF ops for preprocessing.\n",
    "import bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow==2.8.0\n",
      "talos==1.2.3\n",
      "statsmodels==0.13.2\n",
      "scipy==1.8.0\n",
      "scikit-learn==1.0.2\n",
      "pandas==1.4.2\n",
      "numpy==1.22.3\n",
      "keras==2.8.0\n",
      "joblib==1.1.0\n",
      "gensim==4.1.2\n"
     ]
    }
   ],
   "source": [
    "#list packages and their version numbers as used in this script (code is taken from \n",
    "#https://stackoverflow.com/questions/40428931/package-for-listing-version-of-packages-used-in-a-jupyter-notebook)\n",
    "import pkg_resources\n",
    "import types\n",
    "def get_imports():\n",
    "    for name, val in globals().items():\n",
    "        if isinstance(val, types.ModuleType):\n",
    "            # Split ensures you get root package, \n",
    "            # not just imported function\n",
    "            name = val.__name__.split(\".\")[0]\n",
    "\n",
    "        elif isinstance(val, type):\n",
    "            name = val.__module__.split(\".\")[0]\n",
    "\n",
    "        # Some packages are weird and have different\n",
    "        # imported names vs. system/pip names. Unfortunately,\n",
    "        # there is no systematic way to get pip names from\n",
    "        # a package's imported name. You'll have to add\n",
    "        # exceptions to this list manually!\n",
    "        poorly_named_packages = {\n",
    "            \"sklearn\": \"scikit-learn\"\n",
    "        }\n",
    "        if name in poorly_named_packages.keys():\n",
    "            name = poorly_named_packages[name]\n",
    "\n",
    "        yield name\n",
    "imports = list(set(get_imports()))\n",
    "\n",
    "# The only way I found to get the version of the root package\n",
    "# from only the name of the package is to cross-check the names \n",
    "# of installed packages vs. imported packages\n",
    "requirements = []\n",
    "for m in pkg_resources.working_set:\n",
    "    if m.project_name in imports and m.project_name!=\"pip\":\n",
    "        requirements.append((m.project_name, m.version))\n",
    "\n",
    "for r in requirements:\n",
    "    print(\"{}=={}\".format(*r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We also set the working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for available GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\" , len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/conno/Documents/Repo2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the datasets from csv\n",
    "> The preprocessed utterances are split into three sets in the R script. They are saved in three separate csv files. Additionally, the manually assigned labels that correspond with the utterances are saved in three separate csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in datasets (already pre-processed)\n",
    "def readcsv(fname,istext):\n",
    "    if istext:\n",
    "        with open(fname,'rt') as f:\n",
    "            reader=csv.reader(f)\n",
    "            next(reader)\n",
    "            data = []\n",
    "            for row in reader:\n",
    "                for item in row:\n",
    "                    data.append(item)\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(fname,'r') as f:\n",
    "            reader=csv.reader(f,delimiter=';')\n",
    "            next(reader)\n",
    "            data = list(reader)\n",
    "            data = np.asarray(data, dtype='int')\n",
    "            f.close()\n",
    "    return data \n",
    "\n",
    "# read in training, validation, and test set utterances\n",
    "train_text = readcsv('Data/DatasetsForH1/H1_train_texts.csv',True)\n",
    "val_text = readcsv('Data/DatasetsForH1/H1_validate_texts.csv', True)\n",
    "test_text = readcsv('Data/DatasetsForH1/H1_test_texts.csv',True)\n",
    "\n",
    "# read in training, validation, and test set labels\n",
    "train_labels = readcsv('Data/DatasetsForH1/H1_train_labels.csv',False)[:,0:9]\n",
    "val_labels = readcsv('Data/DatasetsForH1/H1_validate_labels.csv', False)[:,0:9]\n",
    "test_labels = readcsv('Data/DatasetsForH1/H1_test_labels.csv',False)[:,0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lot people may think well lot people might not like me', 'might not working fast enough their standards', 'may not able graduate', 'would get bad performance review', 'friends will get annoyed by me']\n"
     ]
    }
   ],
   "source": [
    "print(train_text[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 0 0 0 0 0 3]\n",
      " [0 3 0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0]\n",
      " [2 0 0 0 0 0 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As can be seen, some utterances have multiple schemas assigned. However, overall, the label matrices are sparse matrices. The first column of the labels corresponds to the \"Attachment\" schema, the second to the \"Competence\" schema, the third to last to the \"Other's views on self\" schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for later use\n",
    "schemas = [\"Attach\",\"Comp\",\"Global\",\"Health\",\"Control\",\"MetaCog\",\"Others\",\"Hopeless\",\"OthViews\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding the utterances using BERT \n",
    ">One of the things the paper mentioned that would be interesting to try would be to use a more modern approach such as BERT to classify the data. We will use a pretrained model from TensorFlow that was trained on english wikipedia to encode and then train the model for the purpose of classifying\n",
    "\n",
    "Preprocessor: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3 <br>\n",
    "Encoder: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1 <br>\n",
    "References: https://www.tensorflow.org/text/tutorials/classify_text_with_bert <br>\n",
    "Paper: https://arxiv.org/abs/1908.08962"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: C:\\Users\\conno\\AppData\\Local\\Temp\\tfhub_modules\\602d30248ff7929470db09f7385fc895e9ceb4c0\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17480/1504558720.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpreprocessing_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    104\u001b[0m         module_path, tags=tags, options=options)\n\u001b[0;32m    105\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m   \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0ma\u001b[0m \u001b[0mMetaGraph\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mSavedModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m   \"\"\"\n\u001b[1;32m--> 936\u001b[1;33m   \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"root\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\saved_model\\load.py\u001b[0m in \u001b[0;36mload_internal\u001b[1;34m(export_dir, tags, options, loader_cls, filters)\u001b[0m\n\u001b[0;32m    947\u001b[0m     \u001b[0mtags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m   saved_model_proto, debug_info = (\n\u001b[1;32m--> 949\u001b[1;33m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[0;32m    950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m   \"\"\"\n\u001b[1;32m---> 57\u001b[1;33m   \u001b[0msaved_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m   debug_info_path = file_io.join(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    113\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Cannot parse file {path_to_pbtxt}: {str(e)}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m     raise IOError(\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;34mf\"SavedModel file does not exist at: {export_dir}{os.path.sep}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;34mf\"{{{constants.SAVED_MODEL_FILENAME_PBTXT}|\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: C:\\Users\\conno\\AppData\\Local\\Temp\\tfhub_modules\\602d30248ff7929470db09f7385fc895e9ceb4c0\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "preprocessing_layer = hub.load(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 359 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_encoder_inputs = preprocessing_layer(np.array(train_text))\n",
    "test_encoder_inputs = preprocessing_layer(np.array(test_text))\n",
    "val_encoder_inputs = preprocessing_layer(np.array(val_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/Embeddings/BERT/val_encoder_inputs.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save progress BERT encoder inputs\n",
    "joblib.dump(train_encoder_inputs, 'Data/Embeddings/BERT/train_encoder_inputs.pkl')\n",
    "joblib.dump(test_encoder_inputs, 'Data/Embeddings/BERT/test_encoder_inputs.pkl')\n",
    "joblib.dump(val_encoder_inputs, 'Data/Embeddings/BERT/val_encoder_inputs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoder_inputs = joblib.load(\"Data/Embeddings/BERT/train_encoder_inputs.pkl\")\n",
    "test_encoder_inputs = joblib.load(\"Data/Embeddings/BERT/test_encoder_inputs.pkl\")\n",
    "val_encoder_inputs = joblib.load(\"Data/Embeddings/BERT/val_encoder_inputs.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_type_ids': <tf.Tensor: shape=(4151, 128), dtype=int32, numpy=\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])>,\n",
       " 'input_mask': <tf.Tensor: shape=(4151, 128), dtype=int32, numpy=\n",
       " array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]])>,\n",
       " 'input_word_ids': <tf.Tensor: shape=(4151, 128), dtype=int32, numpy=\n",
       " array([[ 101, 2843, 2111, ...,    0,    0,    0],\n",
       "        [ 101, 2453, 2025, ...,    0,    0,    0],\n",
       "        [ 101, 2089, 2025, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 101, 2228, 3685, ...,    0,    0,    0],\n",
       "        [ 101, 2572, 2025, ...,    0,    0,    0],\n",
       "        [ 101, 2016, 2467, ...,    0,    0,    0]])>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encoder_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load BERT Encoder From TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT Embeddings Model\n",
    "encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\", trainable=True, name='BERT_encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data/Embeddings/BERT/train_outputs.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_outputs = encoder(train_encoder_inputs)\n",
    "joblib.dump(train_outputs, 'Data/Embeddings/BERT/train_outputs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data/Embeddings/BERT/test_outputs.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_outputs = encoder(test_encoder_inputs)\n",
    "joblib.dump(test_outputs, 'Data/Embeddings/BERT/test_outputs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 28.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data/Embeddings/BERT/val_outputs.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "val_outputs = encoder(val_encoder_inputs)\n",
    "joblib.dump(val_outputs, 'Data/Embeddings/BERT/val_outputs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outputs = joblib.load('Data/Embeddings/BERT/train_outputs.pkl')\n",
    "val_outputs = joblib.load('Data/Embeddings/BERT/val_outputs.pkl')\n",
    "test_outputs = joblib.load('Data/Embeddings/BERT/test_outputs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4151, 128, 512), dtype=float32, numpy=\n",
       "array([[[-0.25892833,  0.02584415,  0.9365302 , ..., -0.96089983,\n",
       "          2.0598676 ,  0.74836355],\n",
       "        [-0.30464268,  0.5291489 , -0.0649645 , ...,  0.25906444,\n",
       "          0.9800552 ,  0.8583957 ],\n",
       "        [-0.6293181 ,  0.09620693, -0.60556984, ..., -0.3956486 ,\n",
       "          0.29027948,  0.43135193],\n",
       "        ...,\n",
       "        [-0.4576985 , -0.2561149 ,  0.09631284, ...,  0.02169307,\n",
       "          1.255548  ,  1.0473273 ],\n",
       "        [-0.10746137, -0.33916706,  0.22457744, ...,  0.25563493,\n",
       "          1.5337087 ,  0.67972326],\n",
       "        [-0.17170031, -0.42424932,  0.33490247, ...,  0.05244198,\n",
       "          1.0300156 ,  0.34129512]],\n",
       "\n",
       "       [[ 0.2336044 ,  0.43632537, -0.19059956, ..., -1.0399663 ,\n",
       "          0.70788187,  0.4525274 ],\n",
       "        [-0.37154025,  0.6752021 , -0.50089115, ..., -0.88574004,\n",
       "         -0.36298618,  0.60263026],\n",
       "        [ 0.17977479,  0.6047257 , -0.3719903 , ...,  0.09685966,\n",
       "         -0.520507  ,  0.9380712 ],\n",
       "        ...,\n",
       "        [ 0.28056544, -0.24215463, -0.57758904, ..., -0.2330235 ,\n",
       "          0.89935416, -0.04847287],\n",
       "        [ 0.13884965, -0.03393   , -0.52698594, ..., -0.18716085,\n",
       "          1.0528456 ,  0.1526088 ],\n",
       "        [ 0.2065477 ,  0.20960987, -0.43820348, ..., -0.29557317,\n",
       "          0.9208271 ,  0.2925727 ]],\n",
       "\n",
       "       [[-0.57760584, -0.5851047 , -0.19767515, ..., -1.2112839 ,\n",
       "          2.5984435 ,  0.5106759 ],\n",
       "        [-0.8181053 ,  0.3758497 , -0.85311717, ..., -0.33424047,\n",
       "          0.9185714 ,  0.52564627],\n",
       "        [-0.9323092 ,  0.2816996 ,  0.01742163, ..., -0.09022019,\n",
       "          0.03070335,  0.8444379 ],\n",
       "        ...,\n",
       "        [-0.52088624, -0.6560494 ,  0.02649195, ...,  0.00435448,\n",
       "          1.9186463 ,  0.11290982],\n",
       "        [-0.16765006, -0.5173194 , -0.21298328, ..., -0.19107205,\n",
       "          2.3307595 ,  0.39292008],\n",
       "        [ 0.3705942 , -0.45982936,  0.08432382, ..., -0.92497814,\n",
       "          2.6886039 ,  0.08919296]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.47257954,  0.31704256,  0.10505888, ..., -1.7469622 ,\n",
       "          1.2963561 ,  0.56162703],\n",
       "        [-0.3239936 ,  0.38804847,  0.0764493 , ..., -0.88047934,\n",
       "          1.3697371 ,  0.63922983],\n",
       "        [-0.7822955 ,  0.07482219, -0.28631005, ..., -1.3940023 ,\n",
       "         -0.0748529 ,  1.681326  ],\n",
       "        ...,\n",
       "        [-0.50266457,  0.72857386, -0.16594464, ..., -0.54412603,\n",
       "          0.7372798 ,  0.72706145],\n",
       "        [-0.17241457,  0.10469922, -0.35353053, ..., -0.48720583,\n",
       "          1.0553241 ,  0.26383495],\n",
       "        [ 0.08969249,  0.5718878 ,  0.5486972 , ..., -0.34790313,\n",
       "          1.3907115 ,  0.02214273]],\n",
       "\n",
       "       [[ 0.06235939,  0.30723885,  0.12163874, ..., -0.83413136,\n",
       "          1.0863471 ,  0.5444114 ],\n",
       "        [ 0.10231421,  0.08162311, -0.19372329, ..., -0.10876165,\n",
       "          0.9416629 ,  0.29872787],\n",
       "        [-0.4944383 ,  1.3008369 , -0.90579027, ..., -0.26488495,\n",
       "         -0.2806387 ,  1.0214672 ],\n",
       "        ...,\n",
       "        [-0.16027144,  0.3307513 , -0.7157788 , ...,  0.04690766,\n",
       "          0.7737921 ,  0.65257335],\n",
       "        [ 0.14836982,  0.351152  , -0.6272827 , ..., -0.09222721,\n",
       "          1.3057821 ,  0.54042053],\n",
       "        [ 0.6222449 ,  0.40780967, -0.32939655, ..., -0.5311742 ,\n",
       "          1.61612   ,  0.12105668]],\n",
       "\n",
       "       [[-0.3976554 , -0.07192211,  0.76607895, ..., -1.038312  ,\n",
       "          0.3827495 ,  1.5239724 ],\n",
       "        [-1.0003794 , -0.10249747, -0.24334331, ..., -0.8752458 ,\n",
       "         -0.7191522 ,  0.73850197],\n",
       "        [-0.79149026,  0.6064627 ,  0.47657114, ..., -0.3193234 ,\n",
       "          0.4327429 ,  1.600161  ],\n",
       "        ...,\n",
       "        [-0.6095017 ,  0.06159647, -0.92621416, ..., -0.5243675 ,\n",
       "         -0.05576128,  1.5107876 ],\n",
       "        [-0.24210209, -0.11096199, -0.4594306 , ..., -0.48868412,\n",
       "          0.57623535,  1.6028541 ],\n",
       "        [-0.61919546, -0.31395042, -0.09634954, ..., -0.0572975 ,\n",
       "          0.69485986,  1.5499293 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_outputs[\"sequence_output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4151, 512), dtype=float32, numpy=\n",
       "array([[ 0.9896333 ,  0.9338632 , -0.11650713, ...,  0.12776163,\n",
       "        -0.29113525, -0.8954528 ],\n",
       "       [ 0.9701939 , -0.12391764, -0.20218222, ..., -0.08036453,\n",
       "        -0.37490538, -0.90642047],\n",
       "       [ 0.8312658 , -0.80702513, -0.29396096, ..., -0.0246753 ,\n",
       "        -0.52115893, -0.7763568 ],\n",
       "       ...,\n",
       "       [ 0.96101385,  0.80138934, -0.3839846 , ...,  0.4392669 ,\n",
       "        -0.27659366, -0.9367416 ],\n",
       "       [ 0.98007244,  0.0676232 , -0.00312316, ...,  0.04044244,\n",
       "        -0.67166525, -0.7636678 ],\n",
       "       [ 0.88983876,  0.97235435, -0.07664951, ...,  0.3174023 ,\n",
       "        -0.6655615 , -0.8582763 ]], dtype=float32)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_outputs[\"pooled_output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding the utterances using GLoVE\n",
    "> We have opted for representing the words in utterances as word vectors. We adopt the GLoVE word vector space that has been created with Wikipedia 2014. First, we tokenize the top 2000 words of the training set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2624\n"
     ]
    }
   ],
   "source": [
    "# prepare tokenizer\n",
    "max_words = 2000\n",
    "t = Tokenizer(num_words = max_words)\n",
    "t.fit_on_texts(train_text)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The tokenizer takes the words and indexes these based on frequency. For the recurrent neural net, we need padded utterances sequences. Texts_to_sequences simply represents each utterance as a vector of tokens. Padding ensures that all vectors are of the same length, by appending 0s to the end of shorter vectors. We pad to a length of 25 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[147, 28, 48, 37, 101, 147, 28, 32, 1, 8, 5], [32, 1, 155, 658, 14, 125, 568], [48, 1, 19, 448], [2, 11, 53, 449, 659], [50, 6, 11, 373, 98, 5]]\n"
     ]
    }
   ],
   "source": [
    "# integer encode all utterances\n",
    "encoded_train = t.texts_to_sequences(train_text)\n",
    "encoded_validate = t.texts_to_sequences(val_text)\n",
    "encoded_test = t.texts_to_sequences(test_text)\n",
    "\n",
    "# pad documents to a max length of 25 words\n",
    "max_length = 25\n",
    "\n",
    "padded_train = pad_sequences(encoded_train, maxlen=max_length, padding='post')\n",
    "padded_validate = pad_sequences(encoded_validate, maxlen=max_length, padding='post')\n",
    "padded_test = pad_sequences(encoded_test, maxlen=max_length, padding='post')\n",
    "\n",
    "print(encoded_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[147  28  48  37 101 147  28  32   1   8   5   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [ 32   1 155 658  14 125 568   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [ 48   1  19 448   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [  2  11  53 449 659   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]\n",
      " [ 50   6  11 373  98   5   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(padded_train[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can now load the GLoVE embeddings into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n",
      "Wall time: 6.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 10sec\n",
    "# load all embeddings into memory\n",
    "embeddings_index = dict()\n",
    "f = open('Data/glove.6B/glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We can then create an embedding matrix by taking each word of the training set and finding the corresponding word vector in the GLoVE data. We only work with 100 dimensional representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624, 100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_dims = 100\n",
    "embedding_matrix = np.zeros((vocab_size, vec_dims))\n",
    "for word, i in t.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.29214445 0.         ... 0.         0.         0.        ]\n",
      " [0.         1.29214445 0.         ... 0.         0.         0.        ]\n",
      " [0.         1.29214445 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         1.69021763 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "(4151, 2000)\n"
     ]
    }
   ],
   "source": [
    "# create tfidf weighted encoding matrix of utterances\n",
    "train_sequences = t.texts_to_matrix(train_text,mode='tfidf')\n",
    "val_sequences =  t.texts_to_matrix(val_text,mode='tfidf')\n",
    "test_sequences = t.texts_to_matrix(test_text,mode='tfidf')\n",
    "print(train_sequences[0:5])\n",
    "print(train_sequences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to normalize the word vectors\n",
    "def normalize(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    if norm == 0: \n",
    "       return v\n",
    "    return v / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create utterance embeddings as tfidf weighted average of normalized word vectors\n",
    "def seq2vec(datarow,embedmat):\n",
    "  #initialize an empty utterance vector of the same length as word2vec vectors\n",
    "  seqvec = np.zeros((100,))\n",
    "  #counter for number of words in a specific utterance\n",
    "  wordcount = 1\n",
    "  #we iterate over the 2000 possible words in a given utterance\n",
    "  wordind = 1\n",
    "  while (wordind < len(datarow)):\n",
    "    #the tf-idf weight is saved in the cells of datarow\n",
    "    tfidfweight = datarow[wordind]\n",
    "    if not tfidfweight is None:\n",
    "      wordembed = tfidfweight * embedmat[wordind,]\n",
    "      seqvec = seqvec + normalize(wordembed)\n",
    "      wordcount = wordcount + 1\n",
    "    wordind = wordind + 1\n",
    "  return seqvec/wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through the matrix and embed each utterances\n",
    "def embed_utts(sequences,embedmat):\n",
    "  vecseq = [seq2vec(seq,embedmat)for seq in sequences]\n",
    "  return vecseq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> we now have everything needed to create the utterance embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.44478099e-05  3.48539840e-04  3.35962753e-04 -3.70855457e-04\n",
      " -2.63147438e-04  1.07227074e-04 -1.66559109e-04  1.94234500e-05\n",
      "  7.42420570e-05 -1.80615841e-04  1.80387578e-05  4.92242034e-05\n",
      "  2.75006568e-04  2.34416192e-05  8.31148165e-05 -2.93833280e-04\n",
      " -7.15121389e-05  2.98592314e-04 -4.55134987e-04  4.72657153e-04\n",
      "  2.57585086e-04  1.69741478e-04  7.75960265e-05 -2.15817394e-04\n",
      " -4.34789085e-05  7.24571212e-05 -1.54585404e-04 -4.98166781e-04\n",
      "  1.93941088e-04 -1.74921206e-04  2.37557331e-05  4.85150809e-04\n",
      "  3.08554881e-05 -4.62293641e-05  1.35110613e-04  2.80284189e-04\n",
      " -3.22980711e-05  3.12968134e-04  8.27704500e-05 -2.40951546e-04\n",
      " -3.13527886e-04 -1.35440392e-04 -2.05195768e-05 -4.81099111e-04\n",
      " -2.75375333e-04 -1.27601856e-04  2.50256011e-04 -2.50631136e-04\n",
      " -1.51297680e-04 -8.33555219e-04  3.54382525e-05 -8.74190709e-05\n",
      "  1.05239327e-05  8.00132559e-04 -1.52039351e-04 -1.90058573e-03\n",
      "  9.49153013e-05 -1.17238522e-05  1.18845110e-03  3.93093667e-04\n",
      " -1.88908628e-04  9.94003983e-04 -3.57759952e-04  2.93419204e-05\n",
      "  6.71172261e-04  1.52662986e-04  5.76767087e-04  2.42848249e-04\n",
      "  9.63268891e-06 -2.31785203e-04  1.51988867e-05 -2.98388563e-04\n",
      " -3.74962639e-05 -3.26247156e-04  6.07764018e-05  6.39454626e-05\n",
      "  8.71421849e-05  6.76090198e-05 -5.16919711e-04 -2.17311368e-05\n",
      "  4.80646118e-04 -1.64901023e-04 -5.06686209e-04  1.66221153e-05\n",
      " -1.31359098e-03 -2.02032865e-04 -2.72980358e-05 -6.66373277e-05\n",
      " -3.30798167e-04 -3.81777162e-04 -2.22552903e-05 -2.22256701e-04\n",
      "  4.71648347e-05 -1.49116944e-04 -4.30563119e-04  4.04963585e-05\n",
      " -2.00736932e-04 -3.13451294e-04  2.94196617e-04  2.83769604e-04]\n",
      "Wall time: 50.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 1min 14s\n",
    "# embedd all three datasets\n",
    "train_embedutts = embed_utts(train_sequences,embedding_matrix)\n",
    "val_embedutts = embed_utts(val_sequences,embedding_matrix)\n",
    "test_embedutts = embed_utts(test_sequences,embedding_matrix)\n",
    "print(train_embedutts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/Embeddings/GLoVE/test_embedutts.pkl']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save embeddings for quick loading later\n",
    "joblib.dump(train_embedutts, 'Data/Embeddings/GLoVE/train_embedutts.pkl')\n",
    "joblib.dump(val_embedutts, 'Data/Embeddings/GLoVE/val_embedutts.pkl')\n",
    "joblib.dump(test_embedutts, 'Data/Embeddings/GLoVE/test_embedutts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load them back in\n",
    "train_embedutts = joblib.load('Data/Embeddings/GLoVE/train_embedutts.pkl')\n",
    "val_embedutts = joblib.load('Data/Embeddings/GLoVE/val_embedutts.pkl')\n",
    "test_embedutts = joblib.load('Data/Embeddings/GLoVE/test_embedutts.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "> We use the Spearman correlation to evaluate the models and choose the best one, because it can be used for both the regression and the classification outcomes. This is not the case for a weighted Cohen's Kappa, for example, which only works for class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Goodness of Fit\n",
    "def gof_spear(X,Y):\n",
    "    #spearman correlation of columns (schemas)\n",
    "    gof_spear = np.zeros(X.shape[1])    \n",
    "    for schema in range(9):\n",
    "        rho,p = scipy.stats.spearmanr(X[:,schema],Y[:,schema])\n",
    "        gof_spear[schema]=rho\n",
    "    return gof_spear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping for confidence intervals\n",
    "> Since all models are expensive to run, we only do a small bootstrapping to obtain some insight into how confident we can be about the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we adopt the algorithm from the following website:\n",
    "# https://machinelearningmastery.com/calculate-bootstrap-confidence-intervals-machine-learning-results-python/\n",
    "# def bootstrap\n",
    "def bootstrap(train_X, train_y, iterations, sample_size, sample_embeds, sample_labels, classification, model, embedding=\"GLoVE\"):\n",
    "    stats = np.zeros((iterations,9))\n",
    "    for l in range(iterations):\n",
    "        # prepare bootstrap sample\n",
    "        bootstrap_sample_indx = random.sample(list(enumerate(sample_embeds)), sample_size)\n",
    "        bootstrap_sample_utts = [sample_embeds[i] for (i,j) in bootstrap_sample_indx]\n",
    "        bootstrap_sample_labels = [sample_labels[i] for (i,j) in bootstrap_sample_indx]\n",
    "        # evaluate model\n",
    "        if model==\"knn\":\n",
    "            model_gof=my_kNN(train_X, train_y, np.array(bootstrap_sample_utts),np.array(bootstrap_sample_labels),classification)\n",
    "        elif model==\"svm\":\n",
    "            model_gof=my_svm(train_y, np.array(bootstrap_sample_utts),np.array(bootstrap_sample_labels),classification, embedding)\n",
    "        elif model==\"rnn\":\n",
    "            model_gof=my_rnn_fixed(train_X, train_y, np.array(bootstrap_sample_utts),np.array(bootstrap_sample_labels),classification)\n",
    "        stats[l,:] = model_gof\n",
    "    # confidence intervals\n",
    "    cis = np.zeros((2,9))\n",
    "    alpha = 0.95\n",
    "    p = ((1.0-alpha)/2.0) * 100\n",
    "    cis[0,:] = [max(0.0, np.percentile(stats[:,i], p)) for i in range(9)]\n",
    "    p = (alpha+((1.0-alpha)/2.0)) * 100\n",
    "    cis[1,:] = [min(1.0, np.percentile(stats[:,i], p)) for i in range(9)]\n",
    "    return cis\n",
    "\n",
    "# configure bootstrap\n",
    "n_iterations = 100\n",
    "n_size = int(len(val_text) * 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-nearest Neighbors Classification and Regression\n",
    "> Since we have ordinal labels for our data, we train both classification and regression algorithms and see which one performs better. We also have multi-label data, and therefore write a custom kNN algorithm. We use the cosine distance to find the nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine distance\n",
    "def cosine_dist(X,Y):\n",
    "    return scipy.spatial.distance.cosine(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kNN algorithm\n",
    "def knn_custom(train_X,test_X,train_y,test_y,k,dist,classification):\n",
    "    #empty array to collect the results (should have shape of samples to classify)\n",
    "    votes = np.zeros(test_y.shape)\n",
    "    #fit the knn\n",
    "    knn=NearestNeighbors(n_neighbors=k, metric=dist)\n",
    "    knn.fit(train_X)\n",
    "    #collect neighbors\n",
    "    i=0 # index to collect votes of the neighbors\n",
    "    for sample in test_X:\n",
    "        neighbors=knn.kneighbors([sample],k,return_distance=False)[0]\n",
    "        if classification:\n",
    "            output_y = np.zeros((k,test_y.shape[1]))\n",
    "            j=0\n",
    "            for neighbor in neighbors:\n",
    "                output_y[j,:] = train_y[neighbor,:]\n",
    "                j=j+1\n",
    "            votes[i,:] = stats.mode(output_y,nan_policy='omit')[0]\n",
    "        else:\n",
    "            output_y = np.zeros(test_y.shape[1])\n",
    "            for neighbor in neighbors:\n",
    "                output_y += train_y[neighbor,:]\n",
    "                votes[i,:] = np.divide(output_y,k)\n",
    "        i=i+1\n",
    "    return votes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To evaluate choices for k, we use a performance metric that is a weighted mean of the spearman correlation for each choice of k. As weights we use the frequencies of schemas (# of utterances with labels > 0 for a given schema/total number of utterances) in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighting model output (spearman correlations) by schema frequencies in training set and returning mean over schemas\n",
    "def performance(train_y,output):\n",
    "    train_y = np.array(train_y)\n",
    "    train_y[train_y>0]=1\n",
    "    weighting = train_y.sum(axis=0)/train_y.shape[0]\n",
    "    perf = output * weighting\n",
    "    return np.nanmean(np.array(perf), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding best k by testing some values for k\n",
    "def find_k(train_X, test_X, train_y, test_y, dist, classification):\n",
    "    perf = 0\n",
    "    best_k = 0\n",
    "    for k in [2,3,4,5,6,7,8,9,10,30,100]:\n",
    "        knn_k = knn_custom(train_X, test_X, train_y, test_y,k,dist,classification)\n",
    "        knn_gof_spear = gof_spear(knn_k,test_y)\n",
    "        print('Results for choice of k is %s.' % k)\n",
    "        print(pd.DataFrame(data=knn_gof_spear,index=schemas,columns=['gof']))\n",
    "        if perf < performance(train_y,knn_gof_spear):\n",
    "            perf = performance(train_y,knn_gof_spear)\n",
    "            best_k = k\n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 15min\n",
    "# find best k for classification\n",
    "knn_class_k_glove = find_k(train_embedutts,val_embedutts,train_labels,val_labels,cosine_dist,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best choice for classification k is with GLoVE: 100\n"
     ]
    }
   ],
   "source": [
    "print('Best choice for classification k is with GLoVE: %s' % knn_class_k_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for choice of k is 2.\n",
      "               gof\n",
      "Attach    0.520207\n",
      "Comp      0.538653\n",
      "Global    0.440397\n",
      "Health    0.517527\n",
      "Control   0.067278\n",
      "MetaCog  -0.008059\n",
      "Others   -0.008982\n",
      "Hopeless  0.501311\n",
      "OthViews  0.498057\n",
      "Results for choice of k is 3.\n",
      "               gof\n",
      "Attach    0.532753\n",
      "Comp      0.513828\n",
      "Global    0.496175\n",
      "Health    0.523938\n",
      "Control   0.136950\n",
      "MetaCog  -0.005695\n",
      "Others         NaN\n",
      "Hopeless  0.496209\n",
      "OthViews  0.508845\n",
      "Results for choice of k is 4.\n",
      "               gof\n",
      "Attach    0.546332\n",
      "Comp      0.579449\n",
      "Global    0.508682\n",
      "Health    0.517595\n",
      "Control   0.125264\n",
      "MetaCog        NaN\n",
      "Others   -0.006347\n",
      "Hopeless  0.560365\n",
      "OthViews  0.500715\n",
      "Results for choice of k is 5.\n",
      "               gof\n",
      "Attach    0.495804\n",
      "Comp      0.553438\n",
      "Global    0.507869\n",
      "Health    0.517595\n",
      "Control   0.140895\n",
      "MetaCog        NaN\n",
      "Others         NaN\n",
      "Hopeless  0.511332\n",
      "OthViews  0.464652\n",
      "Results for choice of k is 6.\n",
      "               gof\n",
      "Attach    0.510742\n",
      "Comp      0.570426\n",
      "Global    0.502463\n",
      "Health    0.517327\n",
      "Control   0.120023\n",
      "MetaCog        NaN\n",
      "Others         NaN\n",
      "Hopeless  0.536225\n",
      "OthViews  0.504049\n",
      "Results for choice of k is 7.\n",
      "               gof\n",
      "Attach    0.538541\n",
      "Comp      0.567346\n",
      "Global    0.512484\n",
      "Health    0.514969\n",
      "Control   0.168028\n",
      "MetaCog        NaN\n",
      "Others         NaN\n",
      "Hopeless  0.519645\n",
      "OthViews  0.498908\n",
      "Results for choice of k is 8.\n",
      "               gof\n",
      "Attach    0.547437\n",
      "Comp      0.576020\n",
      "Global    0.503509\n",
      "Health    0.490157\n",
      "Control   0.079205\n",
      "MetaCog        NaN\n",
      "Others         NaN\n",
      "Hopeless  0.499929\n",
      "OthViews  0.482497\n",
      "Results for choice of k is 9.\n",
      "               gof\n",
      "Attach    0.534062\n",
      "Comp      0.574867\n",
      "Global    0.518599\n",
      "Health    0.436559\n",
      "Control   0.079205\n",
      "MetaCog        NaN\n",
      "Others         NaN\n",
      "Hopeless  0.474224\n",
      "OthViews  0.493598\n",
      "Results for choice of k is 10.\n",
      "               gof\n",
      "Attach    0.528338\n",
      "Comp      0.577167\n",
      "Global    0.488448\n",
      "Health    0.349332\n",
      "Control   0.055930\n",
      "MetaCog        NaN\n",
      "Others         NaN\n",
      "Hopeless  0.462044\n",
      "OthViews  0.480170\n",
      "Results for choice of k is 30.\n",
      "               gof\n",
      "Attach    0.426950\n",
      "Comp      0.575444\n",
      "Global    0.372861\n",
      "Health    0.312238\n",
      "Control        NaN\n",
      "MetaCog        NaN\n",
      "Others         NaN\n",
      "Hopeless  0.475320\n",
      "OthViews  0.414775\n",
      "Results for choice of k is 100.\n",
      "               gof\n",
      "Attach    0.321649\n",
      "Comp      0.440494\n",
      "Global    0.286112\n",
      "Health         NaN\n",
      "Control        NaN\n",
      "MetaCog        NaN\n",
      "Others         NaN\n",
      "Hopeless  0.296757\n",
      "OthViews  0.321112\n"
     ]
    }
   ],
   "source": [
    "knn_class_k_bert = find_k(train_outputs[\"pooled_output\"],val_outputs[\"pooled_output\"],train_labels,val_labels,cosine_dist,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best choice for classification k is with BERT Embeddings: 7\n"
     ]
    }
   ],
   "source": [
    "print('Best choice for classification k is with BERT Embeddings: %s' % knn_class_k_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for choice of k is 2.\n",
      "               gof\n",
      "Attach    0.301481\n",
      "Comp      0.172417\n",
      "Global    0.421375\n",
      "Health    0.275585\n",
      "Control        NaN\n",
      "MetaCog        NaN\n",
      "Others    0.039193\n",
      "Hopeless  0.324713\n",
      "OthViews  0.245623\n",
      "Results for choice of k is 3.\n",
      "               gof\n",
      "Attach    0.309176\n",
      "Comp      0.181459\n",
      "Global    0.409544\n",
      "Health    0.275585\n",
      "Control   0.107267\n",
      "MetaCog        NaN\n",
      "Others    0.028961\n",
      "Hopeless  0.324815\n",
      "OthViews  0.257459\n",
      "Results for choice of k is 4.\n",
      "               gof\n",
      "Attach    0.543883\n",
      "Comp      0.643099\n",
      "Global    0.526240\n",
      "Health    0.550825\n",
      "Control   0.236496\n",
      "MetaCog  -0.023015\n",
      "Others    0.022758\n",
      "Hopeless  0.524707\n",
      "OthViews  0.447674\n",
      "Results for choice of k is 5.\n",
      "               gof\n",
      "Attach    0.579190\n",
      "Comp      0.652242\n",
      "Global    0.485816\n",
      "Health    0.583227\n",
      "Control   0.222230\n",
      "MetaCog  -0.031264\n",
      "Others    0.065061\n",
      "Hopeless  0.527806\n",
      "OthViews  0.466995\n",
      "Results for choice of k is 6.\n",
      "               gof\n",
      "Attach    0.591500\n",
      "Comp      0.643973\n",
      "Global    0.480999\n",
      "Health    0.556015\n",
      "Control   0.217936\n",
      "MetaCog   0.032108\n",
      "Others    0.149970\n",
      "Hopeless  0.495656\n",
      "OthViews  0.470939\n",
      "Results for choice of k is 7.\n",
      "               gof\n",
      "Attach    0.590784\n",
      "Comp      0.649580\n",
      "Global    0.482929\n",
      "Health    0.539585\n",
      "Control   0.243550\n",
      "MetaCog   0.040388\n",
      "Others    0.159336\n",
      "Hopeless  0.479787\n",
      "OthViews  0.469014\n",
      "Results for choice of k is 8.\n",
      "               gof\n",
      "Attach    0.611932\n",
      "Comp      0.664233\n",
      "Global    0.483222\n",
      "Health    0.522339\n",
      "Control   0.251943\n",
      "MetaCog   0.085472\n",
      "Others    0.180319\n",
      "Hopeless  0.483483\n",
      "OthViews  0.460556\n",
      "Results for choice of k is 9.\n",
      "               gof\n",
      "Attach    0.615808\n",
      "Comp      0.661483\n",
      "Global    0.479707\n",
      "Health    0.485750\n",
      "Control   0.243638\n",
      "MetaCog   0.099125\n",
      "Others    0.210331\n",
      "Hopeless  0.481095\n",
      "OthViews  0.457985\n",
      "Results for choice of k is 10.\n",
      "               gof\n",
      "Attach    0.610929\n",
      "Comp      0.649782\n",
      "Global    0.486649\n",
      "Health    0.473782\n",
      "Control   0.257238\n",
      "MetaCog   0.087772\n",
      "Others    0.241299\n",
      "Hopeless  0.477677\n",
      "OthViews  0.457838\n",
      "Results for choice of k is 30.\n",
      "               gof\n",
      "Attach    0.607006\n",
      "Comp      0.631050\n",
      "Global    0.491660\n",
      "Health    0.376698\n",
      "Control   0.278285\n",
      "MetaCog   0.080908\n",
      "Others    0.164400\n",
      "Hopeless  0.448814\n",
      "OthViews  0.469782\n",
      "Results for choice of k is 100.\n",
      "               gof\n",
      "Attach    0.587205\n",
      "Comp      0.595194\n",
      "Global    0.468271\n",
      "Health    0.352908\n",
      "Control   0.261337\n",
      "MetaCog   0.058065\n",
      "Others    0.152719\n",
      "Hopeless  0.435439\n",
      "OthViews  0.473454\n",
      "Wall time: 9min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 15min\n",
    "# find best k for regression\n",
    "knn_reg_k_glove = find_k(train_embedutts,val_embedutts,train_labels,val_labels,cosine_dist,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best choice for regression k for GLoVE is: 8\n"
     ]
    }
   ],
   "source": [
    "print('Best choice for regression k for GLoVE is: %s' % knn_reg_k_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for choice of k is 2.\n",
      "               gof\n",
      "Attach    0.560861\n",
      "Comp      0.550576\n",
      "Global    0.423506\n",
      "Health    0.424523\n",
      "Control   0.192486\n",
      "MetaCog   0.068470\n",
      "Others    0.077364\n",
      "Hopeless  0.450919\n",
      "OthViews  0.512912\n",
      "Results for choice of k is 3.\n",
      "               gof\n",
      "Attach    0.576818\n",
      "Comp      0.545873\n",
      "Global    0.454746\n",
      "Health    0.401647\n",
      "Control   0.205284\n",
      "MetaCog   0.087813\n",
      "Others    0.087105\n",
      "Hopeless  0.441195\n",
      "OthViews  0.498680\n",
      "Results for choice of k is 4.\n",
      "               gof\n",
      "Attach    0.576737\n",
      "Comp      0.558685\n",
      "Global    0.442498\n",
      "Health    0.380061\n",
      "Control   0.236177\n",
      "MetaCog   0.111981\n",
      "Others    0.066656\n",
      "Hopeless  0.454449\n",
      "OthViews  0.497457\n",
      "Results for choice of k is 5.\n",
      "               gof\n",
      "Attach    0.577037\n",
      "Comp      0.552242\n",
      "Global    0.439031\n",
      "Health    0.365531\n",
      "Control   0.235795\n",
      "MetaCog   0.099507\n",
      "Others    0.134306\n",
      "Hopeless  0.444075\n",
      "OthViews  0.503337\n",
      "Results for choice of k is 6.\n",
      "               gof\n",
      "Attach    0.566563\n",
      "Comp      0.560409\n",
      "Global    0.430962\n",
      "Health    0.378660\n",
      "Control   0.264871\n",
      "MetaCog   0.081120\n",
      "Others    0.111456\n",
      "Hopeless  0.452308\n",
      "OthViews  0.494593\n",
      "Results for choice of k is 7.\n",
      "               gof\n",
      "Attach    0.567856\n",
      "Comp      0.556150\n",
      "Global    0.418714\n",
      "Health    0.379760\n",
      "Control   0.262702\n",
      "MetaCog   0.097191\n",
      "Others    0.125551\n",
      "Hopeless  0.432771\n",
      "OthViews  0.501724\n",
      "Results for choice of k is 8.\n",
      "               gof\n",
      "Attach    0.568906\n",
      "Comp      0.557939\n",
      "Global    0.411698\n",
      "Health    0.364488\n",
      "Control   0.262603\n",
      "MetaCog   0.087334\n",
      "Others    0.115486\n",
      "Hopeless  0.428493\n",
      "OthViews  0.495844\n",
      "Results for choice of k is 9.\n",
      "               gof\n",
      "Attach    0.575999\n",
      "Comp      0.562099\n",
      "Global    0.415692\n",
      "Health    0.349501\n",
      "Control   0.248350\n",
      "MetaCog   0.072614\n",
      "Others    0.121775\n",
      "Hopeless  0.438088\n",
      "OthViews  0.494260\n",
      "Results for choice of k is 10.\n",
      "               gof\n",
      "Attach    0.574972\n",
      "Comp      0.560005\n",
      "Global    0.424012\n",
      "Health    0.339937\n",
      "Control   0.249755\n",
      "MetaCog   0.069825\n",
      "Others    0.135052\n",
      "Hopeless  0.431647\n",
      "OthViews  0.480577\n",
      "Results for choice of k is 30.\n",
      "               gof\n",
      "Attach    0.570911\n",
      "Comp      0.576451\n",
      "Global    0.419963\n",
      "Health    0.291966\n",
      "Control   0.242082\n",
      "MetaCog   0.072130\n",
      "Others    0.131256\n",
      "Hopeless  0.445368\n",
      "OthViews  0.497242\n",
      "Results for choice of k is 100.\n",
      "               gof\n",
      "Attach    0.545782\n",
      "Comp      0.561509\n",
      "Global    0.409500\n",
      "Health    0.266404\n",
      "Control   0.246845\n",
      "MetaCog   0.112306\n",
      "Others    0.135313\n",
      "Hopeless  0.431461\n",
      "OthViews  0.490563\n",
      "Wall time: 14min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 15min\n",
    "# find best k for regression\n",
    "knn_reg_bert_k = find_k(train_outputs[\"pooled_output\"],val_outputs[\"pooled_output\"],train_labels,val_labels,cosine_dist,0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best choice for regression k for BERT is: 4\n"
     ]
    }
   ],
   "source": [
    "print('Best choice for regression k for BERT is: %s' % knn_reg_bert_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Since this is needed for the bootstrapping algorithm, we define a function that takes testset and labels and returns the goodness of fit. We print the results on the testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_kNN(train_X, train_y, test_X,test_y,classification):\n",
    "    if classification:\n",
    "        my_knn=knn_custom(train_X,test_X,train_y,test_y,4,cosine_dist,1)\n",
    "    else:\n",
    "        my_knn=knn_custom(train_X,test_X,train_y,test_y,5,cosine_dist,0)\n",
    "    return gof_spear(my_knn,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#wall time to run: ~ 2.5 min\n",
    "output_kNN_class_glove = my_kNN(train_embedutts, train_labels, test_embedutts,test_labels,1)\n",
    "output_kNN_reg_glove = my_kNN(train_embedutts, train_labels, test_embedutts,test_labels,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/KNN/output_kNN_reg_glove.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Models\n",
    "joblib.dump(output_kNN_class_glove, 'Data/KNN/output_kNN_class_glove.pkl')\n",
    "joblib.dump(output_kNN_reg_glove, 'Data/KNN/output_kNN_reg_glove.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#wall time to run: ~ 4min\n",
    "output_kNN_class_bert = my_kNN(train_outputs[\"pooled_output\"], train_labels, test_outputs[\"pooled_output\"],test_labels,1)\n",
    "output_kNN_reg_bert = my_kNN(train_outputs[\"pooled_output\"], train_labels, test_outputs[\"pooled_output\"],test_labels,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/KNN/output_kNN_reg_bert.pkl']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save models\n",
    "joblib.dump(output_kNN_class_bert, 'Data/KNN/output_kNN_class_bert.pkl')\n",
    "joblib.dump(output_kNN_reg_bert, 'Data/KNN/output_kNN_reg_bert.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back in saved models\n",
    "output_kNN_class_glove = joblib.load('Data/KNN/output_kNN_class_glove.pkl')\n",
    "output_kNN_reg_glove = joblib.load('Data/KNN/output_kNN_reg_glove.pkl')\n",
    "output_kNN_class_bert = joblib.load('Data/KNN/output_kNN_class_bert.pkl')\n",
    "output_kNN_reg_bert = joblib.load('Data/KNN/output_kNN_reg_bert.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Prediction GLoVE\n",
      "          estimate\n",
      "Attach    0.130606\n",
      "Comp      0.135201\n",
      "Global    0.204418\n",
      "Health    0.249344\n",
      "Control  -0.011459\n",
      "MetaCog        NaN\n",
      "Others         NaN\n",
      "Hopeless  0.167857\n",
      "OthViews  0.157289\n"
     ]
    }
   ],
   "source": [
    "print('KNN Classification Prediction GLoVE')\n",
    "print(pd.DataFrame(data=output_kNN_class_glove,index=schemas,columns=['estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Prediction BERT\n",
      "          estimate\n",
      "Attach    0.531913\n",
      "Comp      0.587256\n",
      "Global    0.375899\n",
      "Health    0.500031\n",
      "Control   0.102623\n",
      "MetaCog        NaN\n",
      "Others    0.183972\n",
      "Hopeless  0.491567\n",
      "OthViews  0.401721\n"
     ]
    }
   ],
   "source": [
    "print('KNN Classification Prediction BERT')\n",
    "print(pd.DataFrame(data=output_kNN_class_bert,index=schemas,columns=['estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regression Prediction GloVE\n",
      "          estimate\n",
      "Attach    0.606499\n",
      "Comp      0.701906\n",
      "Global    0.417896\n",
      "Health    0.656053\n",
      "Control   0.216933\n",
      "MetaCog   0.019173\n",
      "Others    0.237087\n",
      "Hopeless  0.534698\n",
      "OthViews  0.461305\n"
     ]
    }
   ],
   "source": [
    "print('KNN Regression Prediction GloVE')\n",
    "print(pd.DataFrame(data=output_kNN_reg_glove,index=schemas,columns=['estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regression Prediction BERT\n",
      "          estimate\n",
      "Attach    0.527163\n",
      "Comp      0.604087\n",
      "Global    0.399843\n",
      "Health    0.406143\n",
      "Control   0.198838\n",
      "MetaCog   0.042465\n",
      "Others    0.142093\n",
      "Hopeless  0.459757\n",
      "OthViews  0.437244\n"
     ]
    }
   ],
   "source": [
    "print('KNN Regression Prediction BERT')\n",
    "print(pd.DataFrame(data=output_kNN_reg_bert,index=schemas,columns=['estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 7min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 3h 30min\n",
    "# bootstrap confidence intervals for kNN regression and classification\n",
    "bs_knn_reg_glove = bootstrap(train_embedutts, train_labels, n_iterations,n_size,test_embedutts,test_labels,0,\"knn\")\n",
    "bs_knn_class_glove = bootstrap(train_embedutts, train_labels, n_iterations,n_size,test_embedutts,test_labels,1,\"knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification 95% Confidence Intervals with GLoVE\n",
      "               low      high\n",
      "Attach    0.086165  0.165345\n",
      "Comp      0.089736  0.169913\n",
      "Global    0.119456  0.247420\n",
      "Health    0.000000  1.000000\n",
      "Control   0.000000  1.000000\n",
      "MetaCog   0.000000  1.000000\n",
      "Others    0.000000  1.000000\n",
      "Hopeless  0.000000  1.000000\n",
      "OthViews  0.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "print(f'KNN Classification 95% Confidence Intervals with GLoVE')\n",
    "print(pd.DataFrame(data=np.transpose(bs_knn_class_glove),index=schemas,columns=['low','high']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regression 95% Confidence Intervals with GloVE\n",
      "               low      high\n",
      "Attach    0.556876  0.641433\n",
      "Comp      0.666403  0.742867\n",
      "Global    0.356754  0.471224\n",
      "Health    0.587198  0.722349\n",
      "Control   0.151941  0.271973\n",
      "MetaCog   0.000000  0.065638\n",
      "Others    0.131293  0.319599\n",
      "Hopeless  0.487370  0.580630\n",
      "OthViews  0.419942  0.506835\n"
     ]
    }
   ],
   "source": [
    "print(f'KNN Regression 95% Confidence Intervals with GloVE')\n",
    "print(pd.DataFrame(data=np.transpose(bs_knn_reg_glove),index=schemas,columns=['low','high']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3h 19min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 3h 30min\n",
    "# bootstrap confidence intervals for kNN regression and classification\n",
    "bs_knn_reg_bert = bootstrap(train_outputs[\"pooled_output\"], train_labels, n_iterations,n_size,test_outputs[\"pooled_output\"],test_labels,0,\"knn\", \"BERT\")\n",
    "bs_knn_class_bert = bootstrap(train_outputs[\"pooled_output\"], train_labels, n_iterations,n_size,test_outputs[\"pooled_output\"],test_labels,1,\"knn\", \"BERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert KNN Classification 95% Confidence Intervals\n",
      "               low      high\n",
      "Attach    0.488830  0.581333\n",
      "Comp      0.537804  0.629931\n",
      "Global    0.320721  0.432018\n",
      "Health    0.395903  0.594334\n",
      "Control   0.038999  0.175488\n",
      "MetaCog   0.000000  1.000000\n",
      "Others    0.000000  1.000000\n",
      "Hopeless  0.436791  0.553120\n",
      "OthViews  0.343502  0.449071\n"
     ]
    }
   ],
   "source": [
    "print(f'Bert KNN Classification 95% Confidence Intervals')\n",
    "print(pd.DataFrame(data=np.transpose(bs_knn_class_bert),index=schemas,columns=['low','high']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bert KNN Regression 95% Confidence Intervals\n",
      "               low      high\n",
      "Attach    0.481005  0.557272\n",
      "Comp      0.567890  0.629916\n",
      "Global    0.350038  0.460044\n",
      "Health    0.335964  0.468665\n",
      "Control   0.147965  0.260360\n",
      "MetaCog   0.000000  0.106342\n",
      "Others    0.056678  0.220705\n",
      "Hopeless  0.415600  0.498845\n",
      "OthViews  0.380510  0.476266\n"
     ]
    }
   ],
   "source": [
    "print(f'Bert KNN Regression 95% Confidence Intervals')\n",
    "print(pd.DataFrame(data=np.transpose(bs_knn_reg_bert),index=schemas,columns=['low','high']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/BootstrapResults/KNN/bs_knn_class_bert.pkl']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Results for quick loading later if project stops\n",
    "joblib.dump(bs_knn_reg_glove, 'Data/BootstrapResults/KNN/bs_knn_reg_glove.pkl')\n",
    "joblib.dump(bs_knn_class_glove, 'Data/BootstrapResults/KNN/bs_knn_class_glove.pkl')\n",
    "joblib.dump(bs_knn_reg_bert, 'Data/BootstrapResults/KNN/bs_knn_reg_bert.pkl')\n",
    "joblib.dump(bs_knn_class_bert, 'Data/BootstrapResults/KNN/bs_knn_class_bert.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_knn_reg_glove = joblib.load('Data/BootstrapResults/KNN/bs_knn_reg_glove.pkl')\n",
    "bs_knn_class_glove = joblib.load('Data/BootstrapResults/KNN/bs_knn_class_glove.pkl')\n",
    "bs_knn_reg_bert = joblib.load('Data/BootstrapResults/KNN/bs_knn_reg_bert.pkl')\n",
    "bs_knn_class_bert = joblib.load('Data/BootstrapResults/KNN/bs_knn_class_bert.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine\n",
    "> The second algorithm we chose are support vector machines (SVMs). Again, we train both a support vector classification (SVC) and a support vectore regression (SVR). We only try all three types of standard kernels and do not do any additional parameter tuning. Just like the kNN, the support vector machine takes as input the utterances encoded as averages of word vectors. Support vector classification and regression do not allow for multilabel output. We therefore train disjoint models, one for each schema.<br>\n",
    "For both types of SVM, we first transform the input texts as the algorithm expects normally distributed input centered around 0 and with a standard deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM/SVR\n",
    "def svm_scaler(train_X):\n",
    "        #scale the data\n",
    "        scaler_texts = StandardScaler()\n",
    "        scaler_texts = scaler_texts.fit(train_X)\n",
    "        return scaler_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_texts_glove = svm_scaler(train_embedutts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_texts_bert = svm_scaler(train_outputs[\"pooled_output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Since SVMs, unlike kNNs, can be trained and reused, we write a method that returns all 9 models and a separate one for the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_custom(train_X,train_y,text_scaler,kern,classification):\n",
    "        models=[]\n",
    "        train_X = text_scaler.transform(train_X)\n",
    "        #fit a new support vector regression for each schema\n",
    "        for schema in range(9):\n",
    "            if classification:\n",
    "                model = svm.SVC(kernel=kern)\n",
    "            else:\n",
    "                model = svm.SVR(kernel=kern)\n",
    "            model.fit(train_X, train_y[:,schema])\n",
    "            models.append(model)\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_predict(svm_models,test_X,train_y,test_y,text_scaler):\n",
    "    #empty array to collect the results (should have shape of samples to classify)\n",
    "    votes = np.zeros(test_y.shape)\n",
    "    for schema in range(9):\n",
    "        svm_model=svm_models[schema]\n",
    "        prediction = svm_model.predict(text_scaler.transform(test_X))\n",
    "        votes[:,schema] = prediction\n",
    "    out = votes\n",
    "    gof = gof_spear(out,test_y)\n",
    "    perf = performance(train_y,gof)\n",
    "    return out,perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_models(train_X,train_Y,val_X, val_Y, scaler_texts, sv, classification):\n",
    "    svm_rbf_models =  svm_custom(train_X,train_Y,scaler_texts,'rbf',classification)\n",
    "    svm_rbf_out, svm_rbf_perf = svm_predict(svm_rbf_models,val_X,train_Y,val_Y,scaler_texts)\n",
    "    svm_lin_models = svm_custom(train_X,train_Y,scaler_texts,'linear',classification)\n",
    "    svm_lin_out, svm_lin_perf = svm_predict(svm_lin_models,val_X,train_Y,val_Y,scaler_texts)\n",
    "    svm_poly_models = svm_custom(train_X,train_Y,scaler_texts,'poly',classification)\n",
    "    svm_poly_out, svm_poly_perf = svm_predict(svm_poly_models,val_X,train_Y,val_Y,scaler_texts)\n",
    "    print(pd.DataFrame(data=[svm_rbf_perf,svm_lin_perf,svm_poly_perf],index=['rbf','lin','poly'],columns=[sv]))\n",
    "    models = {'rbf': svm_rbf_models, 'lin': svm_lin_models, 'poly': svm_poly_models}\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLoVE SVM Results: \n",
      "Wall time: 3.61 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data/SVM/glove_svm_model.pkl']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 45sec\n",
    "# svm\n",
    "print('GLoVE SVM Results: ')\n",
    "glove_svm = svm_models(train_embedutts,train_labels,val_embedutts, val_labels, scaler_texts_glove, 'svm', 1)\n",
    "# Save Results for quick loading later if project stops\n",
    "joblib.dump(glove_svm, 'Data/SVM/glove_svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT SVM Results: \n",
      "Wall time: 9.09 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data/SVM/bert_svm_model.pkl']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 1 min\n",
    "# svm\n",
    "print('BERT SVM Results: ')\n",
    "bert_svm = svm_models(train_outputs[\"pooled_output\"],train_labels,val_outputs[\"pooled_output\"], val_labels, scaler_texts_bert, 'svm', 1)\n",
    "joblib.dump(bert_svm, 'Data/SVM/bert_svm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLoVE SVR Results: \n",
      "           svr\n",
      "rbf   0.076675\n",
      "lin   0.064361\n",
      "poly  0.066954\n",
      "Wall time: 58.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data/SVM/glove_svr_model.pkl']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 1 min\n",
    "print('GLoVE SVR Results: ')\n",
    "glove_svr = svm_models(train_embedutts,train_labels,val_embedutts, val_labels, scaler_texts_glove, 'svr', 0)\n",
    "joblib.dump(glove_svr, 'Data/SVM/glove_svr_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT SVR Results: \n",
      "Wall time: 8.53 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Data/SVM/bert_svr_model.pkl']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 45sec\n",
    "# svm\n",
    "print('BERT SVR Results: ')\n",
    "bert_svr = svm_models(train_outputs[\"pooled_output\"],train_labels,val_outputs[\"pooled_output\"], val_labels, scaler_texts_bert, 'svr', 0)\n",
    "joblib.dump(bert_svr, 'Data/SVM/bert_svr_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results for quick loading later if project stops\n",
    "glove_svm = joblib.load('Data/SVM/glove_svm_model.pkl')\n",
    "bert_svm = joblib.load('Data/SVM/bert_svm_model.pkl')\n",
    "glove_svr = joblib.load('Data/SVM/glove_svr_model.pkl')\n",
    "bert_svr = joblib.load('Data/SVM/bert_svr_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In both algorithms, the radial basis function (rbf) kernel outperformed linear and polynomial kernels. We therefore opt for the rbf kernel when predicting the labels of the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~10sec\n",
    "\n",
    "def my_svm(train_y, test_X, test_y,classification, embedding):\n",
    "    if embedding == 'GLoVE':\n",
    "        svm_rbf_models = glove_svm['rbf']\n",
    "        svr_rbf_models = glove_svr['rbf']\n",
    "        scaler_texts = scaler_texts_glove\n",
    "    elif embedding == 'BERT':\n",
    "        svm_rbf_models = bert_svm['rbf']\n",
    "        svr_rbf_models = bert_svr['rbf']\n",
    "        scaler_texts = scaler_texts_bert\n",
    "        \n",
    "    if classification:\n",
    "        my_svm_out, my_svm_perf=svm_predict(svm_rbf_models,test_X,train_y,test_y,scaler_texts)\n",
    "    else:\n",
    "        my_svm_out, my_svm_perf=svm_predict(svr_rbf_models,test_X,train_y,test_y,scaler_texts)\n",
    "    return gof_spear(my_svm_out,test_y)\n",
    "\n",
    "output_SVC_glove = my_svm(train_labels, test_embedutts,test_labels,1, 'GLoVE')\n",
    "output_SVR_glove = my_svm(train_labels, test_embedutts,test_labels,0, 'GLoVE')\n",
    "output_SVC_bert = my_svm(train_labels, test_outputs[\"pooled_output\"],test_labels,1, 'BERT')\n",
    "output_SVR_bert = my_svm(train_labels, test_outputs[\"pooled_output\"],test_labels,0, 'BERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Prediction with GLoVE\n",
      "          estimate\n",
      "Attach    0.647714\n",
      "Comp      0.684661\n",
      "Global    0.357601\n",
      "Health    0.729181\n",
      "Control        NaN\n",
      "MetaCog        NaN\n",
      "Others         NaN\n",
      "Hopeless  0.489903\n",
      "OthViews  0.476297\n"
     ]
    }
   ],
   "source": [
    "print('SVM Classification Prediction with GLoVE')\n",
    "print(pd.DataFrame(data=output_SVC_glove,index=schemas,columns=['estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Regression Prediction with GLoVE\n",
      "          estimate\n",
      "Attach    0.675340\n",
      "Comp      0.640866\n",
      "Global    0.489372\n",
      "Health    0.349064\n",
      "Control   0.310007\n",
      "MetaCog   0.114894\n",
      "Others    0.185827\n",
      "Hopeless  0.535979\n",
      "OthViews  0.516635\n"
     ]
    }
   ],
   "source": [
    "print('SVM Regression Prediction with GLoVE')\n",
    "print(pd.DataFrame(data=output_SVR_glove,index=schemas,columns=['estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification Prediction with BERT\n",
      "          estimate\n",
      "Attach    0.577022\n",
      "Comp      0.689898\n",
      "Global    0.373424\n",
      "Health    0.561481\n",
      "Control  -0.011459\n",
      "MetaCog        NaN\n",
      "Others         NaN\n",
      "Hopeless  0.517952\n",
      "OthViews  0.471861\n"
     ]
    }
   ],
   "source": [
    "print('SVM Classification Prediction with BERT')\n",
    "print(pd.DataFrame(data=output_SVC_bert,index=schemas,columns=['estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Regression Prediction with BERT\n",
      "          estimate\n",
      "Attach    0.663786\n",
      "Comp      0.672748\n",
      "Global    0.506108\n",
      "Health    0.305131\n",
      "Control   0.306820\n",
      "MetaCog   0.141697\n",
      "Others    0.114909\n",
      "Hopeless  0.521259\n",
      "OthViews  0.491448\n"
     ]
    }
   ],
   "source": [
    "print('SVM Regression Prediction with BERT')\n",
    "print(pd.DataFrame(data=output_SVR_bert,index=schemas,columns=['estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 3min 15sec\n",
    "# bootstrap confidence intervals for SVR and SVC\n",
    "bs_svc_glove = bootstrap(train_embedutts, train_labels, n_iterations,n_size,test_embedutts,test_labels, 1,\"svm\", \"GLoVE\")\n",
    "bs_svr_glove = bootstrap(train_embedutts, train_labels, n_iterations,n_size,test_embedutts,test_labels, 0,\"svm\", \"GLoVE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification 95% Confidence Intervals with GLoVE\n",
      "               low      high\n",
      "Attach    0.611903  0.690208\n",
      "Comp      0.645037  0.727340\n",
      "Global    0.296369  0.407668\n",
      "Health    0.648348  0.797075\n",
      "Control   0.000000  1.000000\n",
      "MetaCog   0.000000  1.000000\n",
      "Others    0.000000  1.000000\n",
      "Hopeless  0.421759  0.545510\n",
      "OthViews  0.424901  0.537975\n"
     ]
    }
   ],
   "source": [
    "print(f'SVM Classification 95% Confidence Intervals with GLoVE')\n",
    "print(pd.DataFrame(data=np.transpose(bs_svc_glove),index=schemas,columns=['low','high']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Regression 95% Confidence Intervals with GLoVE\n",
      "               low      high\n",
      "Attach    0.649124  0.700444\n",
      "Comp      0.612465  0.667220\n",
      "Global    0.454683  0.524970\n",
      "Health    0.302367  0.392112\n",
      "Control   0.265696  0.341165\n",
      "MetaCog   0.068038  0.154142\n",
      "Others    0.117043  0.231642\n",
      "Hopeless  0.494234  0.563619\n",
      "OthViews  0.483961  0.547114\n"
     ]
    }
   ],
   "source": [
    "print(f'SVM Regression 95% Confidence Intervals with GLoVE')\n",
    "print(pd.DataFrame(data=np.transpose(bs_svr_glove),index=schemas,columns=['low','high']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 3min 15sec\n",
    "# bootstrap confidence intervals for SVR and SVC\n",
    "bs_svc_bert = bootstrap(train_outputs[\"pooled_output\"], train_labels, n_iterations,n_size,test_outputs[\"pooled_output\"],test_labels,1,\"svm\", \"BERT\")\n",
    "bs_svr_bert = bootstrap(train_outputs[\"pooled_output\"], train_labels, n_iterations,n_size,test_outputs[\"pooled_output\"],test_labels,0,\"svm\", \"BERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classification 95% Confidence Intervals with BERT\n",
      "               low      high\n",
      "Attach    0.540790  0.615402\n",
      "Comp      0.644692  0.728376\n",
      "Global    0.303498  0.435311\n",
      "Health    0.472830  0.633118\n",
      "Control   0.000000  1.000000\n",
      "MetaCog   0.000000  1.000000\n",
      "Others    0.000000  1.000000\n",
      "Hopeless  0.455907  0.579318\n",
      "OthViews  0.408834  0.525559\n"
     ]
    }
   ],
   "source": [
    "print(f'SVM Classification 95% Confidence Intervals with BERT')\n",
    "print(pd.DataFrame(data=np.transpose(bs_svc_bert),index=schemas,columns=['low','high']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Regression 95% Confidence Intervals with BERT\n",
      "               low      high\n",
      "Attach    0.637180  0.686531\n",
      "Comp      0.646569  0.698269\n",
      "Global    0.474639  0.535724\n",
      "Health    0.245164  0.360440\n",
      "Control   0.262643  0.342105\n",
      "MetaCog   0.103795  0.179311\n",
      "Others    0.056081  0.167729\n",
      "Hopeless  0.489317  0.545555\n",
      "OthViews  0.444821  0.529859\n"
     ]
    }
   ],
   "source": [
    "print(f'SVM Regression 95% Confidence Intervals with BERT')\n",
    "print(pd.DataFrame(data=np.transpose(bs_svr_bert),index=schemas,columns=['low','high']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/BootstrapResults/SVM/bs_svr_bert.pkl']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Results for quick loading later if project stops\n",
    "joblib.dump(bs_svc_glove, 'Data/BootstrapResults/SVM/bs_svc_glove.pkl')\n",
    "joblib.dump(bs_svr_glove, 'Data/BootstrapResults/SVM/bs_svr_glove.pkl')\n",
    "joblib.dump(bs_svc_bert, 'Data/BootstrapResults/SVM/bs_svc_bert.pkl')\n",
    "joblib.dump(bs_svr_bert, 'Data/BootstrapResults/SVM/bs_svr_bert.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_svc_glove = joblib.load('Data/BootstrapResults/SVM/bs_svc_glove.pkl')\n",
    "bs_svr_glove = joblib.load('Data/BootstrapResults/SVM/bs_svr_glove.pkl')\n",
    "bs_svc_bert = joblib.load('Data/BootstrapResults/SVM/bs_svc_bert.pkl')\n",
    "bs_svr_bert = joblib.load('Data/BootstrapResults/SVM/bs_svr_bert.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We train two types of recurrent neural networks: a multilabel RNN that predicts all 9 schemas simultaneously and a set of 9 single-label RNNs that predict the labels for each schema separately. Each RNN consists of 4 layers: an embedding layer, a bidirectional LSTM layer, a dropout layer, and an output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Multilabel RNN\n",
    "> We used as inspiration for the architecture of all RNNs the paper: Kshirsagar, R., Morris, R., & Bowman, S. (2017). Detecting and explaining crisis. arXiv preprint arXiv:1705.09585. However, we used long short-term memory (LSTM) instead of a gated recurrent unit (GRU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define multilabel model GLoVE\n",
    "def multilabel_model_glove(train_X, train_y, test_X, test_y,params):\n",
    "    # build the model\n",
    "    model = Sequential()\n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "    #embedding layer\n",
    "    model.add(e)\n",
    "    #LSTM layer\n",
    "    model.add(Bidirectional(LSTM(params['lstm_units'])))\n",
    "    #dropout layer\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    #output layer\n",
    "    model.add(Dense(9, activation='sigmoid'))\n",
    "    # compile the model\n",
    "    model.compile(optimizer=params['optimizer'], loss=params['losses'], metrics=['mean_absolute_error'])\n",
    "    # summarize the model\n",
    "    print(model.summary())\n",
    "    # fit the model\n",
    "    out = model.fit(train_X, train_y, \n",
    "                    validation_data=[test_X,test_y],\n",
    "                    batch_size=params['batch_size'], \n",
    "                    epochs=params['epochs'], \n",
    "                    verbose=0)\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define multilabel model BERT\n",
    "def multilabel_model_bert(train_X, train_y, test_X, test_y,params):\n",
    "    # build the model\n",
    "    model = Sequential()\n",
    "    #No embedding layer for bert outputs if sequence is used\n",
    "    model.add(Input(shape=(128, 512,)))\n",
    "    #LSTM layer\n",
    "    model.add(Bidirectional(LSTM(params['lstm_units'])))\n",
    "    #dropout layer\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    #output layer\n",
    "    model.add(Dense(9, activation='sigmoid'))\n",
    "    # compile the model\n",
    "    model.compile(optimizer=params['optimizer'], loss=params['losses'], metrics=['mean_absolute_error'])\n",
    "    # summarize the model\n",
    "    print(model.summary())\n",
    "    # fit the model\n",
    "    out = model.fit(train_X, train_y, \n",
    "                    validation_data=[test_X,test_y],\n",
    "                    batch_size=params['batch_size'], \n",
    "                    epochs=params['epochs'], \n",
    "                    verbose=0)\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(train_X, test_X, train_y, test_y, multilabel_model, exp_name):\n",
    "    #define hyperparameter grid\n",
    "    p={'lstm_units':[50,100],\n",
    "       'optimizer':['rmsprop','Adam'],\n",
    "       'losses':['binary_crossentropy','categorical_crossentropy','mean_absolute_error'],\n",
    "       'dropout':[0.1,0.5],\n",
    "       'batch_size': [32,64],\n",
    "       'epochs':[100]} \n",
    "    #scan the grid\n",
    "    tal=talos.Scan(x=train_X,\n",
    "                   y=train_y,\n",
    "                   x_val=test_X,\n",
    "                   y_val=test_y,\n",
    "                   model=multilabel_model,\n",
    "                   params=p,\n",
    "                   experiment_name= exp_name,\n",
    "                   print_params=True,\n",
    "                   clear_session=True)\n",
    "    return tal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLoVE Embeddings RNN Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|                                                                                 | 1/48 [01:13<57:54, 73.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|                                                                               | 2/48 [02:25<55:43, 72.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|                                                                            | 3/48 [04:08<1:04:44, 86.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|                                                                          | 4/48 [05:51<1:08:09, 92.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|                                                                        | 5/48 [07:03<1:01:17, 85.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|                                                                        | 6/48 [08:18<57:18, 81.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|                                                                     | 7/48 [10:14<1:03:38, 93.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|                                                                  | 8/48 [12:34<1:12:03, 108.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|                                                                 | 9/48 [14:10<1:07:44, 104.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|                                                               | 10/48 [15:32<1:01:37, 97.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|                                                             | 11/48 [17:45<1:06:40, 108.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|                                                           | 12/48 [19:49<1:07:47, 112.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|                                                         | 13/48 [21:13<1:00:49, 104.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|                                                         | 14/48 [22:48<57:28, 101.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|                                                      | 15/48 [26:05<1:11:40, 130.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|                                                    | 16/48 [29:07<1:17:45, 145.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|                                                   | 17/48 [30:53<1:09:07, 133.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|                                                 | 18/48 [32:36<1:02:21, 124.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|                                               | 19/48 [35:58<1:11:26, 147.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|                                              | 20/48 [39:31<1:18:08, 167.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|                                            | 21/48 [41:24<1:08:02, 151.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|                                          | 22/48 [43:23<1:01:19, 141.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|                                         | 23/48 [47:31<1:12:10, 173.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|                                       | 24/48 [52:01<1:20:59, 202.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|                                     | 25/48 [53:24<1:03:47, 166.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|                                     | 26/48 [54:44<51:34, 140.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|                                   | 27/48 [57:57<54:41, 156.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|                                 | 28/48 [1:01:11<55:49, 167.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|                               | 29/48 [1:02:47<46:19, 146.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|                             | 30/48 [1:04:22<39:14, 130.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|                            | 31/48 [1:07:51<43:44, 154.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|                          | 32/48 [1:11:19<45:24, 170.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|                        | 33/48 [1:12:59<37:16, 149.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|                       | 34/48 [1:14:21<30:09, 129.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|                     | 35/48 [1:17:20<31:12, 144.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|                   | 36/48 [1:20:28<31:26, 157.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|                  | 37/48 [1:22:07<25:37, 139.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|                | 38/48 [1:23:47<21:18, 127.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|              | 39/48 [1:27:17<22:51, 152.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|             | 40/48 [1:30:49<22:41, 170.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|           | 41/48 [1:32:37<17:42, 151.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|         | 42/48 [1:34:53<14:41, 146.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|        | 43/48 [1:38:17<13:39, 163.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|      | 44/48 [1:41:42<11:46, 176.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|     | 45/48 [1:44:13<08:25, 168.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 100)              60400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 323,709\n",
      "Trainable params: 61,309\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|   | 46/48 [1:46:00<05:00, 150.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%| | 47/48 [1:49:46<02:52, 172.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              160800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 48/48 [1:54:15<00:00, 142.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1h 54min 15s\n",
      "              start              end    duration  round_epochs        loss  \\\n",
      "0   05/10/22-203225  05/10/22-203338   73.721319           100  -93.232689   \n",
      "1   05/10/22-203339  05/10/22-203450   71.585853           100  -74.255096   \n",
      "2   05/10/22-203450  05/10/22-203633  102.349468           100 -187.947327   \n",
      "3   05/10/22-203633  05/10/22-203816  102.885891           100 -147.428848   \n",
      "4   05/10/22-203816  05/10/22-203928   72.092832           100   46.448235   \n",
      "5   05/10/22-203928  05/10/22-204043   74.571780           100   44.170319   \n",
      "6   05/10/22-204043  05/10/22-204239  116.094220           100   84.605247   \n",
      "7   05/10/22-204239  05/10/22-204459  139.855941           100   80.855774   \n",
      "8   05/10/22-204500  05/10/22-204635   95.492358           100    0.317915   \n",
      "9   05/10/22-204635  05/10/22-204757   81.612673           100    0.317915   \n",
      "10  05/10/22-204757  05/10/22-205010  132.454166           100    0.317915   \n",
      "11  05/10/22-205010  05/10/22-205214  123.880131           100    0.317915   \n",
      "12  05/10/22-205214  05/10/22-205338   84.001661           100  -77.500389   \n",
      "13  05/10/22-205338  05/10/22-205513   94.589328           100  -62.009720   \n",
      "14  05/10/22-205513  05/10/22-205830  197.013662           100 -159.850235   \n",
      "15  05/10/22-205830  05/10/22-210132  181.569255           100 -118.335854   \n",
      "16  05/10/22-210132  05/10/22-210318  105.559389           100   58.238098   \n",
      "17  05/10/22-210318  05/10/22-210501  103.361493           100   49.982967   \n",
      "18  05/10/22-210501  05/10/22-210823  201.431079           100  100.178276   \n",
      "19  05/10/22-210823  05/10/22-211156  212.998319           100   93.381874   \n",
      "20  05/10/22-211156  05/10/22-211349  113.042220           100    0.317915   \n",
      "21  05/10/22-211350  05/10/22-211548  118.781974           100    0.317915   \n",
      "22  05/10/22-211549  05/10/22-211955  246.962516           100    0.317915   \n",
      "23  05/10/22-211956  05/10/22-212426  270.460597           100    0.317915   \n",
      "24  05/10/22-212426  05/10/22-212549   82.133027           100  -53.077679   \n",
      "25  05/10/22-212549  05/10/22-212709   80.326862           100  -34.959923   \n",
      "26  05/10/22-212709  05/10/22-213022  192.441512           100  -97.423378   \n",
      "27  05/10/22-213022  05/10/22-213335  193.447966           100  -83.479507   \n",
      "28  05/10/22-213336  05/10/22-213512   96.518362           100   23.548834   \n",
      "29  05/10/22-213512  05/10/22-213647   94.576745           100   21.081396   \n",
      "30  05/10/22-213647  05/10/22-214016  209.193808           100   33.089554   \n",
      "31  05/10/22-214017  05/10/22-214344  207.072078           100   34.461514   \n",
      "32  05/10/22-214344  05/10/22-214523   99.546668           100    0.317915   \n",
      "33  05/10/22-214524  05/10/22-214646   82.597298           100    0.317916   \n",
      "34  05/10/22-214647  05/10/22-214945  178.382386           100    0.317915   \n",
      "35  05/10/22-214945  05/10/22-215253  187.713993           100    0.317916   \n",
      "36  05/10/22-215253  05/10/22-215432   98.815764           100  -40.086597   \n",
      "37  05/10/22-215432  05/10/22-215612   99.886481           100  -41.138634   \n",
      "38  05/10/22-215612  05/10/22-215942  209.528547           100  -83.993530   \n",
      "39  05/10/22-215942  05/10/22-220313  211.372257           100  -68.439445   \n",
      "40  05/10/22-220314  05/10/22-220502  108.550826           100   25.482723   \n",
      "41  05/10/22-220502  05/10/22-220718  135.228832           100   24.663729   \n",
      "42  05/10/22-220718  05/10/22-221041  203.553286           100   47.319279   \n",
      "43  05/10/22-221042  05/10/22-221407  205.707255           100   42.726440   \n",
      "44  05/10/22-221408  05/10/22-221637  149.898346           100    0.317915   \n",
      "45  05/10/22-221638  05/10/22-221825  107.527389           100    0.317916   \n",
      "46  05/10/22-221825  05/10/22-222211  225.284788           100    0.317915   \n",
      "47  05/10/22-222211  05/10/22-222640  268.571756           100    0.317916   \n",
      "\n",
      "    mean_absolute_error    val_loss  val_mean_absolute_error  batch_size  \\\n",
      "0              0.338700  -71.443260                 0.346752          32   \n",
      "1              0.382358  -64.349663                 0.363545          32   \n",
      "2              0.334780 -142.233841                 0.353025          32   \n",
      "3              0.367332 -116.261330                 0.375833          32   \n",
      "4              1.022993   47.963261                 1.022738          32   \n",
      "5              1.022993   45.533737                 1.022738          32   \n",
      "6              1.022993   87.448982                 1.022738          32   \n",
      "7              1.022993   83.543060                 1.022738          32   \n",
      "8              0.317915    0.315901                 0.315901          32   \n",
      "9              0.317915    0.315901                 0.315901          32   \n",
      "10             0.317915    0.315901                 0.315901          32   \n",
      "11             0.317915    0.315901                 0.315901          32   \n",
      "12             0.353421  -60.552818                 0.346152          32   \n",
      "13             0.387300  -50.811790                 0.369105          32   \n",
      "14             0.343432 -124.435806                 0.340278          32   \n",
      "15             0.383873  -94.160385                 0.362737          32   \n",
      "16             1.022993   58.799896                 1.022738          32   \n",
      "17             1.022993   51.705559                 1.022738          32   \n",
      "18             1.022993  103.389740                 1.022738          32   \n",
      "19             1.022993   96.604202                 1.022738          32   \n",
      "20             0.317915    0.315901                 0.315901          32   \n",
      "21             0.317915    0.315901                 0.315901          32   \n",
      "22             0.317915    0.315901                 0.315901          32   \n",
      "23             0.317915    0.315901                 0.315901          32   \n",
      "24             0.344795  -40.856903                 0.347030          64   \n",
      "25             0.386393  -30.657993                 0.377709          64   \n",
      "26             0.344925  -76.178055                 0.352592          64   \n",
      "27             0.351077  -70.847664                 0.362883          64   \n",
      "28             1.022752   21.959761                 1.022738          64   \n",
      "29             1.022993   20.555643                 1.022738          64   \n",
      "30             1.022993   33.910912                 1.022738          64   \n",
      "31             1.022993   34.902267                 1.022738          64   \n",
      "32             0.317915    0.315901                 0.315901          64   \n",
      "33             0.317916    0.315902                 0.315902          64   \n",
      "34             0.317915    0.315901                 0.315901          64   \n",
      "35             0.317916    0.315901                 0.315901          64   \n",
      "36             0.371282  -31.082897                 0.367263          64   \n",
      "37             0.365382  -34.810692                 0.343191          64   \n",
      "38             0.345245  -67.422844                 0.339047          64   \n",
      "39             0.365388  -54.572247                 0.357191          64   \n",
      "40             1.022993   25.983112                 1.022738          64   \n",
      "41             1.022993   24.993361                 1.022738          64   \n",
      "42             1.022993   47.425705                 1.022738          64   \n",
      "43             1.022993   43.529583                 1.022738          64   \n",
      "44             0.317915    0.315901                 0.315901          64   \n",
      "45             0.317916    0.315901                 0.315901          64   \n",
      "46             0.317915    0.315901                 0.315901          64   \n",
      "47             0.317916    0.315901                 0.315901          64   \n",
      "\n",
      "    dropout  epochs                    losses  lstm_units optimizer  \n",
      "0       0.1     100       binary_crossentropy          50   rmsprop  \n",
      "1       0.1     100       binary_crossentropy          50      Adam  \n",
      "2       0.1     100       binary_crossentropy         100   rmsprop  \n",
      "3       0.1     100       binary_crossentropy         100      Adam  \n",
      "4       0.1     100  categorical_crossentropy          50   rmsprop  \n",
      "5       0.1     100  categorical_crossentropy          50      Adam  \n",
      "6       0.1     100  categorical_crossentropy         100   rmsprop  \n",
      "7       0.1     100  categorical_crossentropy         100      Adam  \n",
      "8       0.1     100       mean_absolute_error          50   rmsprop  \n",
      "9       0.1     100       mean_absolute_error          50      Adam  \n",
      "10      0.1     100       mean_absolute_error         100   rmsprop  \n",
      "11      0.1     100       mean_absolute_error         100      Adam  \n",
      "12      0.5     100       binary_crossentropy          50   rmsprop  \n",
      "13      0.5     100       binary_crossentropy          50      Adam  \n",
      "14      0.5     100       binary_crossentropy         100   rmsprop  \n",
      "15      0.5     100       binary_crossentropy         100      Adam  \n",
      "16      0.5     100  categorical_crossentropy          50   rmsprop  \n",
      "17      0.5     100  categorical_crossentropy          50      Adam  \n",
      "18      0.5     100  categorical_crossentropy         100   rmsprop  \n",
      "19      0.5     100  categorical_crossentropy         100      Adam  \n",
      "20      0.5     100       mean_absolute_error          50   rmsprop  \n",
      "21      0.5     100       mean_absolute_error          50      Adam  \n",
      "22      0.5     100       mean_absolute_error         100   rmsprop  \n",
      "23      0.5     100       mean_absolute_error         100      Adam  \n",
      "24      0.1     100       binary_crossentropy          50   rmsprop  \n",
      "25      0.1     100       binary_crossentropy          50      Adam  \n",
      "26      0.1     100       binary_crossentropy         100   rmsprop  \n",
      "27      0.1     100       binary_crossentropy         100      Adam  \n",
      "28      0.1     100  categorical_crossentropy          50   rmsprop  \n",
      "29      0.1     100  categorical_crossentropy          50      Adam  \n",
      "30      0.1     100  categorical_crossentropy         100   rmsprop  \n",
      "31      0.1     100  categorical_crossentropy         100      Adam  \n",
      "32      0.1     100       mean_absolute_error          50   rmsprop  \n",
      "33      0.1     100       mean_absolute_error          50      Adam  \n",
      "34      0.1     100       mean_absolute_error         100   rmsprop  \n",
      "35      0.1     100       mean_absolute_error         100      Adam  \n",
      "36      0.5     100       binary_crossentropy          50   rmsprop  \n",
      "37      0.5     100       binary_crossentropy          50      Adam  \n",
      "38      0.5     100       binary_crossentropy         100   rmsprop  \n",
      "39      0.5     100       binary_crossentropy         100      Adam  \n",
      "40      0.5     100  categorical_crossentropy          50   rmsprop  \n",
      "41      0.5     100  categorical_crossentropy          50      Adam  \n",
      "42      0.5     100  categorical_crossentropy         100   rmsprop  \n",
      "43      0.5     100  categorical_crossentropy         100      Adam  \n",
      "44      0.5     100       mean_absolute_error          50   rmsprop  \n",
      "45      0.5     100       mean_absolute_error          50      Adam  \n",
      "46      0.5     100       mean_absolute_error         100   rmsprop  \n",
      "47      0.5     100       mean_absolute_error         100      Adam  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# wall time to run grid search: ~ 2h 10min\n",
    "#run the small grid search\n",
    "%time tal = grid_search(padded_train, padded_validate, train_labels, val_labels, multilabel_model_glove, 'multilabel_rnn_glove')\n",
    "#analyze the outcome\n",
    "analyze_object=talos.Analyze(tal)\n",
    "analysis_results = analyze_object.data\n",
    "#let's have a look at the results of the grid search\n",
    "print(analysis_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we choose the best model of the grid search on the basis of the MAE metric, lower values are better\n",
    "mlm_model_glove = tal.best_model(metric='mean_absolute_error', asc=True)\n",
    "#to get an idea of how our best model performs, we check predictions on the validation set\n",
    "prediction_mlm_val_glove = mlm_model_glove.predict(padded_validate)\n",
    "output_mlm_val_glove = gof_spear(prediction_mlm_val_glove,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          estimate\n",
      "Attach   -0.001602\n",
      "Comp     -0.043018\n",
      "Global    0.070571\n",
      "Health   -0.056575\n",
      "Control  -0.075047\n",
      "MetaCog  -0.146498\n",
      "Others   -0.042516\n",
      "Hopeless -0.046862\n",
      "OthViews  0.125471\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(data=output_mlm_val_glove,index=schemas,columns=['estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy package mlm_rnn_glove have been saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<talos.commands.deploy.Deploy at 0x26b0e137d30>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the predictions make sense considering what we got from KNN and SVM. We deploy the model.\n",
    "talos.Deploy(tal,'mlm_rnn_glove',metric='mean_absolute_error',asc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint After Parameter Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we restore the deployed Talos experiment\n",
    "restore_glove = talos.Restore('Data/mlm_rnn_glove.zip')\n",
    "#to get the best performing parameters, we get the results of the Talos experiment\n",
    "scan_results_glove = restore_glove.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              start              end    duration  round_epochs      loss  \\\n",
      "32  05/10/22-214344  05/10/22-214523   99.546668           100  0.317915   \n",
      "34  05/10/22-214647  05/10/22-214945  178.382386           100  0.317915   \n",
      "44  05/10/22-221408  05/10/22-221637  149.898346           100  0.317915   \n",
      "46  05/10/22-221825  05/10/22-222211  225.284788           100  0.317915   \n",
      "\n",
      "    mean_absolute_error  val_loss  val_mean_absolute_error  batch_size  \\\n",
      "32             0.317915  0.315901                 0.315901          64   \n",
      "34             0.317915  0.315901                 0.315901          64   \n",
      "44             0.317915  0.315901                 0.315901          64   \n",
      "46             0.317915  0.315901                 0.315901          64   \n",
      "\n",
      "    dropout  epochs               losses  lstm_units optimizer  \n",
      "32      0.1     100  mean_absolute_error          50   rmsprop  \n",
      "34      0.1     100  mean_absolute_error         100   rmsprop  \n",
      "44      0.5     100  mean_absolute_error          50   rmsprop  \n",
      "46      0.5     100  mean_absolute_error         100   rmsprop  \n"
     ]
    }
   ],
   "source": [
    "#select the row with the smallest mean absolute error\n",
    "print(scan_results_glove[scan_results_glove.mean_absolute_error == scan_results_glove.mean_absolute_error.min()]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT Embeddings RNN Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/48 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|                                                                              | 1/48 [06:52<5:22:57, 412.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|                                                                            | 2/48 [13:52<5:19:36, 416.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|                                                                           | 3/48 [24:20<6:24:57, 513.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|                                                                         | 4/48 [35:23<6:59:43, 572.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|                                                                       | 5/48 [46:08<7:08:58, 598.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|                                                                      | 6/48 [56:11<7:00:02, 600.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|                                                                  | 7/48 [1:10:58<7:54:07, 693.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|                                                                 | 8/48 [1:26:15<8:30:05, 765.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|                                                               | 9/48 [1:37:48<8:02:34, 742.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|                                                             | 10/48 [1:49:25<7:41:20, 728.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|                                                           | 11/48 [2:05:56<8:18:38, 808.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|                                                         | 12/48 [2:22:12<8:35:49, 859.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|                                                        | 13/48 [2:33:43<7:51:41, 808.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|                                                      | 14/48 [2:47:20<7:39:35, 811.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|                                                     | 15/48 [3:04:01<7:57:36, 868.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|                                                   | 16/48 [3:19:01<7:48:15, 877.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|                                                 | 17/48 [3:31:32<7:13:48, 839.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|                                                | 18/48 [3:44:17<6:48:38, 817.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|                                              | 19/48 [4:06:55<7:53:32, 979.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|                                             | 20/48 [4:24:09<7:44:48, 996.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|                                           | 21/48 [4:36:56<6:57:15, 927.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|                                         | 22/48 [4:49:33<6:19:41, 876.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|                                        | 23/48 [5:03:07<5:57:17, 857.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|                                      | 24/48 [5:20:10<6:02:51, 907.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|                                     | 25/48 [5:30:01<5:11:22, 812.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|                                   | 26/48 [5:39:39<4:32:04, 742.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|                                 | 27/48 [5:58:05<4:57:52, 851.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|                                | 28/48 [6:15:30<5:03:07, 909.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|                              | 29/48 [6:26:02<4:21:39, 826.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|                            | 30/48 [6:36:01<3:47:21, 757.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|                           | 31/48 [6:52:49<3:56:02, 833.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|                         | 32/48 [7:12:01<4:07:40, 928.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|                        | 33/48 [7:22:27<3:29:27, 837.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|                      | 34/48 [7:32:14<2:57:55, 762.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|                    | 35/48 [7:51:13<3:09:43, 875.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.1, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|                   | 36/48 [8:08:30<3:04:46, 923.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|                 | 37/48 [8:18:21<2:31:03, 823.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|                | 38/48 [8:27:57<2:04:55, 749.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|              | 39/48 [8:45:51<2:07:02, 846.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'binary_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|            | 40/48 [9:04:14<2:03:11, 923.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|           | 41/48 [9:15:24<1:38:53, 847.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|         | 42/48 [9:26:41<1:19:38, 796.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|        | 43/48 [9:46:54<1:16:46, 921.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'categorical_crossentropy', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|      | 44/48 [10:04:50<1:04:30, 967.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|    | 45/48 [10:14:23<42:28, 849.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 50, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 100)              225200    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 909       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,109\n",
      "Trainable params: 226,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|   | 46/48 [10:23:57<25:33, 766.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'rmsprop'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%| | 47/48 [10:43:54<14:55, 895.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64, 'dropout': 0.5, 'epochs': 100, 'losses': 'mean_absolute_error', 'lstm_units': 100, 'optimizer': 'Adam'}\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional (Bidirectiona  (None, 200)              490400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 48/48 [11:03:28<00:00, 829.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11h 3min 28s\n",
      "              start              end     duration  round_epochs        loss  \\\n",
      "0   05/11/22-105921  05/11/22-110613   412.157741           100 -117.364006   \n",
      "1   05/11/22-110613  05/11/22-111313   419.906254           100  -75.218109   \n",
      "2   05/11/22-111314  05/11/22-112341   627.789979           100 -235.665237   \n",
      "3   05/11/22-112342  05/11/22-113444   662.715708           100 -146.606827   \n",
      "4   05/11/22-113444  05/11/22-114529   644.905038           100   77.595299   \n",
      "5   05/11/22-114530  05/11/22-115532   602.767111           100   60.911186   \n",
      "6   05/11/22-115532  05/11/22-121019   886.779396           100  127.547699   \n",
      "7   05/11/22-121019  05/11/22-122537   917.544783           100   93.097160   \n",
      "8   05/11/22-122537  05/11/22-123709   692.355245           100    0.222509   \n",
      "9   05/11/22-123710  05/11/22-124847   696.886122           100    0.317915   \n",
      "10  05/11/22-124847  05/11/22-130517   990.257118           100    0.209205   \n",
      "11  05/11/22-130517  05/11/22-132134   976.427785           100    0.290935   \n",
      "12  05/11/22-132134  05/11/22-133305   690.852490           100  -94.889488   \n",
      "13  05/11/22-133305  05/11/22-134641   816.425759           100  -71.722412   \n",
      "14  05/11/22-134641  05/11/22-140322  1001.041733           100 -192.646011   \n",
      "15  05/11/22-140323  05/11/22-141823   900.104326           100 -128.508835   \n",
      "16  05/11/22-141823  05/11/22-143053   750.269298           100   82.689804   \n",
      "17  05/11/22-143053  05/11/22-144339   765.109225           100   78.266800   \n",
      "18  05/11/22-144339  05/11/22-150617  1357.997132           100  150.612427   \n",
      "19  05/11/22-150617  05/11/22-152331  1033.795122           100  107.294815   \n",
      "20  05/11/22-152331  05/11/22-153618   766.670448           100    0.243628   \n",
      "21  05/11/22-153618  05/11/22-154855   756.987548           100    0.285307   \n",
      "22  05/11/22-154855  05/11/22-160229   813.716750           100    0.213604   \n",
      "23  05/11/22-160229  05/11/22-161932  1022.726871           100    0.291480   \n",
      "24  05/11/22-161932  05/11/22-162923   590.838497           100  -58.798973   \n",
      "25  05/11/22-162923  05/11/22-163901   577.853670           100  -47.380108   \n",
      "26  05/11/22-163901  05/11/22-165726  1105.280129           100 -116.728851   \n",
      "27  05/11/22-165726  05/11/22-171452  1045.285280           100  -84.751381   \n",
      "28  05/11/22-171452  05/11/22-172524   632.176123           100   33.814716   \n",
      "29  05/11/22-172524  05/11/22-173522   598.053544           100   31.050425   \n",
      "30  05/11/22-173522  05/11/22-175211  1008.360646           100   45.587738   \n",
      "31  05/11/22-175211  05/11/22-181123  1151.967518           100   46.101364   \n",
      "32  05/11/22-181123  05/11/22-182148   625.403229           100    0.228220   \n",
      "33  05/11/22-182149  05/11/22-183135   586.658677           100    0.289599   \n",
      "34  05/11/22-183135  05/11/22-185035  1139.421140           100    0.204597   \n",
      "35  05/11/22-185035  05/11/22-190751  1036.081906           100    0.291149   \n",
      "36  05/11/22-190751  05/11/22-191742   590.695919           100  -50.756187   \n",
      "37  05/11/22-191742  05/11/22-192718   575.820817           100  -45.134140   \n",
      "38  05/11/22-192718  05/11/22-194512  1074.082744           100 -105.671875   \n",
      "39  05/11/22-194513  05/11/22-200336  1103.408960           100  -63.479900   \n",
      "40  05/11/22-200336  05/11/22-201446   669.513648           100   42.133801   \n",
      "41  05/11/22-201446  05/11/22-202602   676.320256           100   34.881565   \n",
      "42  05/11/22-202602  05/11/22-204615  1212.663942           100   70.373634   \n",
      "43  05/11/22-204615  05/11/22-210411  1075.826669           100   54.567188   \n",
      "44  05/11/22-210411  05/11/22-211344   572.950235           100    0.224133   \n",
      "45  05/11/22-211344  05/11/22-212319   574.158712           100    0.247189   \n",
      "46  05/11/22-212319  05/11/22-214316  1197.035146           100    0.231014   \n",
      "47  05/11/22-214316  05/11/22-220250  1173.653767           100    0.291142   \n",
      "\n",
      "    mean_absolute_error    val_loss  val_mean_absolute_error  batch_size  \\\n",
      "0              0.302031  -79.939384                 0.332229          32   \n",
      "1              0.336027  -60.997372                 0.343190          32   \n",
      "2              0.301175 -163.036713                 0.312067          32   \n",
      "3              0.347346 -112.418861                 0.353074          32   \n",
      "4              0.979443   88.418144                 0.986370          32   \n",
      "5              1.022993   75.470863                 1.022738          32   \n",
      "6              1.000067  145.090027                 1.013339          32   \n",
      "7              1.022993   90.643631                 1.022738          32   \n",
      "8              0.222509    0.261265                 0.261265          32   \n",
      "9              0.317915    0.315901                 0.315901          32   \n",
      "10             0.209205    0.254831                 0.254831          32   \n",
      "11             0.290935    0.298811                 0.298811          32   \n",
      "12             0.321943  -67.387772                 0.323206          32   \n",
      "13             0.351622  -55.576355                 0.340828          32   \n",
      "14             0.316737 -146.340958                 0.314682          32   \n",
      "15             0.357140 -112.501160                 0.340479          32   \n",
      "16             0.975434   87.935066                 1.003737          32   \n",
      "17             1.022993   82.207039                 1.022738          32   \n",
      "18             0.995068  158.525513                 1.008113          32   \n",
      "19             1.022993  108.118324                 1.022738          32   \n",
      "20             0.243628    0.270919                 0.270919          32   \n",
      "21             0.285307    0.294040                 0.294040          32   \n",
      "22             0.213604    0.257440                 0.257440          32   \n",
      "23             0.291480    0.297219                 0.297219          32   \n",
      "24             0.313778  -44.106747                 0.320925          64   \n",
      "25             0.335405  -34.679665                 0.348734          64   \n",
      "26             0.311631  -89.396729                 0.316993          64   \n",
      "27             0.334448  -67.468033                 0.340546          64   \n",
      "28             0.983830   37.390541                 1.007276          64   \n",
      "29             1.022993   33.338913                 1.022738          64   \n",
      "30             0.985087   49.247585                 1.011975          64   \n",
      "31             1.022993   50.749893                 1.022738          64   \n",
      "32             0.228220    0.264420                 0.264420          64   \n",
      "33             0.289599    0.297210                 0.297210          64   \n",
      "34             0.204597    0.256177                 0.256177          64   \n",
      "35             0.291149    0.298193                 0.298193          64   \n",
      "36             0.335605  -39.372395                 0.323949          64   \n",
      "37             0.348879  -35.043259                 0.338025          64   \n",
      "38             0.320890  -77.656792                 0.311999          64   \n",
      "39             0.364266  -49.765392                 0.355057          64   \n",
      "40             0.992586   42.777691                 1.000798          64   \n",
      "41             1.022993   35.432487                 1.022738          64   \n",
      "42             0.987503   69.280853                 1.005601          64   \n",
      "43             1.022993   55.723122                 1.022738          64   \n",
      "44             0.224133    0.255229                 0.255229          64   \n",
      "45             0.247189    0.270085                 0.270085          64   \n",
      "46             0.231014    0.262916                 0.262916          64   \n",
      "47             0.291142    0.297896                 0.297896          64   \n",
      "\n",
      "    dropout  epochs                    losses  lstm_units optimizer  \n",
      "0       0.1     100       binary_crossentropy          50   rmsprop  \n",
      "1       0.1     100       binary_crossentropy          50      Adam  \n",
      "2       0.1     100       binary_crossentropy         100   rmsprop  \n",
      "3       0.1     100       binary_crossentropy         100      Adam  \n",
      "4       0.1     100  categorical_crossentropy          50   rmsprop  \n",
      "5       0.1     100  categorical_crossentropy          50      Adam  \n",
      "6       0.1     100  categorical_crossentropy         100   rmsprop  \n",
      "7       0.1     100  categorical_crossentropy         100      Adam  \n",
      "8       0.1     100       mean_absolute_error          50   rmsprop  \n",
      "9       0.1     100       mean_absolute_error          50      Adam  \n",
      "10      0.1     100       mean_absolute_error         100   rmsprop  \n",
      "11      0.1     100       mean_absolute_error         100      Adam  \n",
      "12      0.5     100       binary_crossentropy          50   rmsprop  \n",
      "13      0.5     100       binary_crossentropy          50      Adam  \n",
      "14      0.5     100       binary_crossentropy         100   rmsprop  \n",
      "15      0.5     100       binary_crossentropy         100      Adam  \n",
      "16      0.5     100  categorical_crossentropy          50   rmsprop  \n",
      "17      0.5     100  categorical_crossentropy          50      Adam  \n",
      "18      0.5     100  categorical_crossentropy         100   rmsprop  \n",
      "19      0.5     100  categorical_crossentropy         100      Adam  \n",
      "20      0.5     100       mean_absolute_error          50   rmsprop  \n",
      "21      0.5     100       mean_absolute_error          50      Adam  \n",
      "22      0.5     100       mean_absolute_error         100   rmsprop  \n",
      "23      0.5     100       mean_absolute_error         100      Adam  \n",
      "24      0.1     100       binary_crossentropy          50   rmsprop  \n",
      "25      0.1     100       binary_crossentropy          50      Adam  \n",
      "26      0.1     100       binary_crossentropy         100   rmsprop  \n",
      "27      0.1     100       binary_crossentropy         100      Adam  \n",
      "28      0.1     100  categorical_crossentropy          50   rmsprop  \n",
      "29      0.1     100  categorical_crossentropy          50      Adam  \n",
      "30      0.1     100  categorical_crossentropy         100   rmsprop  \n",
      "31      0.1     100  categorical_crossentropy         100      Adam  \n",
      "32      0.1     100       mean_absolute_error          50   rmsprop  \n",
      "33      0.1     100       mean_absolute_error          50      Adam  \n",
      "34      0.1     100       mean_absolute_error         100   rmsprop  \n",
      "35      0.1     100       mean_absolute_error         100      Adam  \n",
      "36      0.5     100       binary_crossentropy          50   rmsprop  \n",
      "37      0.5     100       binary_crossentropy          50      Adam  \n",
      "38      0.5     100       binary_crossentropy         100   rmsprop  \n",
      "39      0.5     100       binary_crossentropy         100      Adam  \n",
      "40      0.5     100  categorical_crossentropy          50   rmsprop  \n",
      "41      0.5     100  categorical_crossentropy          50      Adam  \n",
      "42      0.5     100  categorical_crossentropy         100   rmsprop  \n",
      "43      0.5     100  categorical_crossentropy         100      Adam  \n",
      "44      0.5     100       mean_absolute_error          50   rmsprop  \n",
      "45      0.5     100       mean_absolute_error          50      Adam  \n",
      "46      0.5     100       mean_absolute_error         100   rmsprop  \n",
      "47      0.5     100       mean_absolute_error         100      Adam  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# wall time to run grid search: ~ 2h 10min\n",
    "#run the small grid search\n",
    "%time tal = grid_search(train_outputs[\"sequence_output\"], val_outputs[\"sequence_output\"], train_labels, val_labels, multilabel_model_bert, 'multilabel_rnn_bert')\n",
    "#analyze the outcome\n",
    "analyze_object=talos.Analyze(tal)\n",
    "analysis_results = analyze_object.data\n",
    "#let's have a look at the results of the grid search\n",
    "print(analysis_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we choose the best model of the grid search on the basis of the MAE metric, lower values are better\n",
    "mlm_model_bert = tal.best_model(metric='mean_absolute_error', asc=True)\n",
    "#to get an idea of how our best model performs, we check predictions on the validation set\n",
    "prediction_mlm_val_bert = mlm_model_bert.predict(val_outputs[\"sequence_output\"])\n",
    "output_mlm_val_bert = gof_spear(prediction_mlm_val_bert,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          estimate\n",
      "Attach    0.673755\n",
      "Comp      0.638589\n",
      "Global    0.544970\n",
      "Health    0.348355\n",
      "Control   0.055208\n",
      "MetaCog   0.044337\n",
      "Others    0.001242\n",
      "Hopeless  0.489562\n",
      "OthViews  0.529834\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(data=output_mlm_val_bert,index=schemas,columns=['estimate']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint After Parameter Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy package mlm_rnn_bert have been saved.\n",
      "data is not 2d, dummy data written instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<talos.commands.deploy.Deploy at 0x23bf9506830>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the predictions make sense considering what we got from KNN and SVM. We deploy the model.\n",
    "talos.Deploy(tal,'mlm_rnn_bert',metric='mean_absolute_error',asc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17480/2633770781.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#we restore the deployed Talos experiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrestore_bert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtalos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Data/mlm_rnn_bert.zip'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#to get the best performing parameters, we get the results of the Talos experiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mscan_results_bert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrestore_bert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\talos\\commands\\restore.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_to_zip)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m# add x data sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_x.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# add y data sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_dtype_objs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "#we restore the deployed Talos experiment\n",
    "restore_bert = talos.Restore('Data/mlm_rnn_bert.zip')\n",
    "#to get the best performing parameters, we get the results of the Talos experiment\n",
    "scan_results_bert = restore_bert.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scan_results_bert' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17480/2192717330.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#select the row with the smallest mean absolute error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscan_results_bert\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscan_results_bert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mscan_results_bert\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'scan_results_bert' is not defined"
     ]
    }
   ],
   "source": [
    "#select the row with the smallest mean absolute error\n",
    "print(scan_results_bert[scan_results_bert.mean_absolute_error == scan_results_bert.mean_absolute_error.min()]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Optimal Model Based On Tuned Parameters\n",
    "#### Optimal GLoVE Multilabel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlm_fixed_glove(train_X, train_y, test_X, test_y):\n",
    "    # build the model\n",
    "    model = Sequential()\n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "    #embedding layer\n",
    "    model.add(e)\n",
    "    #LSTM layer\n",
    "    model.add(Bidirectional(LSTM(100)))\n",
    "    #dropout layer\n",
    "    model.add(Dropout(0.1))\n",
    "    #output layer\n",
    "    model.add(Dense(9, activation='sigmoid'))\n",
    "    # compile the model\n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['mean_absolute_error'])\n",
    "    # summarize the model\n",
    "    print(model.summary())\n",
    "    # fit the model\n",
    "    out = model.fit(train_X, train_y, \n",
    "                    validation_data=[test_X,test_y],\n",
    "                    batch_size=32, \n",
    "                    epochs=100, \n",
    "                    verbose=0)\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_13 (Embedding)    (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional_25 (Bidirecti  (None, 200)              160800    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 425,009\n",
      "Trainable params: 162,609\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 7s 47ms/step - loss: 7.3217 - mean_absolute_error: 0.9652 - val_loss: 7.4269 - val_mean_absolute_error: 1.0227\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 7.9658 - mean_absolute_error: 1.0230 - val_loss: 8.2478 - val_mean_absolute_error: 1.0227\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 8.7260 - mean_absolute_error: 1.0230 - val_loss: 8.7857 - val_mean_absolute_error: 1.0227\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 9.2744 - mean_absolute_error: 1.0230 - val_loss: 9.8499 - val_mean_absolute_error: 1.0227\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 10.4334 - mean_absolute_error: 1.0230 - val_loss: 10.3226 - val_mean_absolute_error: 1.0227\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 10.7972 - mean_absolute_error: 1.0230 - val_loss: 11.2395 - val_mean_absolute_error: 1.0227\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 11.6252 - mean_absolute_error: 1.0230 - val_loss: 12.1401 - val_mean_absolute_error: 1.0227\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 12.6290 - mean_absolute_error: 1.0230 - val_loss: 12.7828 - val_mean_absolute_error: 1.0227\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 13.3386 - mean_absolute_error: 1.0230 - val_loss: 13.7581 - val_mean_absolute_error: 1.0227\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 14.0467 - mean_absolute_error: 1.0230 - val_loss: 14.5687 - val_mean_absolute_error: 1.0227\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 14.8871 - mean_absolute_error: 1.0230 - val_loss: 15.2754 - val_mean_absolute_error: 1.0227\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 15.6273 - mean_absolute_error: 1.0230 - val_loss: 16.0294 - val_mean_absolute_error: 1.0227\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 16.4143 - mean_absolute_error: 1.0230 - val_loss: 16.9816 - val_mean_absolute_error: 1.0227\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 17.1364 - mean_absolute_error: 1.0230 - val_loss: 17.6397 - val_mean_absolute_error: 1.0227\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 17.9032 - mean_absolute_error: 1.0230 - val_loss: 18.3996 - val_mean_absolute_error: 1.0227\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 18.5070 - mean_absolute_error: 1.0230 - val_loss: 19.2352 - val_mean_absolute_error: 1.0227\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 19.4022 - mean_absolute_error: 1.0230 - val_loss: 19.9750 - val_mean_absolute_error: 1.0227\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 20.1556 - mean_absolute_error: 1.0230 - val_loss: 20.6799 - val_mean_absolute_error: 1.0227\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 20.7339 - mean_absolute_error: 1.0230 - val_loss: 21.5522 - val_mean_absolute_error: 1.0227\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 21.5089 - mean_absolute_error: 1.0230 - val_loss: 22.3022 - val_mean_absolute_error: 1.0227\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 22.5491 - mean_absolute_error: 1.0230 - val_loss: 23.0621 - val_mean_absolute_error: 1.0227\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 23.0993 - mean_absolute_error: 1.0230 - val_loss: 23.8521 - val_mean_absolute_error: 1.0227\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 23.9640 - mean_absolute_error: 1.0230 - val_loss: 24.5140 - val_mean_absolute_error: 1.0227\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 24.4715 - mean_absolute_error: 1.0230 - val_loss: 25.2527 - val_mean_absolute_error: 1.0227\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 25.1956 - mean_absolute_error: 1.0230 - val_loss: 26.0384 - val_mean_absolute_error: 1.0227\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 26.0034 - mean_absolute_error: 1.0230 - val_loss: 26.9792 - val_mean_absolute_error: 1.0227\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 26.9171 - mean_absolute_error: 1.0230 - val_loss: 27.8905 - val_mean_absolute_error: 1.0227\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 27.7617 - mean_absolute_error: 1.0230 - val_loss: 28.4876 - val_mean_absolute_error: 1.0227\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 28.3119 - mean_absolute_error: 1.0230 - val_loss: 29.3160 - val_mean_absolute_error: 1.0227\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 29.0578 - mean_absolute_error: 1.0230 - val_loss: 29.9961 - val_mean_absolute_error: 1.0227\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 29.9314 - mean_absolute_error: 1.0230 - val_loss: 30.6781 - val_mean_absolute_error: 1.0227\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 30.5086 - mean_absolute_error: 1.0230 - val_loss: 31.5283 - val_mean_absolute_error: 1.0227\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 31.5141 - mean_absolute_error: 1.0230 - val_loss: 32.3886 - val_mean_absolute_error: 1.0227\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 32.0591 - mean_absolute_error: 1.0230 - val_loss: 33.0938 - val_mean_absolute_error: 1.0227\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 33.0128 - mean_absolute_error: 1.0230 - val_loss: 33.9285 - val_mean_absolute_error: 1.0227\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 33.9094 - mean_absolute_error: 1.0230 - val_loss: 34.6746 - val_mean_absolute_error: 1.0227\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 34.2950 - mean_absolute_error: 1.0230 - val_loss: 35.4024 - val_mean_absolute_error: 1.0227\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 35.1788 - mean_absolute_error: 1.0230 - val_loss: 36.1733 - val_mean_absolute_error: 1.0227\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 35.8400 - mean_absolute_error: 1.0230 - val_loss: 36.9606 - val_mean_absolute_error: 1.0227\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 36.6426 - mean_absolute_error: 1.0230 - val_loss: 37.7102 - val_mean_absolute_error: 1.0227\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 37.4313 - mean_absolute_error: 1.0230 - val_loss: 38.7286 - val_mean_absolute_error: 1.0227\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 38.2004 - mean_absolute_error: 1.0230 - val_loss: 39.4132 - val_mean_absolute_error: 1.0227\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 38.7942 - mean_absolute_error: 1.0230 - val_loss: 40.1294 - val_mean_absolute_error: 1.0227\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 39.5949 - mean_absolute_error: 1.0230 - val_loss: 40.9483 - val_mean_absolute_error: 1.0227\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 40.2767 - mean_absolute_error: 1.0230 - val_loss: 41.8287 - val_mean_absolute_error: 1.0227\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 41.3465 - mean_absolute_error: 1.0230 - val_loss: 42.4919 - val_mean_absolute_error: 1.0227\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 41.9037 - mean_absolute_error: 1.0230 - val_loss: 43.2252 - val_mean_absolute_error: 1.0227\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 42.4583 - mean_absolute_error: 1.0230 - val_loss: 43.8184 - val_mean_absolute_error: 1.0227\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 43.1653 - mean_absolute_error: 1.0230 - val_loss: 44.5456 - val_mean_absolute_error: 1.0227\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 43.8769 - mean_absolute_error: 1.0230 - val_loss: 45.4864 - val_mean_absolute_error: 1.0227\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 44.7515 - mean_absolute_error: 1.0230 - val_loss: 46.1275 - val_mean_absolute_error: 1.0227\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 45.4391 - mean_absolute_error: 1.0230 - val_loss: 47.0160 - val_mean_absolute_error: 1.0227\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 46.0415 - mean_absolute_error: 1.0230 - val_loss: 47.8152 - val_mean_absolute_error: 1.0227\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 46.8989 - mean_absolute_error: 1.0230 - val_loss: 48.6154 - val_mean_absolute_error: 1.0227\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 47.9163 - mean_absolute_error: 1.0230 - val_loss: 49.3043 - val_mean_absolute_error: 1.0227\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 48.4701 - mean_absolute_error: 1.0230 - val_loss: 49.9067 - val_mean_absolute_error: 1.0227\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 48.9797 - mean_absolute_error: 1.0230 - val_loss: 50.7683 - val_mean_absolute_error: 1.0227\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 49.8360 - mean_absolute_error: 1.0230 - val_loss: 51.6242 - val_mean_absolute_error: 1.0227\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 50.6339 - mean_absolute_error: 1.0230 - val_loss: 52.3687 - val_mean_absolute_error: 1.0227\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 51.5754 - mean_absolute_error: 1.0230 - val_loss: 52.9961 - val_mean_absolute_error: 1.0227\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 52.2210 - mean_absolute_error: 1.0230 - val_loss: 53.8119 - val_mean_absolute_error: 1.0227\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 52.9082 - mean_absolute_error: 1.0230 - val_loss: 54.5856 - val_mean_absolute_error: 1.0227\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 53.7964 - mean_absolute_error: 1.0230 - val_loss: 55.5166 - val_mean_absolute_error: 1.0227\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 54.5190 - mean_absolute_error: 1.0230 - val_loss: 56.3237 - val_mean_absolute_error: 1.0227\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 55.1183 - mean_absolute_error: 1.0230 - val_loss: 57.0109 - val_mean_absolute_error: 1.0227\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 56.0006 - mean_absolute_error: 1.0230 - val_loss: 57.9186 - val_mean_absolute_error: 1.0227\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 56.7594 - mean_absolute_error: 1.0230 - val_loss: 58.6857 - val_mean_absolute_error: 1.0227\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 6s 45ms/step - loss: 57.3887 - mean_absolute_error: 1.0230 - val_loss: 59.5765 - val_mean_absolute_error: 1.0227\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 58.4423 - mean_absolute_error: 1.0230 - val_loss: 60.2582 - val_mean_absolute_error: 1.0227\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 58.6854 - mean_absolute_error: 1.0230 - val_loss: 60.9162 - val_mean_absolute_error: 1.0227\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 59.5976 - mean_absolute_error: 1.0230 - val_loss: 61.8083 - val_mean_absolute_error: 1.0227\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 60.3440 - mean_absolute_error: 1.0230 - val_loss: 62.6804 - val_mean_absolute_error: 1.0227\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 61.3197 - mean_absolute_error: 1.0230 - val_loss: 63.1701 - val_mean_absolute_error: 1.0227\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 62.0264 - mean_absolute_error: 1.0230 - val_loss: 63.8408 - val_mean_absolute_error: 1.0227\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 62.5442 - mean_absolute_error: 1.0230 - val_loss: 64.7073 - val_mean_absolute_error: 1.0227\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 63.2901 - mean_absolute_error: 1.0230 - val_loss: 65.2736 - val_mean_absolute_error: 1.0227\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 63.9289 - mean_absolute_error: 1.0230 - val_loss: 66.1471 - val_mean_absolute_error: 1.0227\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 64.7121 - mean_absolute_error: 1.0230 - val_loss: 66.8343 - val_mean_absolute_error: 1.0227\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 65.4760 - mean_absolute_error: 1.0230 - val_loss: 67.6832 - val_mean_absolute_error: 1.0227\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 66.2870 - mean_absolute_error: 1.0230 - val_loss: 68.3662 - val_mean_absolute_error: 1.0227\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 66.9037 - mean_absolute_error: 1.0230 - val_loss: 69.0753 - val_mean_absolute_error: 1.0227\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 67.4356 - mean_absolute_error: 1.0230 - val_loss: 69.7803 - val_mean_absolute_error: 1.0227\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 68.4074 - mean_absolute_error: 1.0230 - val_loss: 70.6424 - val_mean_absolute_error: 1.0227\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 69.0624 - mean_absolute_error: 1.0230 - val_loss: 71.4148 - val_mean_absolute_error: 1.0227\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 69.7610 - mean_absolute_error: 1.0230 - val_loss: 72.2178 - val_mean_absolute_error: 1.0227\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 67.7075 - mean_absolute_error: 1.0230 - val_loss: 72.6036 - val_mean_absolute_error: 1.0227\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 71.2362 - mean_absolute_error: 1.0230 - val_loss: 73.6809 - val_mean_absolute_error: 1.0227\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 72.1081 - mean_absolute_error: 1.0230 - val_loss: 74.2840 - val_mean_absolute_error: 1.0227\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 72.6170 - mean_absolute_error: 1.0230 - val_loss: 75.1298 - val_mean_absolute_error: 1.0227\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 73.3059 - mean_absolute_error: 1.0230 - val_loss: 76.0732 - val_mean_absolute_error: 1.0227\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 6s 44ms/step - loss: 74.2378 - mean_absolute_error: 1.0230 - val_loss: 76.7429 - val_mean_absolute_error: 1.0227\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 74.9615 - mean_absolute_error: 1.0230 - val_loss: 77.5922 - val_mean_absolute_error: 1.0227\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 75.7894 - mean_absolute_error: 1.0230 - val_loss: 78.1996 - val_mean_absolute_error: 1.0227\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 76.3024 - mean_absolute_error: 1.0230 - val_loss: 79.0917 - val_mean_absolute_error: 1.0227\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 77.1663 - mean_absolute_error: 1.0230 - val_loss: 79.7746 - val_mean_absolute_error: 1.0227\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 78.0853 - mean_absolute_error: 1.0230 - val_loss: 80.5418 - val_mean_absolute_error: 1.0227\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 78.5750 - mean_absolute_error: 1.0230 - val_loss: 81.4035 - val_mean_absolute_error: 1.0227\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 79.4727 - mean_absolute_error: 1.0230 - val_loss: 82.1857 - val_mean_absolute_error: 1.0227\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 80.2206 - mean_absolute_error: 1.0230 - val_loss: 82.9273 - val_mean_absolute_error: 1.0227\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 6s 44ms/step - loss: 81.1123 - mean_absolute_error: 1.0230 - val_loss: 83.8184 - val_mean_absolute_error: 1.0227\n",
      "Wall time: 9min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 10min\n",
    "#we train the model\n",
    "res, model = mlm_fixed_glove(padded_train, train_labels, padded_validate, val_labels)\n",
    "#we save models to files to free up working memory\n",
    "model_name = 'Data/MLMs/mlm_model_glove'\n",
    "model.save(model_name + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal BERT Multilabel Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlm_fixed_bert(train_X, train_y, test_X, test_y):\n",
    "    # build the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Input(shape=(128, 512,)))\n",
    "    #LSTM layer\n",
    "    model.add(Bidirectional(LSTM(100)))\n",
    "    #dropout layer\n",
    "    model.add(Dropout(0.1))\n",
    "    #output layer\n",
    "    model.add(Dense(9, activation='sigmoid'))\n",
    "    \n",
    "    model.build()\n",
    "    # compile the model\n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['mean_absolute_error'])\n",
    "    # summarize the model\n",
    "    print(model.summary())\n",
    "    # fit the model\n",
    "    out = model.fit(train_X, train_y, \n",
    "                    validation_data=[test_X,test_y],\n",
    "                    batch_size=32, \n",
    "                    epochs=100, \n",
    "                    verbose=0)\n",
    "    return out, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_3 (Bidirectio  (None, 200)              490400    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 9)                 1809      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492,209\n",
      "Trainable params: 492,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 25s 186ms/step - loss: 6.9779 - mean_absolute_error: 0.9855 - val_loss: 6.9714 - val_mean_absolute_error: 1.0227\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 7.4578 - mean_absolute_error: 1.0230 - val_loss: 7.9266 - val_mean_absolute_error: 1.0227\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 8.3635 - mean_absolute_error: 1.0230 - val_loss: 8.3559 - val_mean_absolute_error: 1.0227\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 8.7939 - mean_absolute_error: 1.0230 - val_loss: 9.3177 - val_mean_absolute_error: 1.0227\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 10.0786 - mean_absolute_error: 1.0230 - val_loss: 9.9766 - val_mean_absolute_error: 1.0227\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 10.5633 - mean_absolute_error: 1.0230 - val_loss: 11.0913 - val_mean_absolute_error: 1.0227\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 11.4666 - mean_absolute_error: 1.0230 - val_loss: 12.0514 - val_mean_absolute_error: 1.0227\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 12.6248 - mean_absolute_error: 1.0230 - val_loss: 12.7402 - val_mean_absolute_error: 1.0227\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 13.4009 - mean_absolute_error: 1.0230 - val_loss: 13.7552 - val_mean_absolute_error: 1.0227\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 14.3747 - mean_absolute_error: 1.0230 - val_loss: 14.7433 - val_mean_absolute_error: 1.0227\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 15.4526 - mean_absolute_error: 1.0230 - val_loss: 15.8124 - val_mean_absolute_error: 1.0227\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 16.2879 - mean_absolute_error: 1.0230 - val_loss: 16.4323 - val_mean_absolute_error: 1.0227\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 17.2805 - mean_absolute_error: 1.0230 - val_loss: 17.4995 - val_mean_absolute_error: 1.0227\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 18.0477 - mean_absolute_error: 1.0230 - val_loss: 18.2599 - val_mean_absolute_error: 1.0227\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 18.9892 - mean_absolute_error: 1.0230 - val_loss: 18.8238 - val_mean_absolute_error: 1.0227\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 19.5935 - mean_absolute_error: 1.0230 - val_loss: 19.9524 - val_mean_absolute_error: 1.0227\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 20.8782 - mean_absolute_error: 1.0230 - val_loss: 20.8645 - val_mean_absolute_error: 1.0227\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 21.7374 - mean_absolute_error: 1.0230 - val_loss: 21.8768 - val_mean_absolute_error: 1.0227\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 22.4322 - mean_absolute_error: 1.0230 - val_loss: 22.4412 - val_mean_absolute_error: 1.0227\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 23.3107 - mean_absolute_error: 1.0230 - val_loss: 23.8779 - val_mean_absolute_error: 1.0227\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 24.6206 - mean_absolute_error: 1.0230 - val_loss: 24.7665 - val_mean_absolute_error: 1.0227\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 25.1926 - mean_absolute_error: 1.0230 - val_loss: 25.1085 - val_mean_absolute_error: 1.0227\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 26.1666 - mean_absolute_error: 1.0230 - val_loss: 26.2397 - val_mean_absolute_error: 1.0227\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 26.7854 - mean_absolute_error: 1.0230 - val_loss: 27.1445 - val_mean_absolute_error: 1.0227\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 27.4955 - mean_absolute_error: 1.0230 - val_loss: 27.8047 - val_mean_absolute_error: 1.0227\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 28.5215 - mean_absolute_error: 1.0230 - val_loss: 28.8368 - val_mean_absolute_error: 1.0227\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 29.6424 - mean_absolute_error: 1.0230 - val_loss: 30.9982 - val_mean_absolute_error: 1.0227\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 30.5731 - mean_absolute_error: 1.0230 - val_loss: 31.0144 - val_mean_absolute_error: 1.0227\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 31.2031 - mean_absolute_error: 1.0230 - val_loss: 31.2710 - val_mean_absolute_error: 1.0227\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 32.0825 - mean_absolute_error: 1.0230 - val_loss: 32.0653 - val_mean_absolute_error: 1.0227\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 33.0474 - mean_absolute_error: 1.0230 - val_loss: 33.1015 - val_mean_absolute_error: 1.0227\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 33.7201 - mean_absolute_error: 1.0230 - val_loss: 33.7238 - val_mean_absolute_error: 1.0227\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 34.8239 - mean_absolute_error: 1.0230 - val_loss: 34.9876 - val_mean_absolute_error: 1.0227\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 35.6618 - mean_absolute_error: 1.0230 - val_loss: 35.8970 - val_mean_absolute_error: 1.0227\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 36.7248 - mean_absolute_error: 1.0230 - val_loss: 37.0034 - val_mean_absolute_error: 1.0227\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 37.6389 - mean_absolute_error: 1.0230 - val_loss: 37.7204 - val_mean_absolute_error: 1.0227\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 38.0931 - mean_absolute_error: 1.0230 - val_loss: 39.2600 - val_mean_absolute_error: 1.0227\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 39.1935 - mean_absolute_error: 1.0230 - val_loss: 39.6312 - val_mean_absolute_error: 1.0227\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 40.2835 - mean_absolute_error: 1.0230 - val_loss: 41.0580 - val_mean_absolute_error: 1.0227\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 40.9492 - mean_absolute_error: 1.0230 - val_loss: 41.9157 - val_mean_absolute_error: 1.0227\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 41.7882 - mean_absolute_error: 1.0230 - val_loss: 42.3752 - val_mean_absolute_error: 1.0227\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 42.3658 - mean_absolute_error: 1.0230 - val_loss: 42.8417 - val_mean_absolute_error: 1.0227\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 43.0776 - mean_absolute_error: 1.0230 - val_loss: 43.8362 - val_mean_absolute_error: 1.0227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 44.0475 - mean_absolute_error: 1.0230 - val_loss: 45.1243 - val_mean_absolute_error: 1.0227\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 44.7830 - mean_absolute_error: 1.0230 - val_loss: 44.6932 - val_mean_absolute_error: 1.0227\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 46.2834 - mean_absolute_error: 1.0230 - val_loss: 45.5488 - val_mean_absolute_error: 1.0227\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 46.8073 - mean_absolute_error: 1.0230 - val_loss: 47.4560 - val_mean_absolute_error: 1.0227\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 47.5903 - mean_absolute_error: 1.0230 - val_loss: 48.2891 - val_mean_absolute_error: 1.0227\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 48.2182 - mean_absolute_error: 1.0230 - val_loss: 48.7928 - val_mean_absolute_error: 1.0227\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 49.1999 - mean_absolute_error: 1.0230 - val_loss: 49.4923 - val_mean_absolute_error: 1.0227\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 50.2922 - mean_absolute_error: 1.0230 - val_loss: 49.3302 - val_mean_absolute_error: 1.0227\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 51.4778 - mean_absolute_error: 1.0230 - val_loss: 51.2912 - val_mean_absolute_error: 1.0227\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 52.1402 - mean_absolute_error: 1.0230 - val_loss: 52.3484 - val_mean_absolute_error: 1.0227\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 52.8638 - mean_absolute_error: 1.0230 - val_loss: 53.2028 - val_mean_absolute_error: 1.0227\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 53.7670 - mean_absolute_error: 1.0230 - val_loss: 54.3317 - val_mean_absolute_error: 1.0227\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 54.3890 - mean_absolute_error: 1.0230 - val_loss: 55.1476 - val_mean_absolute_error: 1.0227\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 54.4706 - mean_absolute_error: 1.0230 - val_loss: 55.4023 - val_mean_absolute_error: 1.0227\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 55.8399 - mean_absolute_error: 1.0230 - val_loss: 57.1929 - val_mean_absolute_error: 1.0227\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 56.8592 - mean_absolute_error: 1.0230 - val_loss: 57.5057 - val_mean_absolute_error: 1.0227\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 58.1482 - mean_absolute_error: 1.0230 - val_loss: 57.8149 - val_mean_absolute_error: 1.0227\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 58.7214 - mean_absolute_error: 1.0230 - val_loss: 59.0127 - val_mean_absolute_error: 1.0227\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 59.3153 - mean_absolute_error: 1.0230 - val_loss: 59.7696 - val_mean_absolute_error: 1.0227\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 60.6536 - mean_absolute_error: 1.0230 - val_loss: 60.9423 - val_mean_absolute_error: 1.0227\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 61.1156 - mean_absolute_error: 1.0230 - val_loss: 62.4416 - val_mean_absolute_error: 1.0227\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 62.0052 - mean_absolute_error: 1.0230 - val_loss: 63.0378 - val_mean_absolute_error: 1.0227\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 62.8687 - mean_absolute_error: 1.0230 - val_loss: 64.6520 - val_mean_absolute_error: 1.0227\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 64.1515 - mean_absolute_error: 1.0230 - val_loss: 66.1102 - val_mean_absolute_error: 1.0227\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 64.7947 - mean_absolute_error: 1.0230 - val_loss: 68.3673 - val_mean_absolute_error: 1.0227\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 66.4206 - mean_absolute_error: 1.0230 - val_loss: 66.1433 - val_mean_absolute_error: 1.0227\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 66.5816 - mean_absolute_error: 1.0230 - val_loss: 67.2705 - val_mean_absolute_error: 1.0227\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 68.1960 - mean_absolute_error: 1.0230 - val_loss: 67.2350 - val_mean_absolute_error: 1.0227\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 68.5728 - mean_absolute_error: 1.0230 - val_loss: 70.7595 - val_mean_absolute_error: 1.0227\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 70.0696 - mean_absolute_error: 1.0230 - val_loss: 68.5141 - val_mean_absolute_error: 1.0227\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 72.3293 - mean_absolute_error: 1.0230 - val_loss: 71.6658 - val_mean_absolute_error: 1.0227\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 72.4296 - mean_absolute_error: 1.0230 - val_loss: 72.8026 - val_mean_absolute_error: 1.0227\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 73.5985 - mean_absolute_error: 1.0230 - val_loss: 73.5864 - val_mean_absolute_error: 1.0227\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 74.1401 - mean_absolute_error: 1.0230 - val_loss: 74.3016 - val_mean_absolute_error: 1.0227\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 74.4337 - mean_absolute_error: 1.0230 - val_loss: 76.3283 - val_mean_absolute_error: 1.0227\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 75.0824 - mean_absolute_error: 1.0230 - val_loss: 77.4390 - val_mean_absolute_error: 1.0227\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 75.3037 - mean_absolute_error: 1.0230 - val_loss: 77.7174 - val_mean_absolute_error: 1.0227\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 76.0550 - mean_absolute_error: 1.0230 - val_loss: 74.9619 - val_mean_absolute_error: 1.0227\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 77.2923 - mean_absolute_error: 1.0230 - val_loss: 79.8554 - val_mean_absolute_error: 1.0227\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 79.2988 - mean_absolute_error: 1.0230 - val_loss: 81.5496 - val_mean_absolute_error: 1.0227\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 79.5389 - mean_absolute_error: 1.0230 - val_loss: 81.4484 - val_mean_absolute_error: 1.0227\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 80.8963 - mean_absolute_error: 1.0230 - val_loss: 81.7863 - val_mean_absolute_error: 1.0227\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 81.8204 - mean_absolute_error: 1.0230 - val_loss: 84.8305 - val_mean_absolute_error: 1.0227\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 83.4072 - mean_absolute_error: 1.0230 - val_loss: 84.2061 - val_mean_absolute_error: 1.0227\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 83.5561 - mean_absolute_error: 1.0230 - val_loss: 84.9101 - val_mean_absolute_error: 1.0227\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 85.3590 - mean_absolute_error: 1.0230 - val_loss: 87.3708 - val_mean_absolute_error: 1.0227\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 85.0699 - mean_absolute_error: 1.0230 - val_loss: 87.3215 - val_mean_absolute_error: 1.0227\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 86.1778 - mean_absolute_error: 1.0230 - val_loss: 88.8988 - val_mean_absolute_error: 1.0227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 86.9619 - mean_absolute_error: 1.0230 - val_loss: 88.0046 - val_mean_absolute_error: 1.0227\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 87.5360 - mean_absolute_error: 1.0230 - val_loss: 90.5209 - val_mean_absolute_error: 1.0227\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 88.4170 - mean_absolute_error: 1.0230 - val_loss: 91.0330 - val_mean_absolute_error: 1.0227\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 89.3112 - mean_absolute_error: 1.0230 - val_loss: 82.1532 - val_mean_absolute_error: 1.0227\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 90.4441 - mean_absolute_error: 1.0230 - val_loss: 86.7196 - val_mean_absolute_error: 1.0227\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 91.1776 - mean_absolute_error: 1.0230 - val_loss: 88.2282 - val_mean_absolute_error: 1.0227\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 92.4124 - mean_absolute_error: 1.0230 - val_loss: 87.3619 - val_mean_absolute_error: 1.0227\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 93.1450 - mean_absolute_error: 1.0230 - val_loss: 89.5957 - val_mean_absolute_error: 1.0227\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 93.5759 - mean_absolute_error: 1.0230 - val_loss: 92.7837 - val_mean_absolute_error: 1.0227\n",
      "Wall time: 39min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 45min\n",
    "#we train the model\n",
    "res, model = mlm_fixed_bert(train_outputs[\"sequence_output\"], train_labels, val_outputs[\"sequence_output\"], val_labels)\n",
    "#we save models to files to free up working memory\n",
    "model_name = 'Data/MLMs/mlm_model_bert'\n",
    "model.save(model_name + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilabel Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan nan nan nan nan nan nan nan]\n"
     ]
    }
   ],
   "source": [
    " #generate predictions with the per-schema models\n",
    "def predict_schema_mlm(test_text, test_labels, model_name):\n",
    "    model_name = \"Data/MLMs/mlm_model_\" + model_name\n",
    "    #print(model_name)\n",
    "    model = keras.models.load_model(model_name + '.h5')\n",
    "    all_preds = model.predict(test_text)\n",
    "    #print(all_preds)\n",
    "    #print(test_labels)\n",
    "    all_gofs = gof_spear(all_preds,test_labels)\n",
    "    return all_gofs,all_preds\n",
    "\n",
    "output_mlm_glove,idx_mlm_glove = predict_schema_mlm(padded_test,test_labels, \"glove\")\n",
    "print(output_mlm_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Per-Schema RNNs\n",
    "> We also train separate RNNs per schema. For this, we can use the output layer to compute a probability for each of the four possible labels. This way, the labels are treated as separate classes. We take over the parameter values from the multilabel model for the number of LSTM units, the dropout rate, the loss function, the evaluation metric, the batch size, and the number of epochs. To obtain the probability for each class, the units of the output layer have a softmax activation function. For the evaluation, the class with the highest probability is chosen per model. The resulting models are written to files and loaded again for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define separate models\n",
    "def perschema_models_glove(train_X, train_y, test_X, test_y):\n",
    "    model = Sequential()\n",
    "    e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length, trainable=False)\n",
    "    model.add(e)\n",
    "    model.add(Bidirectional(LSTM(100)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    # compile the model\n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['mean_absolute_error'])\n",
    "    # summarize the model\n",
    "    print(model.summary())\n",
    "    # fit the model\n",
    "    model.fit(train_X, train_y,\n",
    "              validation_data=[test_X,test_y],\n",
    "              batch_size=32, \n",
    "              epochs=100, \n",
    "              verbose=1)\n",
    "    out=model.predict(test_X)\n",
    "    gof,p=scipy.stats.spearmanr(out,test_y,axis=None)\n",
    "    return gof, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 200)              160800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 424,004\n",
      "Trainable params: 161,604\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 4s 24ms/step - loss: 0.8218 - mean_absolute_error: 0.2142 - val_loss: 0.6478 - val_mean_absolute_error: 0.1821\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.6201 - mean_absolute_error: 0.1594 - val_loss: 0.5762 - val_mean_absolute_error: 0.1504\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.5682 - mean_absolute_error: 0.1473 - val_loss: 0.5578 - val_mean_absolute_error: 0.1402\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.5133 - mean_absolute_error: 0.1310 - val_loss: 0.5186 - val_mean_absolute_error: 0.1298\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.4955 - mean_absolute_error: 0.1273 - val_loss: 0.5236 - val_mean_absolute_error: 0.1208\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.4609 - mean_absolute_error: 0.1179 - val_loss: 0.5259 - val_mean_absolute_error: 0.1263\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.4180 - mean_absolute_error: 0.1067 - val_loss: 0.5098 - val_mean_absolute_error: 0.1242\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.3901 - mean_absolute_error: 0.1007 - val_loss: 0.5119 - val_mean_absolute_error: 0.1065\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.3705 - mean_absolute_error: 0.0974 - val_loss: 0.5548 - val_mean_absolute_error: 0.1007\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.3280 - mean_absolute_error: 0.0867 - val_loss: 0.5387 - val_mean_absolute_error: 0.1185\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.2904 - mean_absolute_error: 0.0765 - val_loss: 0.5596 - val_mean_absolute_error: 0.1053\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.2680 - mean_absolute_error: 0.0726 - val_loss: 0.5766 - val_mean_absolute_error: 0.1015\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.2432 - mean_absolute_error: 0.0667 - val_loss: 0.6111 - val_mean_absolute_error: 0.1131\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.2199 - mean_absolute_error: 0.0622 - val_loss: 0.7321 - val_mean_absolute_error: 0.0944\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.1968 - mean_absolute_error: 0.0557 - val_loss: 0.6275 - val_mean_absolute_error: 0.0929\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.1602 - mean_absolute_error: 0.0463 - val_loss: 0.6570 - val_mean_absolute_error: 0.0933\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.1448 - mean_absolute_error: 0.0423 - val_loss: 0.7594 - val_mean_absolute_error: 0.0940\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.1256 - mean_absolute_error: 0.0371 - val_loss: 0.7916 - val_mean_absolute_error: 0.0975\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.1124 - mean_absolute_error: 0.0329 - val_loss: 0.7437 - val_mean_absolute_error: 0.1124\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0928 - mean_absolute_error: 0.0284 - val_loss: 0.8177 - val_mean_absolute_error: 0.0944\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0736 - mean_absolute_error: 0.0226 - val_loss: 0.8400 - val_mean_absolute_error: 0.0978\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.0768 - mean_absolute_error: 0.0230 - val_loss: 0.8582 - val_mean_absolute_error: 0.0931\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.0721 - mean_absolute_error: 0.0215 - val_loss: 0.9524 - val_mean_absolute_error: 0.1067\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.0601 - mean_absolute_error: 0.0188 - val_loss: 0.9588 - val_mean_absolute_error: 0.0866\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0814 - mean_absolute_error: 0.0233 - val_loss: 0.8874 - val_mean_absolute_error: 0.0929\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.0744 - mean_absolute_error: 0.0223 - val_loss: 0.8647 - val_mean_absolute_error: 0.0950\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0448 - mean_absolute_error: 0.0143 - val_loss: 0.9574 - val_mean_absolute_error: 0.0912\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0479 - mean_absolute_error: 0.0144 - val_loss: 1.0319 - val_mean_absolute_error: 0.0846\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0451 - mean_absolute_error: 0.0134 - val_loss: 1.0272 - val_mean_absolute_error: 0.0954\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0343 - mean_absolute_error: 0.0104 - val_loss: 1.0161 - val_mean_absolute_error: 0.0880\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0320 - mean_absolute_error: 0.0097 - val_loss: 1.0501 - val_mean_absolute_error: 0.0936\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0394 - mean_absolute_error: 0.0105 - val_loss: 1.0133 - val_mean_absolute_error: 0.0910\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0631 - mean_absolute_error: 0.0184 - val_loss: 0.9729 - val_mean_absolute_error: 0.1033\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0517 - mean_absolute_error: 0.0153 - val_loss: 1.0286 - val_mean_absolute_error: 0.0916\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0350 - mean_absolute_error: 0.0110 - val_loss: 0.9736 - val_mean_absolute_error: 0.0965\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0268 - mean_absolute_error: 0.0080 - val_loss: 1.0642 - val_mean_absolute_error: 0.0998\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0318 - mean_absolute_error: 0.0099 - val_loss: 1.0667 - val_mean_absolute_error: 0.0897\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0268 - mean_absolute_error: 0.0083 - val_loss: 1.1070 - val_mean_absolute_error: 0.0960\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0214 - mean_absolute_error: 0.0065 - val_loss: 1.1644 - val_mean_absolute_error: 0.0952\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0234 - mean_absolute_error: 0.0070 - val_loss: 1.2030 - val_mean_absolute_error: 0.0864\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0244 - mean_absolute_error: 0.0072 - val_loss: 1.1074 - val_mean_absolute_error: 0.0924\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0222 - mean_absolute_error: 0.0061 - val_loss: 1.2061 - val_mean_absolute_error: 0.0912\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0197 - mean_absolute_error: 0.0056 - val_loss: 1.3383 - val_mean_absolute_error: 0.0892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0157 - mean_absolute_error: 0.0045 - val_loss: 1.2082 - val_mean_absolute_error: 0.0969\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0171 - mean_absolute_error: 0.0050 - val_loss: 1.2837 - val_mean_absolute_error: 0.0938\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.0187 - mean_absolute_error: 0.0050 - val_loss: 1.2143 - val_mean_absolute_error: 0.0921\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0623 - mean_absolute_error: 0.0151 - val_loss: 1.0820 - val_mean_absolute_error: 0.1185\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0752 - mean_absolute_error: 0.0208 - val_loss: 0.9949 - val_mean_absolute_error: 0.0931\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0304 - mean_absolute_error: 0.0098 - val_loss: 1.0481 - val_mean_absolute_error: 0.0947\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0180 - mean_absolute_error: 0.0056 - val_loss: 1.0796 - val_mean_absolute_error: 0.1015\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0166 - mean_absolute_error: 0.0050 - val_loss: 1.1020 - val_mean_absolute_error: 0.0945\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0144 - mean_absolute_error: 0.0044 - val_loss: 1.1399 - val_mean_absolute_error: 0.0974\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0135 - mean_absolute_error: 0.0041 - val_loss: 1.1093 - val_mean_absolute_error: 0.1009\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0115 - mean_absolute_error: 0.0038 - val_loss: 1.1507 - val_mean_absolute_error: 0.1016\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0309 - mean_absolute_error: 0.0083 - val_loss: 1.1286 - val_mean_absolute_error: 0.0960\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0524 - mean_absolute_error: 0.0146 - val_loss: 1.1214 - val_mean_absolute_error: 0.0904\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0362 - mean_absolute_error: 0.0104 - val_loss: 1.0683 - val_mean_absolute_error: 0.0893\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0215 - mean_absolute_error: 0.0067 - val_loss: 1.1363 - val_mean_absolute_error: 0.0972\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0141 - mean_absolute_error: 0.0044 - val_loss: 1.1073 - val_mean_absolute_error: 0.1007\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0139 - mean_absolute_error: 0.0042 - val_loss: 1.2120 - val_mean_absolute_error: 0.0938\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0116 - mean_absolute_error: 0.0033 - val_loss: 1.2713 - val_mean_absolute_error: 0.0909\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0126 - mean_absolute_error: 0.0033 - val_loss: 1.2591 - val_mean_absolute_error: 0.0895\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0120 - mean_absolute_error: 0.0035 - val_loss: 1.2357 - val_mean_absolute_error: 0.0928\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0124 - mean_absolute_error: 0.0033 - val_loss: 1.2971 - val_mean_absolute_error: 0.0904\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0144 - mean_absolute_error: 0.0040 - val_loss: 1.2763 - val_mean_absolute_error: 0.0908\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0165 - mean_absolute_error: 0.0043 - val_loss: 1.2308 - val_mean_absolute_error: 0.0941\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0129 - mean_absolute_error: 0.0034 - val_loss: 1.2209 - val_mean_absolute_error: 0.0953\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0139 - mean_absolute_error: 0.0038 - val_loss: 1.2544 - val_mean_absolute_error: 0.0934\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0136 - mean_absolute_error: 0.0036 - val_loss: 1.2959 - val_mean_absolute_error: 0.0919\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0118 - mean_absolute_error: 0.0030 - val_loss: 1.1951 - val_mean_absolute_error: 0.0983\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.0120 - mean_absolute_error: 0.0035 - val_loss: 1.2233 - val_mean_absolute_error: 0.0949\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0142 - mean_absolute_error: 0.0037 - val_loss: 1.2538 - val_mean_absolute_error: 0.0937\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0288 - mean_absolute_error: 0.0077 - val_loss: 1.2011 - val_mean_absolute_error: 0.1057\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0183 - mean_absolute_error: 0.0057 - val_loss: 1.3313 - val_mean_absolute_error: 0.0944\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0314 - mean_absolute_error: 0.0090 - val_loss: 1.2549 - val_mean_absolute_error: 0.1027\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0219 - mean_absolute_error: 0.0064 - val_loss: 1.2602 - val_mean_absolute_error: 0.0917\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0454 - mean_absolute_error: 0.0111 - val_loss: 1.0789 - val_mean_absolute_error: 0.0981\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0224 - mean_absolute_error: 0.0066 - val_loss: 1.2507 - val_mean_absolute_error: 0.0872\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0151 - mean_absolute_error: 0.0047 - val_loss: 1.2173 - val_mean_absolute_error: 0.0923\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0105 - mean_absolute_error: 0.0031 - val_loss: 1.2313 - val_mean_absolute_error: 0.0929\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0109 - mean_absolute_error: 0.0031 - val_loss: 1.2228 - val_mean_absolute_error: 0.0904\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0097 - mean_absolute_error: 0.0027 - val_loss: 1.2863 - val_mean_absolute_error: 0.0946\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0113 - mean_absolute_error: 0.0032 - val_loss: 1.2846 - val_mean_absolute_error: 0.0906\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.0100 - mean_absolute_error: 0.0028 - val_loss: 1.2572 - val_mean_absolute_error: 0.0952\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.0095 - mean_absolute_error: 0.0026 - val_loss: 1.2845 - val_mean_absolute_error: 0.0920\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.0118 - mean_absolute_error: 0.0031 - val_loss: 1.2707 - val_mean_absolute_error: 0.0932\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.0100 - mean_absolute_error: 0.0025 - val_loss: 1.2557 - val_mean_absolute_error: 0.0913\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.0100 - mean_absolute_error: 0.0027 - val_loss: 1.3086 - val_mean_absolute_error: 0.0891\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.0106 - mean_absolute_error: 0.0028 - val_loss: 1.2521 - val_mean_absolute_error: 0.0934\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0078 - mean_absolute_error: 0.0023 - val_loss: 1.3368 - val_mean_absolute_error: 0.0925\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.0108 - mean_absolute_error: 0.0026 - val_loss: 1.3118 - val_mean_absolute_error: 0.0906\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 3s 22ms/step - loss: 0.0092 - mean_absolute_error: 0.0024 - val_loss: 1.3186 - val_mean_absolute_error: 0.0948\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0218 - mean_absolute_error: 0.0051 - val_loss: 1.2442 - val_mean_absolute_error: 0.1027\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0526 - mean_absolute_error: 0.0135 - val_loss: 1.2579 - val_mean_absolute_error: 0.0937\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0191 - mean_absolute_error: 0.0058 - val_loss: 1.2323 - val_mean_absolute_error: 0.0947\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0149 - mean_absolute_error: 0.0043 - val_loss: 1.2401 - val_mean_absolute_error: 0.0944\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0114 - mean_absolute_error: 0.0034 - val_loss: 1.2876 - val_mean_absolute_error: 0.0906\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0107 - mean_absolute_error: 0.0030 - val_loss: 1.2894 - val_mean_absolute_error: 0.0941\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0103 - mean_absolute_error: 0.0027 - val_loss: 1.3429 - val_mean_absolute_error: 0.0905\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0088 - mean_absolute_error: 0.0025 - val_loss: 1.3670 - val_mean_absolute_error: 0.0957\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional_7 (Bidirectio  (None, 200)              160800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 424,004\n",
      "Trainable params: 161,604\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 4s 24ms/step - loss: 0.7062 - mean_absolute_error: 0.1852 - val_loss: 0.6124 - val_mean_absolute_error: 0.1413\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.5274 - mean_absolute_error: 0.1321 - val_loss: 0.5628 - val_mean_absolute_error: 0.1340\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.4916 - mean_absolute_error: 0.1224 - val_loss: 0.5230 - val_mean_absolute_error: 0.1283\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.4546 - mean_absolute_error: 0.1143 - val_loss: 0.5121 - val_mean_absolute_error: 0.1189\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 3s 20ms/step - loss: 0.4230 - mean_absolute_error: 0.1057 - val_loss: 0.5058 - val_mean_absolute_error: 0.1207\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 3s 20ms/step - loss: 0.3934 - mean_absolute_error: 0.0996 - val_loss: 0.5206 - val_mean_absolute_error: 0.1231\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.3697 - mean_absolute_error: 0.0927 - val_loss: 0.5093 - val_mean_absolute_error: 0.1088\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.3526 - mean_absolute_error: 0.0897 - val_loss: 0.5055 - val_mean_absolute_error: 0.1102\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.3119 - mean_absolute_error: 0.0804 - val_loss: 0.5191 - val_mean_absolute_error: 0.1004\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.2942 - mean_absolute_error: 0.0744 - val_loss: 0.5056 - val_mean_absolute_error: 0.1123\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.2625 - mean_absolute_error: 0.0697 - val_loss: 0.5572 - val_mean_absolute_error: 0.0897\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.2405 - mean_absolute_error: 0.0631 - val_loss: 0.5199 - val_mean_absolute_error: 0.0954\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.2174 - mean_absolute_error: 0.0581 - val_loss: 0.5450 - val_mean_absolute_error: 0.0990\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.1891 - mean_absolute_error: 0.0519 - val_loss: 0.5725 - val_mean_absolute_error: 0.1062\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.1707 - mean_absolute_error: 0.0475 - val_loss: 0.5812 - val_mean_absolute_error: 0.0975\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.1390 - mean_absolute_error: 0.0392 - val_loss: 0.6558 - val_mean_absolute_error: 0.0925\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.1213 - mean_absolute_error: 0.0356 - val_loss: 0.6729 - val_mean_absolute_error: 0.0934\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0998 - mean_absolute_error: 0.0291 - val_loss: 0.7274 - val_mean_absolute_error: 0.0946\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0960 - mean_absolute_error: 0.0280 - val_loss: 0.6948 - val_mean_absolute_error: 0.0980\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0972 - mean_absolute_error: 0.0288 - val_loss: 0.7408 - val_mean_absolute_error: 0.0935\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0956 - mean_absolute_error: 0.0261 - val_loss: 0.7043 - val_mean_absolute_error: 0.0910\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0733 - mean_absolute_error: 0.0226 - val_loss: 0.8065 - val_mean_absolute_error: 0.0828\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0611 - mean_absolute_error: 0.0187 - val_loss: 0.7430 - val_mean_absolute_error: 0.0869\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0534 - mean_absolute_error: 0.0159 - val_loss: 0.8484 - val_mean_absolute_error: 0.0901\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0501 - mean_absolute_error: 0.0146 - val_loss: 0.7408 - val_mean_absolute_error: 0.0916\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0404 - mean_absolute_error: 0.0127 - val_loss: 0.8502 - val_mean_absolute_error: 0.0829\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0359 - mean_absolute_error: 0.0108 - val_loss: 0.8098 - val_mean_absolute_error: 0.0845\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0339 - mean_absolute_error: 0.0096 - val_loss: 0.8660 - val_mean_absolute_error: 0.0846\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0351 - mean_absolute_error: 0.0115 - val_loss: 0.9271 - val_mean_absolute_error: 0.0841\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0278 - mean_absolute_error: 0.0080 - val_loss: 0.9706 - val_mean_absolute_error: 0.0935\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 3s 20ms/step - loss: 0.0357 - mean_absolute_error: 0.0104 - val_loss: 0.9562 - val_mean_absolute_error: 0.0965\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 3s 20ms/step - loss: 0.0621 - mean_absolute_error: 0.0172 - val_loss: 0.9006 - val_mean_absolute_error: 0.0850\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 3s 20ms/step - loss: 0.0314 - mean_absolute_error: 0.0100 - val_loss: 0.9233 - val_mean_absolute_error: 0.0871\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 3s 20ms/step - loss: 0.0232 - mean_absolute_error: 0.0069 - val_loss: 0.9612 - val_mean_absolute_error: 0.0851\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 3s 20ms/step - loss: 0.0227 - mean_absolute_error: 0.0071 - val_loss: 1.0392 - val_mean_absolute_error: 0.0865\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0192 - mean_absolute_error: 0.0057 - val_loss: 0.9687 - val_mean_absolute_error: 0.0829\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 3s 20ms/step - loss: 0.0191 - mean_absolute_error: 0.0054 - val_loss: 0.9687 - val_mean_absolute_error: 0.0848\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 3s 20ms/step - loss: 0.0207 - mean_absolute_error: 0.0059 - val_loss: 1.0065 - val_mean_absolute_error: 0.0889\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 3s 20ms/step - loss: 0.0165 - mean_absolute_error: 0.0048 - val_loss: 1.0341 - val_mean_absolute_error: 0.0821\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 3s 20ms/step - loss: 0.0170 - mean_absolute_error: 0.0045 - val_loss: 1.0363 - val_mean_absolute_error: 0.0843\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0162 - mean_absolute_error: 0.0045 - val_loss: 1.0170 - val_mean_absolute_error: 0.0802\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0137 - mean_absolute_error: 0.0039 - val_loss: 1.0646 - val_mean_absolute_error: 0.0845\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0153 - mean_absolute_error: 0.0041 - val_loss: 1.2163 - val_mean_absolute_error: 0.0793\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0412 - mean_absolute_error: 0.0102 - val_loss: 1.0508 - val_mean_absolute_error: 0.0959\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.1077 - mean_absolute_error: 0.0262 - val_loss: 0.8506 - val_mean_absolute_error: 0.0894\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0362 - mean_absolute_error: 0.0114 - val_loss: 0.9689 - val_mean_absolute_error: 0.0839\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0210 - mean_absolute_error: 0.0068 - val_loss: 0.9779 - val_mean_absolute_error: 0.0810\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0158 - mean_absolute_error: 0.0048 - val_loss: 1.0148 - val_mean_absolute_error: 0.0853\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0139 - mean_absolute_error: 0.0042 - val_loss: 1.0108 - val_mean_absolute_error: 0.0793\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0150 - mean_absolute_error: 0.0041 - val_loss: 1.0293 - val_mean_absolute_error: 0.0791\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0143 - mean_absolute_error: 0.0039 - val_loss: 1.0432 - val_mean_absolute_error: 0.0810\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0144 - mean_absolute_error: 0.0042 - val_loss: 1.0199 - val_mean_absolute_error: 0.0825\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0136 - mean_absolute_error: 0.0038 - val_loss: 1.0755 - val_mean_absolute_error: 0.0810\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0128 - mean_absolute_error: 0.0038 - val_loss: 1.1502 - val_mean_absolute_error: 0.0772\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0167 - mean_absolute_error: 0.0038 - val_loss: 1.1333 - val_mean_absolute_error: 0.0827\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0133 - mean_absolute_error: 0.0036 - val_loss: 1.1070 - val_mean_absolute_error: 0.0806\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0114 - mean_absolute_error: 0.0032 - val_loss: 1.1438 - val_mean_absolute_error: 0.0773\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0134 - mean_absolute_error: 0.0034 - val_loss: 1.1422 - val_mean_absolute_error: 0.0816\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0112 - mean_absolute_error: 0.0028 - val_loss: 1.1282 - val_mean_absolute_error: 0.0922\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0280 - mean_absolute_error: 0.0071 - val_loss: 1.1425 - val_mean_absolute_error: 0.0847\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0671 - mean_absolute_error: 0.0164 - val_loss: 0.9937 - val_mean_absolute_error: 0.0815\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0527 - mean_absolute_error: 0.0138 - val_loss: 0.9599 - val_mean_absolute_error: 0.0801\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 3s 20ms/step - loss: 0.0195 - mean_absolute_error: 0.0063 - val_loss: 1.0580 - val_mean_absolute_error: 0.0830\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 3s 20ms/step - loss: 0.0160 - mean_absolute_error: 0.0046 - val_loss: 1.0551 - val_mean_absolute_error: 0.0811\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0110 - mean_absolute_error: 0.0037 - val_loss: 1.1344 - val_mean_absolute_error: 0.0783\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0122 - mean_absolute_error: 0.0031 - val_loss: 1.1170 - val_mean_absolute_error: 0.0791\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0098 - mean_absolute_error: 0.0030 - val_loss: 1.1353 - val_mean_absolute_error: 0.0821\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0121 - mean_absolute_error: 0.0033 - val_loss: 1.1384 - val_mean_absolute_error: 0.0815\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0122 - mean_absolute_error: 0.0033 - val_loss: 1.1517 - val_mean_absolute_error: 0.0798\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 3s 20ms/step - loss: 0.0112 - mean_absolute_error: 0.0031 - val_loss: 1.1435 - val_mean_absolute_error: 0.0839\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0115 - mean_absolute_error: 0.0031 - val_loss: 1.2058 - val_mean_absolute_error: 0.0810\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0113 - mean_absolute_error: 0.0029 - val_loss: 1.2185 - val_mean_absolute_error: 0.0818\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0096 - mean_absolute_error: 0.0029 - val_loss: 1.2243 - val_mean_absolute_error: 0.0815\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0101 - mean_absolute_error: 0.0028 - val_loss: 1.2297 - val_mean_absolute_error: 0.0813\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0105 - mean_absolute_error: 0.0028 - val_loss: 1.2347 - val_mean_absolute_error: 0.0861\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0435 - mean_absolute_error: 0.0086 - val_loss: 1.0650 - val_mean_absolute_error: 0.0850\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0822 - mean_absolute_error: 0.0200 - val_loss: 1.0353 - val_mean_absolute_error: 0.0827\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0214 - mean_absolute_error: 0.0072 - val_loss: 1.1051 - val_mean_absolute_error: 0.0828\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0123 - mean_absolute_error: 0.0040 - val_loss: 1.1460 - val_mean_absolute_error: 0.0816\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0124 - mean_absolute_error: 0.0035 - val_loss: 1.1694 - val_mean_absolute_error: 0.0803\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0112 - mean_absolute_error: 0.0034 - val_loss: 1.2122 - val_mean_absolute_error: 0.0803\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0105 - mean_absolute_error: 0.0030 - val_loss: 1.2357 - val_mean_absolute_error: 0.0797\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0111 - mean_absolute_error: 0.0027 - val_loss: 1.1983 - val_mean_absolute_error: 0.0810\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0113 - mean_absolute_error: 0.0028 - val_loss: 1.2187 - val_mean_absolute_error: 0.0819\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0098 - mean_absolute_error: 0.0029 - val_loss: 1.2226 - val_mean_absolute_error: 0.0819\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0103 - mean_absolute_error: 0.0028 - val_loss: 1.2320 - val_mean_absolute_error: 0.0798\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0119 - mean_absolute_error: 0.0029 - val_loss: 1.2491 - val_mean_absolute_error: 0.0798\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0104 - mean_absolute_error: 0.0029 - val_loss: 1.2307 - val_mean_absolute_error: 0.0812\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0092 - mean_absolute_error: 0.0026 - val_loss: 1.2535 - val_mean_absolute_error: 0.0858\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0119 - mean_absolute_error: 0.0030 - val_loss: 1.2760 - val_mean_absolute_error: 0.0768\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0095 - mean_absolute_error: 0.0023 - val_loss: 1.2485 - val_mean_absolute_error: 0.0826\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0104 - mean_absolute_error: 0.0029 - val_loss: 1.2538 - val_mean_absolute_error: 0.0796\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0107 - mean_absolute_error: 0.0028 - val_loss: 1.3267 - val_mean_absolute_error: 0.0817\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0113 - mean_absolute_error: 0.0028 - val_loss: 1.2769 - val_mean_absolute_error: 0.0788\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0114 - mean_absolute_error: 0.0028 - val_loss: 1.2378 - val_mean_absolute_error: 0.0822\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0101 - mean_absolute_error: 0.0027 - val_loss: 1.3161 - val_mean_absolute_error: 0.0855\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0382 - mean_absolute_error: 0.0098 - val_loss: 1.0710 - val_mean_absolute_error: 0.0882\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0483 - mean_absolute_error: 0.0128 - val_loss: 1.1581 - val_mean_absolute_error: 0.0902\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0243 - mean_absolute_error: 0.0071 - val_loss: 1.1013 - val_mean_absolute_error: 0.0972\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 3s 21ms/step - loss: 0.0115 - mean_absolute_error: 0.0036 - val_loss: 1.2321 - val_mean_absolute_error: 0.0814\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional_8 (Bidirectio  (None, 200)              160800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 424,004\n",
      "Trainable params: 161,604\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 5s 26ms/step - loss: 0.7017 - mean_absolute_error: 0.1754 - val_loss: 0.6020 - val_mean_absolute_error: 0.1529\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.5999 - mean_absolute_error: 0.1508 - val_loss: 0.5665 - val_mean_absolute_error: 0.1436\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.5523 - mean_absolute_error: 0.1391 - val_loss: 0.5376 - val_mean_absolute_error: 0.1444\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.5043 - mean_absolute_error: 0.1272 - val_loss: 0.5162 - val_mean_absolute_error: 0.1316\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.4744 - mean_absolute_error: 0.1191 - val_loss: 0.5068 - val_mean_absolute_error: 0.1131\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.4523 - mean_absolute_error: 0.1142 - val_loss: 0.5122 - val_mean_absolute_error: 0.1180\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.4301 - mean_absolute_error: 0.1080 - val_loss: 0.5114 - val_mean_absolute_error: 0.1040\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.3949 - mean_absolute_error: 0.0998 - val_loss: 0.5172 - val_mean_absolute_error: 0.1232\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.3632 - mean_absolute_error: 0.0928 - val_loss: 0.4883 - val_mean_absolute_error: 0.1047\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.3267 - mean_absolute_error: 0.0851 - val_loss: 0.5440 - val_mean_absolute_error: 0.0912\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.2912 - mean_absolute_error: 0.0755 - val_loss: 0.5116 - val_mean_absolute_error: 0.0917\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.2715 - mean_absolute_error: 0.0718 - val_loss: 0.5561 - val_mean_absolute_error: 0.0911\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.2268 - mean_absolute_error: 0.0611 - val_loss: 0.5776 - val_mean_absolute_error: 0.1238\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.2055 - mean_absolute_error: 0.0557 - val_loss: 0.6214 - val_mean_absolute_error: 0.0943\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.1871 - mean_absolute_error: 0.0521 - val_loss: 0.6526 - val_mean_absolute_error: 0.0799\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.1518 - mean_absolute_error: 0.0435 - val_loss: 0.7006 - val_mean_absolute_error: 0.0833\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.1460 - mean_absolute_error: 0.0414 - val_loss: 0.6684 - val_mean_absolute_error: 0.0851\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.1109 - mean_absolute_error: 0.0338 - val_loss: 0.8108 - val_mean_absolute_error: 0.0804\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0987 - mean_absolute_error: 0.0291 - val_loss: 0.7352 - val_mean_absolute_error: 0.0889\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0847 - mean_absolute_error: 0.0251 - val_loss: 0.8162 - val_mean_absolute_error: 0.0846\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0737 - mean_absolute_error: 0.0222 - val_loss: 0.7959 - val_mean_absolute_error: 0.0837\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0720 - mean_absolute_error: 0.0215 - val_loss: 0.8228 - val_mean_absolute_error: 0.0928\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0882 - mean_absolute_error: 0.0255 - val_loss: 0.9122 - val_mean_absolute_error: 0.0851\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0701 - mean_absolute_error: 0.0213 - val_loss: 0.8929 - val_mean_absolute_error: 0.0953\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0480 - mean_absolute_error: 0.0151 - val_loss: 0.8982 - val_mean_absolute_error: 0.0928\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0499 - mean_absolute_error: 0.0149 - val_loss: 0.9389 - val_mean_absolute_error: 0.0910\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0413 - mean_absolute_error: 0.0133 - val_loss: 0.9189 - val_mean_absolute_error: 0.0923\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0331 - mean_absolute_error: 0.0110 - val_loss: 0.9577 - val_mean_absolute_error: 0.0772\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0452 - mean_absolute_error: 0.0128 - val_loss: 0.9978 - val_mean_absolute_error: 0.0970\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0467 - mean_absolute_error: 0.0141 - val_loss: 0.9930 - val_mean_absolute_error: 0.0825\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0309 - mean_absolute_error: 0.0104 - val_loss: 0.9877 - val_mean_absolute_error: 0.0792\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0266 - mean_absolute_error: 0.0084 - val_loss: 1.0769 - val_mean_absolute_error: 0.0768\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0222 - mean_absolute_error: 0.0066 - val_loss: 1.0511 - val_mean_absolute_error: 0.0938\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0446 - mean_absolute_error: 0.0133 - val_loss: 1.1003 - val_mean_absolute_error: 0.0840\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0406 - mean_absolute_error: 0.0118 - val_loss: 0.9673 - val_mean_absolute_error: 0.0860\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0365 - mean_absolute_error: 0.0107 - val_loss: 1.0606 - val_mean_absolute_error: 0.0897\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0265 - mean_absolute_error: 0.0087 - val_loss: 1.0981 - val_mean_absolute_error: 0.0842\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0245 - mean_absolute_error: 0.0079 - val_loss: 1.1348 - val_mean_absolute_error: 0.0781\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0189 - mean_absolute_error: 0.0062 - val_loss: 1.1501 - val_mean_absolute_error: 0.0807\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0148 - mean_absolute_error: 0.0046 - val_loss: 1.1745 - val_mean_absolute_error: 0.0784\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0131 - mean_absolute_error: 0.0037 - val_loss: 1.2384 - val_mean_absolute_error: 0.0773\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0122 - mean_absolute_error: 0.0036 - val_loss: 1.2474 - val_mean_absolute_error: 0.0776\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0108 - mean_absolute_error: 0.0030 - val_loss: 1.2125 - val_mean_absolute_error: 0.0755\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0136 - mean_absolute_error: 0.0037 - val_loss: 1.3027 - val_mean_absolute_error: 0.0768\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0093 - mean_absolute_error: 0.0029 - val_loss: 1.2285 - val_mean_absolute_error: 0.0918\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0149 - mean_absolute_error: 0.0040 - val_loss: 1.2273 - val_mean_absolute_error: 0.0852\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0142 - mean_absolute_error: 0.0044 - val_loss: 1.2672 - val_mean_absolute_error: 0.0759\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0572 - mean_absolute_error: 0.0141 - val_loss: 1.1538 - val_mean_absolute_error: 0.1238\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0580 - mean_absolute_error: 0.0164 - val_loss: 1.0649 - val_mean_absolute_error: 0.0866\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0222 - mean_absolute_error: 0.0067 - val_loss: 1.1034 - val_mean_absolute_error: 0.0802\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0121 - mean_absolute_error: 0.0042 - val_loss: 1.1535 - val_mean_absolute_error: 0.0788\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0199 - mean_absolute_error: 0.0057 - val_loss: 1.0726 - val_mean_absolute_error: 0.0837\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0161 - mean_absolute_error: 0.0050 - val_loss: 1.1795 - val_mean_absolute_error: 0.0840\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0112 - mean_absolute_error: 0.0034 - val_loss: 1.2134 - val_mean_absolute_error: 0.0896\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0104 - mean_absolute_error: 0.0031 - val_loss: 1.2953 - val_mean_absolute_error: 0.0794\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0096 - mean_absolute_error: 0.0024 - val_loss: 1.1907 - val_mean_absolute_error: 0.0827\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0077 - mean_absolute_error: 0.0022 - val_loss: 1.2757 - val_mean_absolute_error: 0.0790\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0100 - mean_absolute_error: 0.0023 - val_loss: 1.3457 - val_mean_absolute_error: 0.0761\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0121 - mean_absolute_error: 0.0032 - val_loss: 1.4154 - val_mean_absolute_error: 0.0711\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0133 - mean_absolute_error: 0.0037 - val_loss: 1.3520 - val_mean_absolute_error: 0.0865\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0460 - mean_absolute_error: 0.0118 - val_loss: 1.2180 - val_mean_absolute_error: 0.0804\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0476 - mean_absolute_error: 0.0129 - val_loss: 1.1637 - val_mean_absolute_error: 0.0825\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0353 - mean_absolute_error: 0.0114 - val_loss: 1.1768 - val_mean_absolute_error: 0.0819\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0111 - mean_absolute_error: 0.0039 - val_loss: 1.2620 - val_mean_absolute_error: 0.0814\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0077 - mean_absolute_error: 0.0025 - val_loss: 1.3396 - val_mean_absolute_error: 0.0831\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0075 - mean_absolute_error: 0.0022 - val_loss: 1.2801 - val_mean_absolute_error: 0.0865\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0073 - mean_absolute_error: 0.0021 - val_loss: 1.3796 - val_mean_absolute_error: 0.0828\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0086 - mean_absolute_error: 0.0022 - val_loss: 1.3210 - val_mean_absolute_error: 0.0789\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0075 - mean_absolute_error: 0.0020 - val_loss: 1.3875 - val_mean_absolute_error: 0.0850\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0073 - mean_absolute_error: 0.0017 - val_loss: 1.3684 - val_mean_absolute_error: 0.0831\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0067 - mean_absolute_error: 0.0019 - val_loss: 1.3643 - val_mean_absolute_error: 0.0832\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0064 - mean_absolute_error: 0.0019 - val_loss: 1.4374 - val_mean_absolute_error: 0.0809\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0059 - mean_absolute_error: 0.0017 - val_loss: 1.4349 - val_mean_absolute_error: 0.0879\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0134 - mean_absolute_error: 0.0036 - val_loss: 1.3270 - val_mean_absolute_error: 0.0787\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0810 - mean_absolute_error: 0.0180 - val_loss: 1.1855 - val_mean_absolute_error: 0.0884\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0264 - mean_absolute_error: 0.0079 - val_loss: 1.1652 - val_mean_absolute_error: 0.0808\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0124 - mean_absolute_error: 0.0040 - val_loss: 1.1548 - val_mean_absolute_error: 0.0816\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0088 - mean_absolute_error: 0.0024 - val_loss: 1.2355 - val_mean_absolute_error: 0.0807\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0091 - mean_absolute_error: 0.0022 - val_loss: 1.2122 - val_mean_absolute_error: 0.0802\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0075 - mean_absolute_error: 0.0021 - val_loss: 1.2833 - val_mean_absolute_error: 0.0849\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0071 - mean_absolute_error: 0.0019 - val_loss: 1.3082 - val_mean_absolute_error: 0.0766\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0064 - mean_absolute_error: 0.0019 - val_loss: 1.3317 - val_mean_absolute_error: 0.0787\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0072 - mean_absolute_error: 0.0021 - val_loss: 1.3012 - val_mean_absolute_error: 0.0793\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0067 - mean_absolute_error: 0.0019 - val_loss: 1.3256 - val_mean_absolute_error: 0.0748\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0063 - mean_absolute_error: 0.0016 - val_loss: 1.3438 - val_mean_absolute_error: 0.0809\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0077 - mean_absolute_error: 0.0020 - val_loss: 1.3888 - val_mean_absolute_error: 0.0850\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0070 - mean_absolute_error: 0.0017 - val_loss: 1.3289 - val_mean_absolute_error: 0.0813\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0074 - mean_absolute_error: 0.0018 - val_loss: 1.4012 - val_mean_absolute_error: 0.0812\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0088 - mean_absolute_error: 0.0021 - val_loss: 1.4119 - val_mean_absolute_error: 0.0781\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0078 - mean_absolute_error: 0.0018 - val_loss: 1.3931 - val_mean_absolute_error: 0.0780\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0068 - mean_absolute_error: 0.0016 - val_loss: 1.3834 - val_mean_absolute_error: 0.0800\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0073 - mean_absolute_error: 0.0019 - val_loss: 1.4757 - val_mean_absolute_error: 0.0761\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0078 - mean_absolute_error: 0.0017 - val_loss: 1.3646 - val_mean_absolute_error: 0.0802\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0075 - mean_absolute_error: 0.0018 - val_loss: 1.3801 - val_mean_absolute_error: 0.0852\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0081 - mean_absolute_error: 0.0017 - val_loss: 1.3568 - val_mean_absolute_error: 0.0799\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0069 - mean_absolute_error: 0.0018 - val_loss: 1.5061 - val_mean_absolute_error: 0.0743\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0075 - mean_absolute_error: 0.0017 - val_loss: 1.3549 - val_mean_absolute_error: 0.0817\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0060 - mean_absolute_error: 0.0015 - val_loss: 1.4393 - val_mean_absolute_error: 0.0797\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0085 - mean_absolute_error: 0.0022 - val_loss: 1.3600 - val_mean_absolute_error: 0.0927\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0971 - mean_absolute_error: 0.0216 - val_loss: 1.0868 - val_mean_absolute_error: 0.0948\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional_9 (Bidirectio  (None, 200)              160800    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 424,004\n",
      "Trainable params: 161,604\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 5s 26ms/step - loss: 0.3017 - mean_absolute_error: 0.0640 - val_loss: 0.2002 - val_mean_absolute_error: 0.0541\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.1816 - mean_absolute_error: 0.0411 - val_loss: 0.1197 - val_mean_absolute_error: 0.0342\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.1426 - mean_absolute_error: 0.0322 - val_loss: 0.1055 - val_mean_absolute_error: 0.0262\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.1370 - mean_absolute_error: 0.0298 - val_loss: 0.0919 - val_mean_absolute_error: 0.0246\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.1236 - mean_absolute_error: 0.0272 - val_loss: 0.1005 - val_mean_absolute_error: 0.0289\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.1120 - mean_absolute_error: 0.0255 - val_loss: 0.0884 - val_mean_absolute_error: 0.0223\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.1033 - mean_absolute_error: 0.0233 - val_loss: 0.0907 - val_mean_absolute_error: 0.0229\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0999 - mean_absolute_error: 0.0230 - val_loss: 0.0893 - val_mean_absolute_error: 0.0235\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0873 - mean_absolute_error: 0.0206 - val_loss: 0.0957 - val_mean_absolute_error: 0.0272\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0827 - mean_absolute_error: 0.0204 - val_loss: 0.0986 - val_mean_absolute_error: 0.0240\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0716 - mean_absolute_error: 0.0179 - val_loss: 0.0942 - val_mean_absolute_error: 0.0195\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0606 - mean_absolute_error: 0.0156 - val_loss: 0.1020 - val_mean_absolute_error: 0.0212\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0504 - mean_absolute_error: 0.0138 - val_loss: 0.1400 - val_mean_absolute_error: 0.0295\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0436 - mean_absolute_error: 0.0121 - val_loss: 0.1259 - val_mean_absolute_error: 0.0253\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0358 - mean_absolute_error: 0.0104 - val_loss: 0.1295 - val_mean_absolute_error: 0.0171\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0410 - mean_absolute_error: 0.0111 - val_loss: 0.1109 - val_mean_absolute_error: 0.0195\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0277 - mean_absolute_error: 0.0086 - val_loss: 0.1164 - val_mean_absolute_error: 0.0178\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0233 - mean_absolute_error: 0.0071 - val_loss: 0.1189 - val_mean_absolute_error: 0.0165\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0171 - mean_absolute_error: 0.0053 - val_loss: 0.1290 - val_mean_absolute_error: 0.0191\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0160 - mean_absolute_error: 0.0052 - val_loss: 0.1440 - val_mean_absolute_error: 0.0196\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0168 - mean_absolute_error: 0.0050 - val_loss: 0.1467 - val_mean_absolute_error: 0.0172\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0131 - mean_absolute_error: 0.0042 - val_loss: 0.1348 - val_mean_absolute_error: 0.0166\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0104 - mean_absolute_error: 0.0034 - val_loss: 0.1369 - val_mean_absolute_error: 0.0171\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0087 - mean_absolute_error: 0.0028 - val_loss: 0.1392 - val_mean_absolute_error: 0.0151\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0080 - mean_absolute_error: 0.0025 - val_loss: 0.1478 - val_mean_absolute_error: 0.0160\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0075 - mean_absolute_error: 0.0024 - val_loss: 0.1616 - val_mean_absolute_error: 0.0194\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0076 - mean_absolute_error: 0.0022 - val_loss: 0.1724 - val_mean_absolute_error: 0.0190\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0249 - mean_absolute_error: 0.0056 - val_loss: 0.1583 - val_mean_absolute_error: 0.0250\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0380 - mean_absolute_error: 0.0094 - val_loss: 0.1269 - val_mean_absolute_error: 0.0198\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0142 - mean_absolute_error: 0.0044 - val_loss: 0.1293 - val_mean_absolute_error: 0.0154\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0119 - mean_absolute_error: 0.0035 - val_loss: 0.1318 - val_mean_absolute_error: 0.0155\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0068 - mean_absolute_error: 0.0023 - val_loss: 0.1449 - val_mean_absolute_error: 0.0181\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0064 - mean_absolute_error: 0.0020 - val_loss: 0.1482 - val_mean_absolute_error: 0.0153\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0057 - mean_absolute_error: 0.0018 - val_loss: 0.1459 - val_mean_absolute_error: 0.0167\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0060 - mean_absolute_error: 0.0018 - val_loss: 0.1492 - val_mean_absolute_error: 0.0170\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0055 - mean_absolute_error: 0.0015 - val_loss: 0.1534 - val_mean_absolute_error: 0.0159\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0056 - mean_absolute_error: 0.0015 - val_loss: 0.1659 - val_mean_absolute_error: 0.0165\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0054 - mean_absolute_error: 0.0016 - val_loss: 0.1473 - val_mean_absolute_error: 0.0160\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0057 - mean_absolute_error: 0.0014 - val_loss: 0.1647 - val_mean_absolute_error: 0.0157\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0047 - mean_absolute_error: 0.0014 - val_loss: 0.1610 - val_mean_absolute_error: 0.0169\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0051 - mean_absolute_error: 0.0013 - val_loss: 0.1765 - val_mean_absolute_error: 0.0170\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0053 - mean_absolute_error: 0.0015 - val_loss: 0.1731 - val_mean_absolute_error: 0.0153\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0049 - mean_absolute_error: 0.0014 - val_loss: 0.1865 - val_mean_absolute_error: 0.0176\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0058 - mean_absolute_error: 0.0012 - val_loss: 0.1688 - val_mean_absolute_error: 0.0156\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0053 - mean_absolute_error: 0.0013 - val_loss: 0.1657 - val_mean_absolute_error: 0.0159\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0048 - mean_absolute_error: 0.0014 - val_loss: 0.1710 - val_mean_absolute_error: 0.0155\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0048 - mean_absolute_error: 0.0011 - val_loss: 0.1779 - val_mean_absolute_error: 0.0168\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0079 - mean_absolute_error: 0.0018 - val_loss: 0.1629 - val_mean_absolute_error: 0.0142\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0259 - mean_absolute_error: 0.0056 - val_loss: 0.1506 - val_mean_absolute_error: 0.0182\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0223 - mean_absolute_error: 0.0059 - val_loss: 0.1560 - val_mean_absolute_error: 0.0190\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0117 - mean_absolute_error: 0.0039 - val_loss: 0.1744 - val_mean_absolute_error: 0.0203\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0052 - mean_absolute_error: 0.0017 - val_loss: 0.1651 - val_mean_absolute_error: 0.0161\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0039 - mean_absolute_error: 0.0011 - val_loss: 0.1670 - val_mean_absolute_error: 0.0167\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0042 - mean_absolute_error: 0.0012 - val_loss: 0.1718 - val_mean_absolute_error: 0.0173\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0045 - mean_absolute_error: 0.0013 - val_loss: 0.1738 - val_mean_absolute_error: 0.0177\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0045 - mean_absolute_error: 0.0012 - val_loss: 0.1768 - val_mean_absolute_error: 0.0151\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0046 - mean_absolute_error: 0.0012 - val_loss: 0.1783 - val_mean_absolute_error: 0.0150\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0036 - mean_absolute_error: 0.0010 - val_loss: 0.1799 - val_mean_absolute_error: 0.0149\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0046 - mean_absolute_error: 0.0011 - val_loss: 0.1817 - val_mean_absolute_error: 0.0176\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0045 - mean_absolute_error: 0.0012 - val_loss: 0.1838 - val_mean_absolute_error: 0.0157\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0049 - mean_absolute_error: 0.0012 - val_loss: 0.1766 - val_mean_absolute_error: 0.0158\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0044 - mean_absolute_error: 0.0010 - val_loss: 0.1858 - val_mean_absolute_error: 0.0165\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0044 - mean_absolute_error: 0.0011 - val_loss: 0.1861 - val_mean_absolute_error: 0.0157\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0041 - mean_absolute_error: 9.0831e-04 - val_loss: 0.1809 - val_mean_absolute_error: 0.0162\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0045 - mean_absolute_error: 0.0010 - val_loss: 0.1974 - val_mean_absolute_error: 0.0167\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0038 - mean_absolute_error: 9.6542e-04 - val_loss: 0.1970 - val_mean_absolute_error: 0.0176\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0047 - mean_absolute_error: 0.0011 - val_loss: 0.1986 - val_mean_absolute_error: 0.0170\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0033 - mean_absolute_error: 9.3711e-04 - val_loss: 0.2104 - val_mean_absolute_error: 0.0171\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0034 - mean_absolute_error: 9.8424e-04 - val_loss: 0.1916 - val_mean_absolute_error: 0.0163\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0041 - mean_absolute_error: 9.5400e-04 - val_loss: 0.1949 - val_mean_absolute_error: 0.0149\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0047 - mean_absolute_error: 0.0011 - val_loss: 0.1914 - val_mean_absolute_error: 0.0171\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0032 - mean_absolute_error: 8.8429e-04 - val_loss: 0.2137 - val_mean_absolute_error: 0.0194\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0047 - mean_absolute_error: 9.0787e-04 - val_loss: 0.1899 - val_mean_absolute_error: 0.0167\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0036 - mean_absolute_error: 0.0010 - val_loss: 0.1840 - val_mean_absolute_error: 0.0157\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0038 - mean_absolute_error: 9.5690e-04 - val_loss: 0.1992 - val_mean_absolute_error: 0.0160\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0036 - mean_absolute_error: 8.8154e-04 - val_loss: 0.2062 - val_mean_absolute_error: 0.0179\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0049 - mean_absolute_error: 0.0011 - val_loss: 0.1930 - val_mean_absolute_error: 0.0152\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0040 - mean_absolute_error: 9.6247e-04 - val_loss: 0.2038 - val_mean_absolute_error: 0.0158\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0050 - mean_absolute_error: 9.6291e-04 - val_loss: 0.2051 - val_mean_absolute_error: 0.0164\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0038 - mean_absolute_error: 9.4313e-04 - val_loss: 0.1928 - val_mean_absolute_error: 0.0153\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0035 - mean_absolute_error: 8.0969e-04 - val_loss: 0.2026 - val_mean_absolute_error: 0.0153\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0113 - mean_absolute_error: 0.0022 - val_loss: 0.1648 - val_mean_absolute_error: 0.0202\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0348 - mean_absolute_error: 0.0079 - val_loss: 0.1467 - val_mean_absolute_error: 0.0157\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0097 - mean_absolute_error: 0.0029 - val_loss: 0.1613 - val_mean_absolute_error: 0.0193\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0042 - mean_absolute_error: 0.0013 - val_loss: 0.1459 - val_mean_absolute_error: 0.0138\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0043 - mean_absolute_error: 0.0012 - val_loss: 0.1521 - val_mean_absolute_error: 0.0143\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0042 - mean_absolute_error: 9.7241e-04 - val_loss: 0.1537 - val_mean_absolute_error: 0.0160\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0036 - mean_absolute_error: 0.0010 - val_loss: 0.1549 - val_mean_absolute_error: 0.0142\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0033 - mean_absolute_error: 0.0010 - val_loss: 0.1549 - val_mean_absolute_error: 0.0147\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 3s 23ms/step - loss: 0.0032 - mean_absolute_error: 0.0010 - val_loss: 0.1531 - val_mean_absolute_error: 0.0137\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0034 - mean_absolute_error: 9.2183e-04 - val_loss: 0.1612 - val_mean_absolute_error: 0.0133\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0041 - mean_absolute_error: 0.0011 - val_loss: 0.1553 - val_mean_absolute_error: 0.0139\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0035 - mean_absolute_error: 9.3324e-04 - val_loss: 0.1634 - val_mean_absolute_error: 0.0159\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0036 - mean_absolute_error: 9.6336e-04 - val_loss: 0.1591 - val_mean_absolute_error: 0.0149\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0036 - mean_absolute_error: 9.4694e-04 - val_loss: 0.1757 - val_mean_absolute_error: 0.0177\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0045 - mean_absolute_error: 0.0011 - val_loss: 0.1590 - val_mean_absolute_error: 0.0133\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0032 - mean_absolute_error: 8.3840e-04 - val_loss: 0.1659 - val_mean_absolute_error: 0.0154\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0032 - mean_absolute_error: 9.0509e-04 - val_loss: 0.1597 - val_mean_absolute_error: 0.0146\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0035 - mean_absolute_error: 9.2175e-04 - val_loss: 0.1636 - val_mean_absolute_error: 0.0142\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 3s 24ms/step - loss: 0.0027 - mean_absolute_error: 6.9061e-04 - val_loss: 0.1662 - val_mean_absolute_error: 0.0138\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, 200)              160800    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 424,004\n",
      "Trainable params: 161,604\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 6s 33ms/step - loss: 0.5015 - mean_absolute_error: 0.1152 - val_loss: 0.4946 - val_mean_absolute_error: 0.1435\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.4492 - mean_absolute_error: 0.1036 - val_loss: 0.4431 - val_mean_absolute_error: 0.1078\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.4251 - mean_absolute_error: 0.0998 - val_loss: 0.4362 - val_mean_absolute_error: 0.1125\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.4077 - mean_absolute_error: 0.0966 - val_loss: 0.4312 - val_mean_absolute_error: 0.1047\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.3973 - mean_absolute_error: 0.0960 - val_loss: 0.4414 - val_mean_absolute_error: 0.0933\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.3759 - mean_absolute_error: 0.0905 - val_loss: 0.4647 - val_mean_absolute_error: 0.1203\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.3612 - mean_absolute_error: 0.0897 - val_loss: 0.4358 - val_mean_absolute_error: 0.0960\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.3454 - mean_absolute_error: 0.0857 - val_loss: 0.4777 - val_mean_absolute_error: 0.0804\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.3238 - mean_absolute_error: 0.0815 - val_loss: 0.4364 - val_mean_absolute_error: 0.1029\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.3005 - mean_absolute_error: 0.0766 - val_loss: 0.4638 - val_mean_absolute_error: 0.1148\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.2786 - mean_absolute_error: 0.0731 - val_loss: 0.4662 - val_mean_absolute_error: 0.0899\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.2555 - mean_absolute_error: 0.0670 - val_loss: 0.4813 - val_mean_absolute_error: 0.0959\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.2306 - mean_absolute_error: 0.0610 - val_loss: 0.4947 - val_mean_absolute_error: 0.0862\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.1965 - mean_absolute_error: 0.0538 - val_loss: 0.5115 - val_mean_absolute_error: 0.0901\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.1731 - mean_absolute_error: 0.0487 - val_loss: 0.5478 - val_mean_absolute_error: 0.0894\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.1436 - mean_absolute_error: 0.0405 - val_loss: 0.6274 - val_mean_absolute_error: 0.0854\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.1167 - mean_absolute_error: 0.0347 - val_loss: 0.6705 - val_mean_absolute_error: 0.0863\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0983 - mean_absolute_error: 0.0299 - val_loss: 0.7213 - val_mean_absolute_error: 0.0920\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0756 - mean_absolute_error: 0.0238 - val_loss: 0.7752 - val_mean_absolute_error: 0.0783\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0629 - mean_absolute_error: 0.0199 - val_loss: 0.8352 - val_mean_absolute_error: 0.0881\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0530 - mean_absolute_error: 0.0165 - val_loss: 0.8316 - val_mean_absolute_error: 0.1007\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0474 - mean_absolute_error: 0.0149 - val_loss: 0.9541 - val_mean_absolute_error: 0.0745\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0361 - mean_absolute_error: 0.0126 - val_loss: 0.9407 - val_mean_absolute_error: 0.0831\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0373 - mean_absolute_error: 0.0119 - val_loss: 0.9631 - val_mean_absolute_error: 0.0844\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0291 - mean_absolute_error: 0.0097 - val_loss: 1.0550 - val_mean_absolute_error: 0.0838\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0312 - mean_absolute_error: 0.0102 - val_loss: 0.9418 - val_mean_absolute_error: 0.0888\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0285 - mean_absolute_error: 0.0094 - val_loss: 1.0513 - val_mean_absolute_error: 0.0851\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0402 - mean_absolute_error: 0.0126 - val_loss: 1.0076 - val_mean_absolute_error: 0.0891\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0210 - mean_absolute_error: 0.0069 - val_loss: 1.0552 - val_mean_absolute_error: 0.0846\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0284 - mean_absolute_error: 0.0085 - val_loss: 1.1220 - val_mean_absolute_error: 0.0761\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0287 - mean_absolute_error: 0.0087 - val_loss: 1.0430 - val_mean_absolute_error: 0.0917\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0227 - mean_absolute_error: 0.0076 - val_loss: 1.0881 - val_mean_absolute_error: 0.0896\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0137 - mean_absolute_error: 0.0047 - val_loss: 1.1660 - val_mean_absolute_error: 0.0783\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0095 - mean_absolute_error: 0.0032 - val_loss: 1.1822 - val_mean_absolute_error: 0.0803\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0095 - mean_absolute_error: 0.0029 - val_loss: 1.1855 - val_mean_absolute_error: 0.0781\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0090 - mean_absolute_error: 0.0028 - val_loss: 1.2407 - val_mean_absolute_error: 0.0773\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0501 - mean_absolute_error: 0.0119 - val_loss: 0.9827 - val_mean_absolute_error: 0.0813\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0360 - mean_absolute_error: 0.0117 - val_loss: 1.0643 - val_mean_absolute_error: 0.0816\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0171 - mean_absolute_error: 0.0056 - val_loss: 1.0694 - val_mean_absolute_error: 0.0849\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0099 - mean_absolute_error: 0.0034 - val_loss: 1.1197 - val_mean_absolute_error: 0.0848\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0093 - mean_absolute_error: 0.0026 - val_loss: 1.1171 - val_mean_absolute_error: 0.0893\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0085 - mean_absolute_error: 0.0026 - val_loss: 1.1784 - val_mean_absolute_error: 0.0849\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0081 - mean_absolute_error: 0.0023 - val_loss: 1.2598 - val_mean_absolute_error: 0.0815\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0069 - mean_absolute_error: 0.0021 - val_loss: 1.1933 - val_mean_absolute_error: 0.0890\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0088 - mean_absolute_error: 0.0025 - val_loss: 1.2684 - val_mean_absolute_error: 0.0797\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0119 - mean_absolute_error: 0.0032 - val_loss: 1.2230 - val_mean_absolute_error: 0.0819\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0314 - mean_absolute_error: 0.0091 - val_loss: 1.2007 - val_mean_absolute_error: 0.1238\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0365 - mean_absolute_error: 0.0114 - val_loss: 1.0632 - val_mean_absolute_error: 0.0874\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0212 - mean_absolute_error: 0.0064 - val_loss: 1.0226 - val_mean_absolute_error: 0.0914\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0105 - mean_absolute_error: 0.0034 - val_loss: 1.1323 - val_mean_absolute_error: 0.0867\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0079 - mean_absolute_error: 0.0022 - val_loss: 1.2363 - val_mean_absolute_error: 0.0826\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0064 - mean_absolute_error: 0.0020 - val_loss: 1.1693 - val_mean_absolute_error: 0.0900\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0079 - mean_absolute_error: 0.0023 - val_loss: 1.2663 - val_mean_absolute_error: 0.0807\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0072 - mean_absolute_error: 0.0021 - val_loss: 1.2104 - val_mean_absolute_error: 0.0853\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0060 - mean_absolute_error: 0.0018 - val_loss: 1.2815 - val_mean_absolute_error: 0.0824\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0061 - mean_absolute_error: 0.0017 - val_loss: 1.2582 - val_mean_absolute_error: 0.0836\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0058 - mean_absolute_error: 0.0020 - val_loss: 1.3669 - val_mean_absolute_error: 0.0835\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0080 - mean_absolute_error: 0.0024 - val_loss: 1.2766 - val_mean_absolute_error: 0.0891\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0472 - mean_absolute_error: 0.0127 - val_loss: 1.1672 - val_mean_absolute_error: 0.0957\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0356 - mean_absolute_error: 0.0098 - val_loss: 1.0111 - val_mean_absolute_error: 0.0905\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0306 - mean_absolute_error: 0.0081 - val_loss: 0.9936 - val_mean_absolute_error: 0.0841\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0125 - mean_absolute_error: 0.0042 - val_loss: 1.1052 - val_mean_absolute_error: 0.0847\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0073 - mean_absolute_error: 0.0025 - val_loss: 1.3046 - val_mean_absolute_error: 0.0767\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0059 - mean_absolute_error: 0.0019 - val_loss: 1.1903 - val_mean_absolute_error: 0.0866\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0070 - mean_absolute_error: 0.0017 - val_loss: 1.1714 - val_mean_absolute_error: 0.0882\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0062 - mean_absolute_error: 0.0019 - val_loss: 1.3207 - val_mean_absolute_error: 0.0786\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0075 - mean_absolute_error: 0.0020 - val_loss: 1.1843 - val_mean_absolute_error: 0.0901\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0065 - mean_absolute_error: 0.0019 - val_loss: 1.2463 - val_mean_absolute_error: 0.0833\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0055 - mean_absolute_error: 0.0015 - val_loss: 1.3203 - val_mean_absolute_error: 0.0804\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0064 - mean_absolute_error: 0.0016 - val_loss: 1.3021 - val_mean_absolute_error: 0.0798\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0054 - mean_absolute_error: 0.0015 - val_loss: 1.2618 - val_mean_absolute_error: 0.0901\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0059 - mean_absolute_error: 0.0017 - val_loss: 1.2953 - val_mean_absolute_error: 0.0854\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0059 - mean_absolute_error: 0.0017 - val_loss: 1.3126 - val_mean_absolute_error: 0.0852\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0085 - mean_absolute_error: 0.0022 - val_loss: 1.2968 - val_mean_absolute_error: 0.0838\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0079 - mean_absolute_error: 0.0019 - val_loss: 1.3500 - val_mean_absolute_error: 0.0842\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0057 - mean_absolute_error: 0.0016 - val_loss: 1.3406 - val_mean_absolute_error: 0.0801\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0059 - mean_absolute_error: 0.0016 - val_loss: 1.3225 - val_mean_absolute_error: 0.0824\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0060 - mean_absolute_error: 0.0016 - val_loss: 1.3150 - val_mean_absolute_error: 0.0849\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0054 - mean_absolute_error: 0.0014 - val_loss: 1.3193 - val_mean_absolute_error: 0.0833\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0135 - mean_absolute_error: 0.0032 - val_loss: 1.2090 - val_mean_absolute_error: 0.0809\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0579 - mean_absolute_error: 0.0140 - val_loss: 0.9728 - val_mean_absolute_error: 0.0842\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0229 - mean_absolute_error: 0.0068 - val_loss: 1.0262 - val_mean_absolute_error: 0.0797\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0102 - mean_absolute_error: 0.0036 - val_loss: 1.1691 - val_mean_absolute_error: 0.0776\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0068 - mean_absolute_error: 0.0022 - val_loss: 1.1546 - val_mean_absolute_error: 0.0826\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0051 - mean_absolute_error: 0.0017 - val_loss: 1.1758 - val_mean_absolute_error: 0.0817\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0052 - mean_absolute_error: 0.0017 - val_loss: 1.2364 - val_mean_absolute_error: 0.0793\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0042 - mean_absolute_error: 0.0014 - val_loss: 1.2313 - val_mean_absolute_error: 0.0818\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0049 - mean_absolute_error: 0.0016 - val_loss: 1.2509 - val_mean_absolute_error: 0.0818\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0048 - mean_absolute_error: 0.0013 - val_loss: 1.2968 - val_mean_absolute_error: 0.0800\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0041 - mean_absolute_error: 0.0013 - val_loss: 1.3603 - val_mean_absolute_error: 0.0762\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0042 - mean_absolute_error: 0.0013 - val_loss: 1.3259 - val_mean_absolute_error: 0.0779\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0046 - mean_absolute_error: 0.0014 - val_loss: 1.2640 - val_mean_absolute_error: 0.0843\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0146 - mean_absolute_error: 0.0044 - val_loss: 1.1656 - val_mean_absolute_error: 0.0786\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0427 - mean_absolute_error: 0.0108 - val_loss: 1.2638 - val_mean_absolute_error: 0.0804\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0237 - mean_absolute_error: 0.0067 - val_loss: 1.1040 - val_mean_absolute_error: 0.0900\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0103 - mean_absolute_error: 0.0034 - val_loss: 1.1248 - val_mean_absolute_error: 0.0892\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 4s 28ms/step - loss: 0.0059 - mean_absolute_error: 0.0019 - val_loss: 1.3018 - val_mean_absolute_error: 0.0817\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0056 - mean_absolute_error: 0.0016 - val_loss: 1.3132 - val_mean_absolute_error: 0.0804\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0051 - mean_absolute_error: 0.0016 - val_loss: 1.3039 - val_mean_absolute_error: 0.0834\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 4s 29ms/step - loss: 0.0048 - mean_absolute_error: 0.0015 - val_loss: 1.3848 - val_mean_absolute_error: 0.0794\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 200)              160800    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 424,004\n",
      "Trainable params: 161,604\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 6s 34ms/step - loss: 0.1825 - mean_absolute_error: 0.0370 - val_loss: 0.1346 - val_mean_absolute_error: 0.0194\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1244 - mean_absolute_error: 0.0203 - val_loss: 0.1365 - val_mean_absolute_error: 0.0316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1256 - mean_absolute_error: 0.0217 - val_loss: 0.1326 - val_mean_absolute_error: 0.0191\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1181 - mean_absolute_error: 0.0212 - val_loss: 0.1404 - val_mean_absolute_error: 0.0153\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1179 - mean_absolute_error: 0.0202 - val_loss: 0.1317 - val_mean_absolute_error: 0.0222\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1114 - mean_absolute_error: 0.0211 - val_loss: 0.1331 - val_mean_absolute_error: 0.0189\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1084 - mean_absolute_error: 0.0199 - val_loss: 0.1252 - val_mean_absolute_error: 0.0234\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0976 - mean_absolute_error: 0.0195 - val_loss: 0.1354 - val_mean_absolute_error: 0.0203\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0859 - mean_absolute_error: 0.0185 - val_loss: 0.1394 - val_mean_absolute_error: 0.0202\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0778 - mean_absolute_error: 0.0177 - val_loss: 0.1716 - val_mean_absolute_error: 0.0139\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0724 - mean_absolute_error: 0.0166 - val_loss: 0.1431 - val_mean_absolute_error: 0.0224\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0577 - mean_absolute_error: 0.0142 - val_loss: 0.1815 - val_mean_absolute_error: 0.0160\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0482 - mean_absolute_error: 0.0118 - val_loss: 0.1787 - val_mean_absolute_error: 0.0147\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0439 - mean_absolute_error: 0.0116 - val_loss: 0.1843 - val_mean_absolute_error: 0.0168\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0326 - mean_absolute_error: 0.0087 - val_loss: 0.2038 - val_mean_absolute_error: 0.0166\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0229 - mean_absolute_error: 0.0068 - val_loss: 0.2058 - val_mean_absolute_error: 0.0197\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0161 - mean_absolute_error: 0.0053 - val_loss: 0.2286 - val_mean_absolute_error: 0.0188\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0122 - mean_absolute_error: 0.0039 - val_loss: 0.2412 - val_mean_absolute_error: 0.0174\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0066 - mean_absolute_error: 0.0024 - val_loss: 0.2514 - val_mean_absolute_error: 0.0176\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0108 - mean_absolute_error: 0.0037 - val_loss: 0.2604 - val_mean_absolute_error: 0.0157\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0089 - mean_absolute_error: 0.0031 - val_loss: 0.2520 - val_mean_absolute_error: 0.0202\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0092 - mean_absolute_error: 0.0031 - val_loss: 0.2638 - val_mean_absolute_error: 0.0188\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0026 - mean_absolute_error: 0.0011 - val_loss: 0.2808 - val_mean_absolute_error: 0.0149\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0013 - mean_absolute_error: 6.0365e-04 - val_loss: 0.2857 - val_mean_absolute_error: 0.0135\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 8.3641e-04 - mean_absolute_error: 4.0509e-04 - val_loss: 0.2913 - val_mean_absolute_error: 0.0139\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 7.9450e-04 - mean_absolute_error: 3.7809e-04 - val_loss: 0.2927 - val_mean_absolute_error: 0.0145\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 5.3561e-04 - mean_absolute_error: 2.5640e-04 - val_loss: 0.3027 - val_mean_absolute_error: 0.0135\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 4.6671e-04 - mean_absolute_error: 2.2565e-04 - val_loss: 0.3030 - val_mean_absolute_error: 0.0149\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 3.6864e-04 - mean_absolute_error: 1.8194e-04 - val_loss: 0.3130 - val_mean_absolute_error: 0.0133\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 3.4643e-04 - mean_absolute_error: 1.6946e-04 - val_loss: 0.3183 - val_mean_absolute_error: 0.0130\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 2.7241e-04 - mean_absolute_error: 1.3430e-04 - val_loss: 0.3201 - val_mean_absolute_error: 0.0136\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 2.1853e-04 - mean_absolute_error: 1.0852e-04 - val_loss: 0.3310 - val_mean_absolute_error: 0.0128\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 2.0384e-04 - mean_absolute_error: 1.0106e-04 - val_loss: 0.3323 - val_mean_absolute_error: 0.0129\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 2.1726e-04 - mean_absolute_error: 1.0669e-04 - val_loss: 0.3354 - val_mean_absolute_error: 0.0130\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.2664e-04 - mean_absolute_error: 6.3079e-05 - val_loss: 0.3395 - val_mean_absolute_error: 0.0132\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.3532e-04 - mean_absolute_error: 6.7148e-05 - val_loss: 0.3429 - val_mean_absolute_error: 0.0134\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.1513e-04 - mean_absolute_error: 5.7341e-05 - val_loss: 0.3515 - val_mean_absolute_error: 0.0126\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 9.5285e-05 - mean_absolute_error: 4.7413e-05 - val_loss: 0.3513 - val_mean_absolute_error: 0.0133\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.0013e-04 - mean_absolute_error: 4.9860e-05 - val_loss: 0.3540 - val_mean_absolute_error: 0.0134\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.0019e-04 - mean_absolute_error: 4.9661e-05 - val_loss: 0.3615 - val_mean_absolute_error: 0.0132\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 6.7640e-05 - mean_absolute_error: 3.3765e-05 - val_loss: 0.3609 - val_mean_absolute_error: 0.0130\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 6.9874e-05 - mean_absolute_error: 3.4804e-05 - val_loss: 0.3637 - val_mean_absolute_error: 0.0134\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 6.5603e-05 - mean_absolute_error: 3.2714e-05 - val_loss: 0.3670 - val_mean_absolute_error: 0.0134\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 6.6615e-05 - mean_absolute_error: 3.3150e-05 - val_loss: 0.3732 - val_mean_absolute_error: 0.0129\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 5.0520e-05 - mean_absolute_error: 2.5216e-05 - val_loss: 0.3718 - val_mean_absolute_error: 0.0140\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 4.4571e-05 - mean_absolute_error: 2.2230e-05 - val_loss: 0.3787 - val_mean_absolute_error: 0.0130\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 3.9978e-05 - mean_absolute_error: 1.9942e-05 - val_loss: 0.3743 - val_mean_absolute_error: 0.0135\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 3.8725e-05 - mean_absolute_error: 1.9321e-05 - val_loss: 0.3794 - val_mean_absolute_error: 0.0140\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 3.3630e-05 - mean_absolute_error: 1.6790e-05 - val_loss: 0.3856 - val_mean_absolute_error: 0.0132\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 3.3223e-05 - mean_absolute_error: 1.6590e-05 - val_loss: 0.3872 - val_mean_absolute_error: 0.0138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 2.8199e-05 - mean_absolute_error: 1.4088e-05 - val_loss: 0.3928 - val_mean_absolute_error: 0.0136\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 2.3188e-05 - mean_absolute_error: 1.1578e-05 - val_loss: 0.3938 - val_mean_absolute_error: 0.0139\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 2.4028e-05 - mean_absolute_error: 1.2006e-05 - val_loss: 0.3979 - val_mean_absolute_error: 0.0127\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.9854e-05 - mean_absolute_error: 9.9200e-06 - val_loss: 0.3980 - val_mean_absolute_error: 0.0133\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 2.1933e-05 - mean_absolute_error: 1.0950e-05 - val_loss: 0.3989 - val_mean_absolute_error: 0.0134\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.8771e-05 - mean_absolute_error: 9.3789e-06 - val_loss: 0.3971 - val_mean_absolute_error: 0.0143\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.9091e-05 - mean_absolute_error: 9.5382e-06 - val_loss: 0.4016 - val_mean_absolute_error: 0.0135\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.7899e-05 - mean_absolute_error: 8.9438e-06 - val_loss: 0.4070 - val_mean_absolute_error: 0.0130\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.5219e-05 - mean_absolute_error: 7.6062e-06 - val_loss: 0.4088 - val_mean_absolute_error: 0.0137\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.3979e-05 - mean_absolute_error: 6.9867e-06 - val_loss: 0.4146 - val_mean_absolute_error: 0.0134\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.5929e-05 - mean_absolute_error: 7.9583e-06 - val_loss: 0.4076 - val_mean_absolute_error: 0.0139\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.8740e-05 - mean_absolute_error: 9.3576e-06 - val_loss: 0.4262 - val_mean_absolute_error: 0.0130\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.3515e-05 - mean_absolute_error: 6.7550e-06 - val_loss: 0.4193 - val_mean_absolute_error: 0.0138\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.1020e-05 - mean_absolute_error: 5.5081e-06 - val_loss: 0.4165 - val_mean_absolute_error: 0.0134\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 9.4411e-06 - mean_absolute_error: 4.7200e-06 - val_loss: 0.4239 - val_mean_absolute_error: 0.0135\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 6.6039e-06 - mean_absolute_error: 3.3026e-06 - val_loss: 0.4261 - val_mean_absolute_error: 0.0131\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 7.3150e-06 - mean_absolute_error: 3.6578e-06 - val_loss: 0.4262 - val_mean_absolute_error: 0.0134\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 6.6421e-06 - mean_absolute_error: 3.3217e-06 - val_loss: 0.4294 - val_mean_absolute_error: 0.0133\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 6.1516e-06 - mean_absolute_error: 3.0764e-06 - val_loss: 0.4339 - val_mean_absolute_error: 0.0132\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 6.1532e-06 - mean_absolute_error: 3.0771e-06 - val_loss: 0.4342 - val_mean_absolute_error: 0.0134\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 6.4600e-06 - mean_absolute_error: 3.2303e-06 - val_loss: 0.4362 - val_mean_absolute_error: 0.0134\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 6.8135e-06 - mean_absolute_error: 3.4059e-06 - val_loss: 0.4432 - val_mean_absolute_error: 0.0130\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0196 - mean_absolute_error: 0.0026 - val_loss: 0.1998 - val_mean_absolute_error: 0.0202\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0632 - mean_absolute_error: 0.0138 - val_loss: 0.1951 - val_mean_absolute_error: 0.0162\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0157 - mean_absolute_error: 0.0051 - val_loss: 0.2424 - val_mean_absolute_error: 0.0143\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0068 - mean_absolute_error: 0.0024 - val_loss: 0.2494 - val_mean_absolute_error: 0.0143\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0011 - mean_absolute_error: 5.3414e-04 - val_loss: 0.2705 - val_mean_absolute_error: 0.0137\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 5.4715e-04 - mean_absolute_error: 2.6891e-04 - val_loss: 0.2849 - val_mean_absolute_error: 0.0136\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 4.3969e-04 - mean_absolute_error: 2.1690e-04 - val_loss: 0.2912 - val_mean_absolute_error: 0.0136\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 3.0553e-04 - mean_absolute_error: 1.5140e-04 - val_loss: 0.2984 - val_mean_absolute_error: 0.0137\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 2.5251e-04 - mean_absolute_error: 1.2540e-04 - val_loss: 0.3045 - val_mean_absolute_error: 0.0136\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 2.3113e-04 - mean_absolute_error: 1.1454e-04 - val_loss: 0.3083 - val_mean_absolute_error: 0.0136\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.6830e-04 - mean_absolute_error: 8.3786e-05 - val_loss: 0.3131 - val_mean_absolute_error: 0.0135\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.8557e-04 - mean_absolute_error: 9.2091e-05 - val_loss: 0.3154 - val_mean_absolute_error: 0.0139\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.3058e-04 - mean_absolute_error: 6.5095e-05 - val_loss: 0.3226 - val_mean_absolute_error: 0.0135\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 1.2391e-04 - mean_absolute_error: 6.1599e-05 - val_loss: 0.3253 - val_mean_absolute_error: 0.0139\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 9.8013e-05 - mean_absolute_error: 4.8881e-05 - val_loss: 0.3320 - val_mean_absolute_error: 0.0136\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 9.4265e-05 - mean_absolute_error: 4.6949e-05 - val_loss: 0.3351 - val_mean_absolute_error: 0.0135\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 7.9401e-05 - mean_absolute_error: 3.9617e-05 - val_loss: 0.3385 - val_mean_absolute_error: 0.0135\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 6.8554e-05 - mean_absolute_error: 3.4186e-05 - val_loss: 0.3390 - val_mean_absolute_error: 0.0134\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 6.2940e-05 - mean_absolute_error: 3.1418e-05 - val_loss: 0.3421 - val_mean_absolute_error: 0.0134\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 5.3983e-05 - mean_absolute_error: 2.6943e-05 - val_loss: 0.3471 - val_mean_absolute_error: 0.0132\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 6.2697e-05 - mean_absolute_error: 3.1191e-05 - val_loss: 0.3462 - val_mean_absolute_error: 0.0135\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 5.4954e-05 - mean_absolute_error: 2.7425e-05 - val_loss: 0.3503 - val_mean_absolute_error: 0.0134\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 4.1152e-05 - mean_absolute_error: 2.0559e-05 - val_loss: 0.3520 - val_mean_absolute_error: 0.0135\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 4.1977e-05 - mean_absolute_error: 2.0968e-05 - val_loss: 0.3553 - val_mean_absolute_error: 0.0133\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 5.1747e-05 - mean_absolute_error: 2.5707e-05 - val_loss: 0.3586 - val_mean_absolute_error: 0.0131\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 4s 31ms/step - loss: 3.0385e-05 - mean_absolute_error: 1.5183e-05 - val_loss: 0.3623 - val_mean_absolute_error: 0.0131\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 3.2213e-05 - mean_absolute_error: 1.6094e-05 - val_loss: 0.3648 - val_mean_absolute_error: 0.0132\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 3.5837e-05 - mean_absolute_error: 1.7883e-05 - val_loss: 0.3649 - val_mean_absolute_error: 0.0134\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional_12 (Bidirecti  (None, 200)              160800    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 424,004\n",
      "Trainable params: 161,604\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 6s 33ms/step - loss: 0.1879 - mean_absolute_error: 0.0369 - val_loss: 0.1559 - val_mean_absolute_error: 0.0215\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.1439 - mean_absolute_error: 0.0244 - val_loss: 0.1554 - val_mean_absolute_error: 0.0305\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.1382 - mean_absolute_error: 0.0255 - val_loss: 0.1512 - val_mean_absolute_error: 0.0210\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.1295 - mean_absolute_error: 0.0241 - val_loss: 0.1517 - val_mean_absolute_error: 0.0381\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.1178 - mean_absolute_error: 0.0228 - val_loss: 0.1441 - val_mean_absolute_error: 0.0348\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.1118 - mean_absolute_error: 0.0234 - val_loss: 0.1397 - val_mean_absolute_error: 0.0276\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.1019 - mean_absolute_error: 0.0217 - val_loss: 0.1626 - val_mean_absolute_error: 0.0195\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0923 - mean_absolute_error: 0.0204 - val_loss: 0.1508 - val_mean_absolute_error: 0.0228\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0888 - mean_absolute_error: 0.0203 - val_loss: 0.1463 - val_mean_absolute_error: 0.0290\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0826 - mean_absolute_error: 0.0192 - val_loss: 0.1412 - val_mean_absolute_error: 0.0279\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0732 - mean_absolute_error: 0.0186 - val_loss: 0.1464 - val_mean_absolute_error: 0.0268\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0649 - mean_absolute_error: 0.0166 - val_loss: 0.1755 - val_mean_absolute_error: 0.0211\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0568 - mean_absolute_error: 0.0157 - val_loss: 0.1692 - val_mean_absolute_error: 0.0195\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0532 - mean_absolute_error: 0.0144 - val_loss: 0.1623 - val_mean_absolute_error: 0.0224\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0409 - mean_absolute_error: 0.0117 - val_loss: 0.1887 - val_mean_absolute_error: 0.0200\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0324 - mean_absolute_error: 0.0094 - val_loss: 0.2118 - val_mean_absolute_error: 0.0182\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0261 - mean_absolute_error: 0.0079 - val_loss: 0.2404 - val_mean_absolute_error: 0.0167\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0278 - mean_absolute_error: 0.0086 - val_loss: 0.2297 - val_mean_absolute_error: 0.0174\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0190 - mean_absolute_error: 0.0061 - val_loss: 0.2406 - val_mean_absolute_error: 0.0174\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0204 - mean_absolute_error: 0.0063 - val_loss: 0.2470 - val_mean_absolute_error: 0.0167\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0166 - mean_absolute_error: 0.0056 - val_loss: 0.2363 - val_mean_absolute_error: 0.0169\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0116 - mean_absolute_error: 0.0039 - val_loss: 0.2393 - val_mean_absolute_error: 0.0228\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0082 - mean_absolute_error: 0.0029 - val_loss: 0.2698 - val_mean_absolute_error: 0.0183\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0079 - mean_absolute_error: 0.0027 - val_loss: 0.2727 - val_mean_absolute_error: 0.0181\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0056 - mean_absolute_error: 0.0020 - val_loss: 0.2921 - val_mean_absolute_error: 0.0189\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0091 - mean_absolute_error: 0.0028 - val_loss: 0.3433 - val_mean_absolute_error: 0.0152\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0107 - mean_absolute_error: 0.0033 - val_loss: 0.2663 - val_mean_absolute_error: 0.0235\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0069 - mean_absolute_error: 0.0023 - val_loss: 0.3234 - val_mean_absolute_error: 0.0166\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0044 - mean_absolute_error: 0.0017 - val_loss: 0.2995 - val_mean_absolute_error: 0.0173\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0038 - mean_absolute_error: 0.0012 - val_loss: 0.3611 - val_mean_absolute_error: 0.0164\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0096 - mean_absolute_error: 0.0026 - val_loss: 0.2868 - val_mean_absolute_error: 0.0182\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0046 - mean_absolute_error: 0.0017 - val_loss: 0.3197 - val_mean_absolute_error: 0.0172\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0032 - mean_absolute_error: 0.0010 - val_loss: 0.3210 - val_mean_absolute_error: 0.0176\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0022 - mean_absolute_error: 8.5843e-04 - val_loss: 0.3586 - val_mean_absolute_error: 0.0168\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0038 - mean_absolute_error: 0.0012 - val_loss: 0.3611 - val_mean_absolute_error: 0.0180\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0043 - mean_absolute_error: 0.0011 - val_loss: 0.3281 - val_mean_absolute_error: 0.0180\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0026 - mean_absolute_error: 8.6609e-04 - val_loss: 0.3399 - val_mean_absolute_error: 0.0166\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0022 - mean_absolute_error: 7.2526e-04 - val_loss: 0.3605 - val_mean_absolute_error: 0.0170\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0017 - mean_absolute_error: 6.2713e-04 - val_loss: 0.3521 - val_mean_absolute_error: 0.0176\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0017 - mean_absolute_error: 6.1909e-04 - val_loss: 0.3652 - val_mean_absolute_error: 0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0019 - mean_absolute_error: 5.7574e-04 - val_loss: 0.3620 - val_mean_absolute_error: 0.0173\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0015 - mean_absolute_error: 5.1856e-04 - val_loss: 0.3744 - val_mean_absolute_error: 0.0176\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0021 - mean_absolute_error: 5.5595e-04 - val_loss: 0.3744 - val_mean_absolute_error: 0.0176\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0028 - mean_absolute_error: 8.4874e-04 - val_loss: 0.3674 - val_mean_absolute_error: 0.0207\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0218 - mean_absolute_error: 0.0050 - val_loss: 0.2796 - val_mean_absolute_error: 0.0202\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0076 - mean_absolute_error: 0.0026 - val_loss: 0.2938 - val_mean_absolute_error: 0.0195\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0025 - mean_absolute_error: 9.8282e-04 - val_loss: 0.3222 - val_mean_absolute_error: 0.0172\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0020 - mean_absolute_error: 6.9202e-04 - val_loss: 0.3107 - val_mean_absolute_error: 0.0199\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0065 - mean_absolute_error: 0.0020 - val_loss: 0.3071 - val_mean_absolute_error: 0.0181\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0022 - mean_absolute_error: 8.8874e-04 - val_loss: 0.3516 - val_mean_absolute_error: 0.0171\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0013 - mean_absolute_error: 4.8746e-04 - val_loss: 0.3413 - val_mean_absolute_error: 0.0173\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0017 - mean_absolute_error: 5.4997e-04 - val_loss: 0.3592 - val_mean_absolute_error: 0.0173\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0012 - mean_absolute_error: 4.3020e-04 - val_loss: 0.3680 - val_mean_absolute_error: 0.0167\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0016 - mean_absolute_error: 4.6337e-04 - val_loss: 0.3530 - val_mean_absolute_error: 0.0181\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0014 - mean_absolute_error: 4.6091e-04 - val_loss: 0.3684 - val_mean_absolute_error: 0.0174\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0013 - mean_absolute_error: 4.2077e-04 - val_loss: 0.4002 - val_mean_absolute_error: 0.0163\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0014 - mean_absolute_error: 4.3801e-04 - val_loss: 0.3826 - val_mean_absolute_error: 0.0169\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0011 - mean_absolute_error: 3.7259e-04 - val_loss: 0.3789 - val_mean_absolute_error: 0.0173\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0011 - mean_absolute_error: 3.7733e-04 - val_loss: 0.3897 - val_mean_absolute_error: 0.0164\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0012 - mean_absolute_error: 3.6652e-04 - val_loss: 0.3765 - val_mean_absolute_error: 0.0183\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0014 - mean_absolute_error: 3.9769e-04 - val_loss: 0.3990 - val_mean_absolute_error: 0.0169\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0014 - mean_absolute_error: 3.6987e-04 - val_loss: 0.3743 - val_mean_absolute_error: 0.0187\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0014 - mean_absolute_error: 3.8852e-04 - val_loss: 0.4143 - val_mean_absolute_error: 0.0159\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0015 - mean_absolute_error: 4.6285e-04 - val_loss: 0.3979 - val_mean_absolute_error: 0.0167\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0011 - mean_absolute_error: 3.5351e-04 - val_loss: 0.3951 - val_mean_absolute_error: 0.0175\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0015 - mean_absolute_error: 4.0655e-04 - val_loss: 0.4115 - val_mean_absolute_error: 0.0164\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0013 - mean_absolute_error: 4.2650e-04 - val_loss: 0.3560 - val_mean_absolute_error: 0.0215\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0245 - mean_absolute_error: 0.0051 - val_loss: 0.2519 - val_mean_absolute_error: 0.0239\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0072 - mean_absolute_error: 0.0025 - val_loss: 0.2949 - val_mean_absolute_error: 0.0178\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0114 - mean_absolute_error: 0.0033 - val_loss: 0.2862 - val_mean_absolute_error: 0.0173\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0035 - mean_absolute_error: 0.0013 - val_loss: 0.3034 - val_mean_absolute_error: 0.0178\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0018 - mean_absolute_error: 6.8432e-04 - val_loss: 0.3204 - val_mean_absolute_error: 0.0181\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0019 - mean_absolute_error: 5.4910e-04 - val_loss: 0.3233 - val_mean_absolute_error: 0.0182\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0014 - mean_absolute_error: 4.7789e-04 - val_loss: 0.3315 - val_mean_absolute_error: 0.0182\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0013 - mean_absolute_error: 4.4402e-04 - val_loss: 0.3494 - val_mean_absolute_error: 0.0172\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0015 - mean_absolute_error: 4.5490e-04 - val_loss: 0.3494 - val_mean_absolute_error: 0.0177\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0013 - mean_absolute_error: 4.2782e-04 - val_loss: 0.3509 - val_mean_absolute_error: 0.0182\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0014 - mean_absolute_error: 4.0343e-04 - val_loss: 0.3654 - val_mean_absolute_error: 0.0175\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0017 - mean_absolute_error: 4.6565e-04 - val_loss: 0.3662 - val_mean_absolute_error: 0.0178\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0013 - mean_absolute_error: 3.6531e-04 - val_loss: 0.3573 - val_mean_absolute_error: 0.0187\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0012 - mean_absolute_error: 3.7151e-04 - val_loss: 0.3755 - val_mean_absolute_error: 0.0177\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0012 - mean_absolute_error: 3.6705e-04 - val_loss: 0.3666 - val_mean_absolute_error: 0.0187\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0013 - mean_absolute_error: 3.7542e-04 - val_loss: 0.3827 - val_mean_absolute_error: 0.0177\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0012 - mean_absolute_error: 4.0402e-04 - val_loss: 0.3853 - val_mean_absolute_error: 0.0177\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0014 - mean_absolute_error: 3.9447e-04 - val_loss: 0.3857 - val_mean_absolute_error: 0.0179\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0013 - mean_absolute_error: 3.9531e-04 - val_loss: 0.3865 - val_mean_absolute_error: 0.0184\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 7.7975e-04 - mean_absolute_error: 2.8481e-04 - val_loss: 0.3884 - val_mean_absolute_error: 0.0186\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0010 - mean_absolute_error: 3.4610e-04 - val_loss: 0.3945 - val_mean_absolute_error: 0.0181\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 4s 30ms/step - loss: 7.6889e-04 - mean_absolute_error: 2.6856e-04 - val_loss: 0.3961 - val_mean_absolute_error: 0.0184\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0010 - mean_absolute_error: 3.4725e-04 - val_loss: 0.3940 - val_mean_absolute_error: 0.0188\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 8.0707e-04 - mean_absolute_error: 2.8896e-04 - val_loss: 0.3996 - val_mean_absolute_error: 0.0190\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 9.2520e-04 - mean_absolute_error: 3.2270e-04 - val_loss: 0.4202 - val_mean_absolute_error: 0.0180\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0012 - mean_absolute_error: 3.7297e-04 - val_loss: 0.4127 - val_mean_absolute_error: 0.0184\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0013 - mean_absolute_error: 3.4804e-04 - val_loss: 0.4002 - val_mean_absolute_error: 0.0195\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0013 - mean_absolute_error: 3.9913e-04 - val_loss: 0.3987 - val_mean_absolute_error: 0.0194\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0014 - mean_absolute_error: 4.0255e-04 - val_loss: 0.4073 - val_mean_absolute_error: 0.0189\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0011 - mean_absolute_error: 3.1782e-04 - val_loss: 0.4189 - val_mean_absolute_error: 0.0181\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0013 - mean_absolute_error: 4.0290e-04 - val_loss: 0.4297 - val_mean_absolute_error: 0.0181\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0011 - mean_absolute_error: 3.4914e-04 - val_loss: 0.4309 - val_mean_absolute_error: 0.0180\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 8.9571e-04 - mean_absolute_error: 3.1169e-04 - val_loss: 0.4245 - val_mean_absolute_error: 0.0184\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional_13 (Bidirecti  (None, 200)              160800    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 424,004\n",
      "Trainable params: 161,604\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 6s 37ms/step - loss: 0.5149 - mean_absolute_error: 0.1286 - val_loss: 0.4255 - val_mean_absolute_error: 0.1269\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.3820 - mean_absolute_error: 0.0985 - val_loss: 0.3223 - val_mean_absolute_error: 0.0823\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.3359 - mean_absolute_error: 0.0871 - val_loss: 0.3228 - val_mean_absolute_error: 0.0787\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.3209 - mean_absolute_error: 0.0829 - val_loss: 0.3354 - val_mean_absolute_error: 0.0954\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.2939 - mean_absolute_error: 0.0777 - val_loss: 0.3065 - val_mean_absolute_error: 0.0680\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.2620 - mean_absolute_error: 0.0701 - val_loss: 0.3142 - val_mean_absolute_error: 0.0734\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.2492 - mean_absolute_error: 0.0668 - val_loss: 0.3322 - val_mean_absolute_error: 0.0656\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.2278 - mean_absolute_error: 0.0615 - val_loss: 0.3164 - val_mean_absolute_error: 0.0680\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.2158 - mean_absolute_error: 0.0580 - val_loss: 0.3125 - val_mean_absolute_error: 0.0650\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1974 - mean_absolute_error: 0.0541 - val_loss: 0.3353 - val_mean_absolute_error: 0.0590\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1781 - mean_absolute_error: 0.0496 - val_loss: 0.3548 - val_mean_absolute_error: 0.0603\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1617 - mean_absolute_error: 0.0454 - val_loss: 0.3618 - val_mean_absolute_error: 0.0636\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1424 - mean_absolute_error: 0.0413 - val_loss: 0.3695 - val_mean_absolute_error: 0.0625\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1289 - mean_absolute_error: 0.0371 - val_loss: 0.3929 - val_mean_absolute_error: 0.0639\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1082 - mean_absolute_error: 0.0318 - val_loss: 0.4088 - val_mean_absolute_error: 0.0598\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1044 - mean_absolute_error: 0.0310 - val_loss: 0.4215 - val_mean_absolute_error: 0.0554\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0802 - mean_absolute_error: 0.0250 - val_loss: 0.4797 - val_mean_absolute_error: 0.0531\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0749 - mean_absolute_error: 0.0227 - val_loss: 0.4952 - val_mean_absolute_error: 0.0567\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0692 - mean_absolute_error: 0.0211 - val_loss: 0.4864 - val_mean_absolute_error: 0.0570\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0643 - mean_absolute_error: 0.0194 - val_loss: 0.5062 - val_mean_absolute_error: 0.0527\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0514 - mean_absolute_error: 0.0157 - val_loss: 0.5333 - val_mean_absolute_error: 0.0601\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0642 - mean_absolute_error: 0.0185 - val_loss: 0.5071 - val_mean_absolute_error: 0.0588\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0443 - mean_absolute_error: 0.0138 - val_loss: 0.5104 - val_mean_absolute_error: 0.0518\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0390 - mean_absolute_error: 0.0128 - val_loss: 0.5760 - val_mean_absolute_error: 0.0513\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0376 - mean_absolute_error: 0.0117 - val_loss: 0.5713 - val_mean_absolute_error: 0.0575\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0352 - mean_absolute_error: 0.0107 - val_loss: 0.5656 - val_mean_absolute_error: 0.0537\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0451 - mean_absolute_error: 0.0129 - val_loss: 0.5370 - val_mean_absolute_error: 0.0530\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0333 - mean_absolute_error: 0.0105 - val_loss: 0.5958 - val_mean_absolute_error: 0.0498\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0315 - mean_absolute_error: 0.0093 - val_loss: 0.5686 - val_mean_absolute_error: 0.0595\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0428 - mean_absolute_error: 0.0122 - val_loss: 0.6103 - val_mean_absolute_error: 0.0553\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0394 - mean_absolute_error: 0.0121 - val_loss: 0.5855 - val_mean_absolute_error: 0.0536\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0260 - mean_absolute_error: 0.0086 - val_loss: 0.5951 - val_mean_absolute_error: 0.0527\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0257 - mean_absolute_error: 0.0080 - val_loss: 0.6525 - val_mean_absolute_error: 0.0507\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0261 - mean_absolute_error: 0.0074 - val_loss: 0.6400 - val_mean_absolute_error: 0.0516\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0291 - mean_absolute_error: 0.0092 - val_loss: 0.6458 - val_mean_absolute_error: 0.0640\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0223 - mean_absolute_error: 0.0073 - val_loss: 0.6826 - val_mean_absolute_error: 0.0517\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0228 - mean_absolute_error: 0.0060 - val_loss: 0.6910 - val_mean_absolute_error: 0.0519\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0190 - mean_absolute_error: 0.0056 - val_loss: 0.6868 - val_mean_absolute_error: 0.0551\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0352 - mean_absolute_error: 0.0093 - val_loss: 0.6611 - val_mean_absolute_error: 0.0713\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0454 - mean_absolute_error: 0.0126 - val_loss: 0.6860 - val_mean_absolute_error: 0.0504\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0221 - mean_absolute_error: 0.0068 - val_loss: 0.6726 - val_mean_absolute_error: 0.0542\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0185 - mean_absolute_error: 0.0055 - val_loss: 0.6837 - val_mean_absolute_error: 0.0567\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0174 - mean_absolute_error: 0.0053 - val_loss: 0.7311 - val_mean_absolute_error: 0.0522\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0176 - mean_absolute_error: 0.0047 - val_loss: 0.7352 - val_mean_absolute_error: 0.0506\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0162 - mean_absolute_error: 0.0047 - val_loss: 0.7180 - val_mean_absolute_error: 0.0542\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0171 - mean_absolute_error: 0.0050 - val_loss: 0.7150 - val_mean_absolute_error: 0.0521\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0161 - mean_absolute_error: 0.0044 - val_loss: 0.7390 - val_mean_absolute_error: 0.0493\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0150 - mean_absolute_error: 0.0042 - val_loss: 0.7595 - val_mean_absolute_error: 0.0513\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0168 - mean_absolute_error: 0.0045 - val_loss: 0.7443 - val_mean_absolute_error: 0.0499\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0145 - mean_absolute_error: 0.0041 - val_loss: 0.7404 - val_mean_absolute_error: 0.0515\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0142 - mean_absolute_error: 0.0041 - val_loss: 0.7673 - val_mean_absolute_error: 0.0501\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0152 - mean_absolute_error: 0.0044 - val_loss: 0.8434 - val_mean_absolute_error: 0.0653\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0295 - mean_absolute_error: 0.0082 - val_loss: 0.7177 - val_mean_absolute_error: 0.0520\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0446 - mean_absolute_error: 0.0115 - val_loss: 0.6687 - val_mean_absolute_error: 0.0714\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0362 - mean_absolute_error: 0.0105 - val_loss: 0.6863 - val_mean_absolute_error: 0.0547\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0170 - mean_absolute_error: 0.0051 - val_loss: 0.7056 - val_mean_absolute_error: 0.0532\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0175 - mean_absolute_error: 0.0047 - val_loss: 0.6889 - val_mean_absolute_error: 0.0554\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0142 - mean_absolute_error: 0.0040 - val_loss: 0.7604 - val_mean_absolute_error: 0.0503\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0171 - mean_absolute_error: 0.0046 - val_loss: 0.7271 - val_mean_absolute_error: 0.0515\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0135 - mean_absolute_error: 0.0038 - val_loss: 0.7471 - val_mean_absolute_error: 0.0508\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0124 - mean_absolute_error: 0.0035 - val_loss: 0.7453 - val_mean_absolute_error: 0.0530\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0158 - mean_absolute_error: 0.0039 - val_loss: 0.7154 - val_mean_absolute_error: 0.0533\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0120 - mean_absolute_error: 0.0035 - val_loss: 0.7540 - val_mean_absolute_error: 0.0530\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0133 - mean_absolute_error: 0.0036 - val_loss: 0.7537 - val_mean_absolute_error: 0.0549\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0135 - mean_absolute_error: 0.0037 - val_loss: 0.7609 - val_mean_absolute_error: 0.0523\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0131 - mean_absolute_error: 0.0033 - val_loss: 0.7632 - val_mean_absolute_error: 0.0503\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0143 - mean_absolute_error: 0.0040 - val_loss: 0.7748 - val_mean_absolute_error: 0.0520\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0129 - mean_absolute_error: 0.0035 - val_loss: 0.8067 - val_mean_absolute_error: 0.0497\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0129 - mean_absolute_error: 0.0035 - val_loss: 0.7725 - val_mean_absolute_error: 0.0515\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0124 - mean_absolute_error: 0.0034 - val_loss: 0.7714 - val_mean_absolute_error: 0.0526\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 4s 32ms/step - loss: 0.0155 - mean_absolute_error: 0.0039 - val_loss: 0.7575 - val_mean_absolute_error: 0.0530\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 4s 32ms/step - loss: 0.0161 - mean_absolute_error: 0.0048 - val_loss: 0.7887 - val_mean_absolute_error: 0.0505\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 4s 32ms/step - loss: 0.0165 - mean_absolute_error: 0.0042 - val_loss: 0.7744 - val_mean_absolute_error: 0.0545\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 4s 32ms/step - loss: 0.0262 - mean_absolute_error: 0.0069 - val_loss: 0.7346 - val_mean_absolute_error: 0.0658\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0411 - mean_absolute_error: 0.0120 - val_loss: 0.7295 - val_mean_absolute_error: 0.0496\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 4s 32ms/step - loss: 0.0247 - mean_absolute_error: 0.0071 - val_loss: 0.7482 - val_mean_absolute_error: 0.0534\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 4s 32ms/step - loss: 0.0148 - mean_absolute_error: 0.0040 - val_loss: 0.7339 - val_mean_absolute_error: 0.0500\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 4s 32ms/step - loss: 0.0126 - mean_absolute_error: 0.0035 - val_loss: 0.7388 - val_mean_absolute_error: 0.0508\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 4s 32ms/step - loss: 0.0125 - mean_absolute_error: 0.0034 - val_loss: 0.7604 - val_mean_absolute_error: 0.0501\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 4s 32ms/step - loss: 0.0119 - mean_absolute_error: 0.0034 - val_loss: 0.7883 - val_mean_absolute_error: 0.0498\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 4s 32ms/step - loss: 0.0154 - mean_absolute_error: 0.0043 - val_loss: 0.7488 - val_mean_absolute_error: 0.0510\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0126 - mean_absolute_error: 0.0038 - val_loss: 0.8043 - val_mean_absolute_error: 0.0495\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0132 - mean_absolute_error: 0.0038 - val_loss: 0.7843 - val_mean_absolute_error: 0.0495\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0132 - mean_absolute_error: 0.0034 - val_loss: 0.7879 - val_mean_absolute_error: 0.0499\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0127 - mean_absolute_error: 0.0034 - val_loss: 0.8077 - val_mean_absolute_error: 0.0489\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0106 - mean_absolute_error: 0.0029 - val_loss: 0.7835 - val_mean_absolute_error: 0.0522\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0137 - mean_absolute_error: 0.0034 - val_loss: 0.7688 - val_mean_absolute_error: 0.0527\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0120 - mean_absolute_error: 0.0034 - val_loss: 0.7852 - val_mean_absolute_error: 0.0519\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 4s 32ms/step - loss: 0.0117 - mean_absolute_error: 0.0034 - val_loss: 0.7932 - val_mean_absolute_error: 0.0500\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0116 - mean_absolute_error: 0.0033 - val_loss: 0.8623 - val_mean_absolute_error: 0.0502\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0133 - mean_absolute_error: 0.0036 - val_loss: 0.8069 - val_mean_absolute_error: 0.0517\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0120 - mean_absolute_error: 0.0031 - val_loss: 0.8030 - val_mean_absolute_error: 0.0513\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0113 - mean_absolute_error: 0.0031 - val_loss: 0.8439 - val_mean_absolute_error: 0.0503\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0130 - mean_absolute_error: 0.0032 - val_loss: 0.8311 - val_mean_absolute_error: 0.0508\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0117 - mean_absolute_error: 0.0032 - val_loss: 0.8362 - val_mean_absolute_error: 0.0502\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0125 - mean_absolute_error: 0.0032 - val_loss: 0.8056 - val_mean_absolute_error: 0.0546\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0112 - mean_absolute_error: 0.0031 - val_loss: 0.8210 - val_mean_absolute_error: 0.0522\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0116 - mean_absolute_error: 0.0031 - val_loss: 0.8141 - val_mean_absolute_error: 0.0526\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0114 - mean_absolute_error: 0.0030 - val_loss: 0.8484 - val_mean_absolute_error: 0.0519\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 4s 32ms/step - loss: 0.0118 - mean_absolute_error: 0.0031 - val_loss: 0.8374 - val_mean_absolute_error: 0.0517\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 25, 100)           262400    \n",
      "                                                                 \n",
      " bidirectional_14 (Bidirecti  (None, 200)              160800    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 424,004\n",
      "Trainable params: 161,604\n",
      "Non-trainable params: 262,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 6s 34ms/step - loss: 0.6341 - mean_absolute_error: 0.1589 - val_loss: 0.5236 - val_mean_absolute_error: 0.1127\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.4891 - mean_absolute_error: 0.1223 - val_loss: 0.4905 - val_mean_absolute_error: 0.1354\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.4539 - mean_absolute_error: 0.1174 - val_loss: 0.4840 - val_mean_absolute_error: 0.0979\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.4245 - mean_absolute_error: 0.1079 - val_loss: 0.4543 - val_mean_absolute_error: 0.1191\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.3956 - mean_absolute_error: 0.1017 - val_loss: 0.4464 - val_mean_absolute_error: 0.1054\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.3667 - mean_absolute_error: 0.0957 - val_loss: 0.4436 - val_mean_absolute_error: 0.0910\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.3416 - mean_absolute_error: 0.0895 - val_loss: 0.4362 - val_mean_absolute_error: 0.0899\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.3113 - mean_absolute_error: 0.0835 - val_loss: 0.4436 - val_mean_absolute_error: 0.0936\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.2872 - mean_absolute_error: 0.0774 - val_loss: 0.4462 - val_mean_absolute_error: 0.0883\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.2508 - mean_absolute_error: 0.0686 - val_loss: 0.4672 - val_mean_absolute_error: 0.0843\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.2298 - mean_absolute_error: 0.0642 - val_loss: 0.5804 - val_mean_absolute_error: 0.0813\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1938 - mean_absolute_error: 0.0560 - val_loss: 0.5239 - val_mean_absolute_error: 0.0766\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1642 - mean_absolute_error: 0.0473 - val_loss: 0.5427 - val_mean_absolute_error: 0.0852\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1479 - mean_absolute_error: 0.0431 - val_loss: 0.5828 - val_mean_absolute_error: 0.0734\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1176 - mean_absolute_error: 0.0355 - val_loss: 0.6796 - val_mean_absolute_error: 0.0734\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1087 - mean_absolute_error: 0.0334 - val_loss: 0.6387 - val_mean_absolute_error: 0.0775\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0995 - mean_absolute_error: 0.0290 - val_loss: 0.6624 - val_mean_absolute_error: 0.0751\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0723 - mean_absolute_error: 0.0236 - val_loss: 0.7330 - val_mean_absolute_error: 0.0704\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0840 - mean_absolute_error: 0.0252 - val_loss: 0.7037 - val_mean_absolute_error: 0.0775\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0713 - mean_absolute_error: 0.0227 - val_loss: 0.6975 - val_mean_absolute_error: 0.0748\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0500 - mean_absolute_error: 0.0163 - val_loss: 0.8336 - val_mean_absolute_error: 0.0679\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0398 - mean_absolute_error: 0.0135 - val_loss: 0.8635 - val_mean_absolute_error: 0.0683\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0335 - mean_absolute_error: 0.0108 - val_loss: 0.9703 - val_mean_absolute_error: 0.0696\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0308 - mean_absolute_error: 0.0101 - val_loss: 0.8991 - val_mean_absolute_error: 0.0709\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0360 - mean_absolute_error: 0.0107 - val_loss: 0.9232 - val_mean_absolute_error: 0.0692\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0353 - mean_absolute_error: 0.0111 - val_loss: 0.8975 - val_mean_absolute_error: 0.0770\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0278 - mean_absolute_error: 0.0092 - val_loss: 0.9635 - val_mean_absolute_error: 0.0666\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0244 - mean_absolute_error: 0.0073 - val_loss: 0.8912 - val_mean_absolute_error: 0.0760\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0551 - mean_absolute_error: 0.0155 - val_loss: 0.8513 - val_mean_absolute_error: 0.0678\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0687 - mean_absolute_error: 0.0195 - val_loss: 0.8467 - val_mean_absolute_error: 0.0745\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0416 - mean_absolute_error: 0.0131 - val_loss: 0.9486 - val_mean_absolute_error: 0.0678\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0209 - mean_absolute_error: 0.0069 - val_loss: 0.9492 - val_mean_absolute_error: 0.0690\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0219 - mean_absolute_error: 0.0068 - val_loss: 0.9229 - val_mean_absolute_error: 0.0703\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0203 - mean_absolute_error: 0.0067 - val_loss: 0.9622 - val_mean_absolute_error: 0.0707\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0190 - mean_absolute_error: 0.0059 - val_loss: 0.9723 - val_mean_absolute_error: 0.0684\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0179 - mean_absolute_error: 0.0054 - val_loss: 0.9527 - val_mean_absolute_error: 0.0732\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0285 - mean_absolute_error: 0.0083 - val_loss: 1.1304 - val_mean_absolute_error: 0.0704\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0202 - mean_absolute_error: 0.0057 - val_loss: 0.9756 - val_mean_absolute_error: 0.0713\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0164 - mean_absolute_error: 0.0052 - val_loss: 0.9881 - val_mean_absolute_error: 0.0737\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0161 - mean_absolute_error: 0.0047 - val_loss: 1.0836 - val_mean_absolute_error: 0.0698\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0148 - mean_absolute_error: 0.0045 - val_loss: 1.0920 - val_mean_absolute_error: 0.0690\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0180 - mean_absolute_error: 0.0045 - val_loss: 1.1126 - val_mean_absolute_error: 0.0718\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0169 - mean_absolute_error: 0.0047 - val_loss: 1.0860 - val_mean_absolute_error: 0.0713\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0153 - mean_absolute_error: 0.0044 - val_loss: 1.0838 - val_mean_absolute_error: 0.0725\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0133 - mean_absolute_error: 0.0041 - val_loss: 1.1280 - val_mean_absolute_error: 0.0696\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0144 - mean_absolute_error: 0.0039 - val_loss: 1.1113 - val_mean_absolute_error: 0.0708\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0144 - mean_absolute_error: 0.0040 - val_loss: 1.1776 - val_mean_absolute_error: 0.0706\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0121 - mean_absolute_error: 0.0035 - val_loss: 1.1437 - val_mean_absolute_error: 0.0727\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0114 - mean_absolute_error: 0.0037 - val_loss: 1.1041 - val_mean_absolute_error: 0.0729\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0130 - mean_absolute_error: 0.0036 - val_loss: 1.1364 - val_mean_absolute_error: 0.0726\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0117 - mean_absolute_error: 0.0035 - val_loss: 1.1723 - val_mean_absolute_error: 0.0710\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0126 - mean_absolute_error: 0.0035 - val_loss: 1.1698 - val_mean_absolute_error: 0.0694\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0113 - mean_absolute_error: 0.0033 - val_loss: 1.2287 - val_mean_absolute_error: 0.0704\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0156 - mean_absolute_error: 0.0041 - val_loss: 1.0683 - val_mean_absolute_error: 0.0793\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.1222 - mean_absolute_error: 0.0278 - val_loss: 0.9167 - val_mean_absolute_error: 0.0780\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0560 - mean_absolute_error: 0.0164 - val_loss: 0.9459 - val_mean_absolute_error: 0.0678\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0255 - mean_absolute_error: 0.0081 - val_loss: 0.9124 - val_mean_absolute_error: 0.0713\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0129 - mean_absolute_error: 0.0046 - val_loss: 0.9539 - val_mean_absolute_error: 0.0708\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0102 - mean_absolute_error: 0.0034 - val_loss: 0.9734 - val_mean_absolute_error: 0.0714\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0124 - mean_absolute_error: 0.0037 - val_loss: 1.0211 - val_mean_absolute_error: 0.0698\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0105 - mean_absolute_error: 0.0033 - val_loss: 1.0238 - val_mean_absolute_error: 0.0712\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0102 - mean_absolute_error: 0.0032 - val_loss: 1.0580 - val_mean_absolute_error: 0.0693\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0099 - mean_absolute_error: 0.0031 - val_loss: 1.0664 - val_mean_absolute_error: 0.0688\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0097 - mean_absolute_error: 0.0028 - val_loss: 1.1343 - val_mean_absolute_error: 0.0696\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0125 - mean_absolute_error: 0.0036 - val_loss: 1.0967 - val_mean_absolute_error: 0.0705\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0104 - mean_absolute_error: 0.0034 - val_loss: 1.1467 - val_mean_absolute_error: 0.0704\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0555 - mean_absolute_error: 0.0140 - val_loss: 0.8349 - val_mean_absolute_error: 0.0720\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0206 - mean_absolute_error: 0.0068 - val_loss: 0.9844 - val_mean_absolute_error: 0.0693\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0125 - mean_absolute_error: 0.0037 - val_loss: 1.0540 - val_mean_absolute_error: 0.0659\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0110 - mean_absolute_error: 0.0034 - val_loss: 1.0444 - val_mean_absolute_error: 0.0698\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0120 - mean_absolute_error: 0.0032 - val_loss: 1.0665 - val_mean_absolute_error: 0.0691\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0093 - mean_absolute_error: 0.0031 - val_loss: 1.0943 - val_mean_absolute_error: 0.0685\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0115 - mean_absolute_error: 0.0030 - val_loss: 1.0934 - val_mean_absolute_error: 0.0681\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0099 - mean_absolute_error: 0.0029 - val_loss: 1.1411 - val_mean_absolute_error: 0.0672\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0106 - mean_absolute_error: 0.0027 - val_loss: 1.1170 - val_mean_absolute_error: 0.0664\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0092 - mean_absolute_error: 0.0027 - val_loss: 1.1108 - val_mean_absolute_error: 0.0678\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0114 - mean_absolute_error: 0.0030 - val_loss: 1.0607 - val_mean_absolute_error: 0.0691\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0108 - mean_absolute_error: 0.0032 - val_loss: 1.1055 - val_mean_absolute_error: 0.0676\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0111 - mean_absolute_error: 0.0031 - val_loss: 1.2137 - val_mean_absolute_error: 0.0647\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0105 - mean_absolute_error: 0.0029 - val_loss: 1.1697 - val_mean_absolute_error: 0.0651\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0108 - mean_absolute_error: 0.0027 - val_loss: 1.1619 - val_mean_absolute_error: 0.0669\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0313 - mean_absolute_error: 0.0079 - val_loss: 0.9554 - val_mean_absolute_error: 0.0710\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0627 - mean_absolute_error: 0.0164 - val_loss: 1.0049 - val_mean_absolute_error: 0.0734\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0311 - mean_absolute_error: 0.0093 - val_loss: 0.9234 - val_mean_absolute_error: 0.0713\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0119 - mean_absolute_error: 0.0040 - val_loss: 0.9844 - val_mean_absolute_error: 0.0667\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0103 - mean_absolute_error: 0.0030 - val_loss: 1.0610 - val_mean_absolute_error: 0.0648\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0098 - mean_absolute_error: 0.0030 - val_loss: 1.0700 - val_mean_absolute_error: 0.0652\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0094 - mean_absolute_error: 0.0027 - val_loss: 1.0582 - val_mean_absolute_error: 0.0660\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0100 - mean_absolute_error: 0.0030 - val_loss: 1.1021 - val_mean_absolute_error: 0.0651\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0095 - mean_absolute_error: 0.0027 - val_loss: 1.0618 - val_mean_absolute_error: 0.0677\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0105 - mean_absolute_error: 0.0031 - val_loss: 1.1251 - val_mean_absolute_error: 0.0646\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0111 - mean_absolute_error: 0.0030 - val_loss: 1.1253 - val_mean_absolute_error: 0.0648\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0104 - mean_absolute_error: 0.0029 - val_loss: 1.1116 - val_mean_absolute_error: 0.0670\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0096 - mean_absolute_error: 0.0027 - val_loss: 1.1186 - val_mean_absolute_error: 0.0662\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0099 - mean_absolute_error: 0.0028 - val_loss: 1.1322 - val_mean_absolute_error: 0.0644\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0106 - mean_absolute_error: 0.0030 - val_loss: 1.1588 - val_mean_absolute_error: 0.0641\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0099 - mean_absolute_error: 0.0026 - val_loss: 1.1346 - val_mean_absolute_error: 0.0649\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0114 - mean_absolute_error: 0.0029 - val_loss: 1.1363 - val_mean_absolute_error: 0.0650\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 4s 31ms/step - loss: 0.0088 - mean_absolute_error: 0.0026 - val_loss: 1.1800 - val_mean_absolute_error: 0.0643\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 4s 30ms/step - loss: 0.0089 - mean_absolute_error: 0.0027 - val_loss: 1.1718 - val_mean_absolute_error: 0.0665\n",
      "Wall time: 52min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Wall time: 52min 36s\n",
    "directory_name = \"Data/PSMs/per_schema_models_glove\"\n",
    "for i in range(9):\n",
    "    train_label_schema = np_utils.to_categorical(train_labels[:,i])\n",
    "    val_label_schema = np_utils.to_categorical(val_labels[:,i])\n",
    "    val_output_slm, model = perschema_models_glove(padded_train,train_label_schema,padded_validate,val_label_schema)\n",
    "    #we write trained models to files to free up working memory\n",
    "    model_name = '/schema_model_' + schemas[i]\n",
    "    save_model_under = directory_name + model_name\n",
    "    model.save(save_model_under + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define separate models\n",
    "def perschema_models_bert(train_X, train_y, test_X, test_y):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(128, 512,)))\n",
    "    model.add(Bidirectional(LSTM(100)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    # compile the model\n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['mean_absolute_error'])\n",
    "    # summarize the model\n",
    "    print(model.summary())\n",
    "    # fit the model\n",
    "    model.fit(train_X, train_y,\n",
    "              validation_data=[test_X,test_y],\n",
    "              batch_size=32, \n",
    "              epochs=100, \n",
    "              verbose=1)\n",
    "    out=model.predict(test_X)\n",
    "    gof,p=scipy.stats.spearmanr(out,test_y,axis=None)\n",
    "    return gof, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_16 (Bidirecti  (None, 200)              490400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 491,204\n",
      "Trainable params: 491,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 25s 176ms/step - loss: 0.6601 - mean_absolute_error: 0.1688 - val_loss: 0.5835 - val_mean_absolute_error: 0.1477\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.5046 - mean_absolute_error: 0.1327 - val_loss: 0.5745 - val_mean_absolute_error: 0.1540\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.4399 - mean_absolute_error: 0.1171 - val_loss: 0.5553 - val_mean_absolute_error: 0.1197\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.3744 - mean_absolute_error: 0.1024 - val_loss: 0.5603 - val_mean_absolute_error: 0.1282\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.3184 - mean_absolute_error: 0.0899 - val_loss: 0.5467 - val_mean_absolute_error: 0.1136\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 23s 173ms/step - loss: 0.2386 - mean_absolute_error: 0.0705 - val_loss: 0.5830 - val_mean_absolute_error: 0.1128\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.1880 - mean_absolute_error: 0.0583 - val_loss: 0.6102 - val_mean_absolute_error: 0.1178\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.1336 - mean_absolute_error: 0.0439 - val_loss: 0.6676 - val_mean_absolute_error: 0.0994\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.1040 - mean_absolute_error: 0.0337 - val_loss: 0.6843 - val_mean_absolute_error: 0.1080\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0687 - mean_absolute_error: 0.0237 - val_loss: 0.7306 - val_mean_absolute_error: 0.1002\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0479 - mean_absolute_error: 0.0164 - val_loss: 0.8259 - val_mean_absolute_error: 0.0947\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0475 - mean_absolute_error: 0.0156 - val_loss: 0.8207 - val_mean_absolute_error: 0.0933\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0360 - mean_absolute_error: 0.0123 - val_loss: 0.9020 - val_mean_absolute_error: 0.0941\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0336 - mean_absolute_error: 0.0117 - val_loss: 0.8817 - val_mean_absolute_error: 0.0949\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0375 - mean_absolute_error: 0.0127 - val_loss: 0.9847 - val_mean_absolute_error: 0.0905\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0289 - mean_absolute_error: 0.0093 - val_loss: 0.9202 - val_mean_absolute_error: 0.0899\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0208 - mean_absolute_error: 0.0072 - val_loss: 0.9771 - val_mean_absolute_error: 0.0924\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0181 - mean_absolute_error: 0.0052 - val_loss: 1.0801 - val_mean_absolute_error: 0.0887\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0335 - mean_absolute_error: 0.0087 - val_loss: 0.8606 - val_mean_absolute_error: 0.1038\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0599 - mean_absolute_error: 0.0195 - val_loss: 0.9439 - val_mean_absolute_error: 0.0918\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0622 - mean_absolute_error: 0.0193 - val_loss: 0.9164 - val_mean_absolute_error: 0.1001\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0235 - mean_absolute_error: 0.0074 - val_loss: 0.9061 - val_mean_absolute_error: 0.0937\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0152 - mean_absolute_error: 0.0049 - val_loss: 0.9632 - val_mean_absolute_error: 0.0877\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0120 - mean_absolute_error: 0.0032 - val_loss: 1.1187 - val_mean_absolute_error: 0.0875\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0121 - mean_absolute_error: 0.0037 - val_loss: 0.9847 - val_mean_absolute_error: 0.0893\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0122 - mean_absolute_error: 0.0032 - val_loss: 1.0108 - val_mean_absolute_error: 0.0887\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0134 - mean_absolute_error: 0.0035 - val_loss: 1.0376 - val_mean_absolute_error: 0.0881\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0104 - mean_absolute_error: 0.0028 - val_loss: 1.0567 - val_mean_absolute_error: 0.0940\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0111 - mean_absolute_error: 0.0028 - val_loss: 1.1462 - val_mean_absolute_error: 0.0859\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0097 - mean_absolute_error: 0.0026 - val_loss: 1.1195 - val_mean_absolute_error: 0.0860\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0111 - mean_absolute_error: 0.0028 - val_loss: 1.0809 - val_mean_absolute_error: 0.0880\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0091 - mean_absolute_error: 0.0026 - val_loss: 1.1552 - val_mean_absolute_error: 0.0849\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0081 - mean_absolute_error: 0.0022 - val_loss: 1.1065 - val_mean_absolute_error: 0.0897\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0071 - mean_absolute_error: 0.0021 - val_loss: 1.1611 - val_mean_absolute_error: 0.0862\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0079 - mean_absolute_error: 0.0022 - val_loss: 1.1490 - val_mean_absolute_error: 0.0908\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0079 - mean_absolute_error: 0.0021 - val_loss: 1.1260 - val_mean_absolute_error: 0.0871\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0071 - mean_absolute_error: 0.0021 - val_loss: 1.1736 - val_mean_absolute_error: 0.0871\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0093 - mean_absolute_error: 0.0026 - val_loss: 1.2700 - val_mean_absolute_error: 0.0856\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0261 - mean_absolute_error: 0.0067 - val_loss: 1.0743 - val_mean_absolute_error: 0.0988\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.1272 - mean_absolute_error: 0.0365 - val_loss: 0.9492 - val_mean_absolute_error: 0.1100\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0724 - mean_absolute_error: 0.0223 - val_loss: 0.9243 - val_mean_absolute_error: 0.0957\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0270 - mean_absolute_error: 0.0086 - val_loss: 1.0210 - val_mean_absolute_error: 0.0880\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0153 - mean_absolute_error: 0.0046 - val_loss: 1.0996 - val_mean_absolute_error: 0.0862\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0123 - mean_absolute_error: 0.0031 - val_loss: 1.0429 - val_mean_absolute_error: 0.0879\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0074 - mean_absolute_error: 0.0024 - val_loss: 1.0953 - val_mean_absolute_error: 0.0883\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0090 - mean_absolute_error: 0.0024 - val_loss: 1.1672 - val_mean_absolute_error: 0.0850\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0092 - mean_absolute_error: 0.0026 - val_loss: 1.1528 - val_mean_absolute_error: 0.0854\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0086 - mean_absolute_error: 0.0024 - val_loss: 1.1563 - val_mean_absolute_error: 0.0867\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0078 - mean_absolute_error: 0.0023 - val_loss: 1.1822 - val_mean_absolute_error: 0.0875\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0095 - mean_absolute_error: 0.0025 - val_loss: 1.1675 - val_mean_absolute_error: 0.0868\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0088 - mean_absolute_error: 0.0023 - val_loss: 1.1837 - val_mean_absolute_error: 0.0846\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0089 - mean_absolute_error: 0.0023 - val_loss: 1.2359 - val_mean_absolute_error: 0.0846\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0073 - mean_absolute_error: 0.0022 - val_loss: 1.1866 - val_mean_absolute_error: 0.0841\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0069 - mean_absolute_error: 0.0021 - val_loss: 1.2276 - val_mean_absolute_error: 0.0837\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0081 - mean_absolute_error: 0.0022 - val_loss: 1.2594 - val_mean_absolute_error: 0.0840\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0069 - mean_absolute_error: 0.0019 - val_loss: 1.2149 - val_mean_absolute_error: 0.0868\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0060 - mean_absolute_error: 0.0018 - val_loss: 1.2676 - val_mean_absolute_error: 0.0839\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0073 - mean_absolute_error: 0.0019 - val_loss: 1.2261 - val_mean_absolute_error: 0.0880\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0067 - mean_absolute_error: 0.0020 - val_loss: 1.2883 - val_mean_absolute_error: 0.0862\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0070 - mean_absolute_error: 0.0020 - val_loss: 1.2894 - val_mean_absolute_error: 0.0848\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0068 - mean_absolute_error: 0.0019 - val_loss: 1.2586 - val_mean_absolute_error: 0.0850\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0068 - mean_absolute_error: 0.0020 - val_loss: 1.3175 - val_mean_absolute_error: 0.0838\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0092 - mean_absolute_error: 0.0024 - val_loss: 1.2312 - val_mean_absolute_error: 0.0848\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0783 - mean_absolute_error: 0.0199 - val_loss: 0.8435 - val_mean_absolute_error: 0.1116\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0976 - mean_absolute_error: 0.0294 - val_loss: 0.9096 - val_mean_absolute_error: 0.1015\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0354 - mean_absolute_error: 0.0117 - val_loss: 0.9914 - val_mean_absolute_error: 0.0981\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0211 - mean_absolute_error: 0.0064 - val_loss: 1.0700 - val_mean_absolute_error: 0.0891\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0125 - mean_absolute_error: 0.0040 - val_loss: 1.1051 - val_mean_absolute_error: 0.0880\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0095 - mean_absolute_error: 0.0029 - val_loss: 1.1433 - val_mean_absolute_error: 0.0858\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0097 - mean_absolute_error: 0.0026 - val_loss: 1.1674 - val_mean_absolute_error: 0.0855\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0084 - mean_absolute_error: 0.0023 - val_loss: 1.1676 - val_mean_absolute_error: 0.0880\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0084 - mean_absolute_error: 0.0022 - val_loss: 1.2247 - val_mean_absolute_error: 0.0870\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0082 - mean_absolute_error: 0.0022 - val_loss: 1.1786 - val_mean_absolute_error: 0.0889\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0068 - mean_absolute_error: 0.0021 - val_loss: 1.2309 - val_mean_absolute_error: 0.0868\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0064 - mean_absolute_error: 0.0020 - val_loss: 1.2509 - val_mean_absolute_error: 0.0877\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0072 - mean_absolute_error: 0.0021 - val_loss: 1.2535 - val_mean_absolute_error: 0.0879\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0075 - mean_absolute_error: 0.0021 - val_loss: 1.2907 - val_mean_absolute_error: 0.0866\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0064 - mean_absolute_error: 0.0019 - val_loss: 1.2600 - val_mean_absolute_error: 0.0870\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0076 - mean_absolute_error: 0.0022 - val_loss: 1.2607 - val_mean_absolute_error: 0.0868\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0064 - mean_absolute_error: 0.0019 - val_loss: 1.3141 - val_mean_absolute_error: 0.0862\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0066 - mean_absolute_error: 0.0019 - val_loss: 1.3179 - val_mean_absolute_error: 0.0866\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0064 - mean_absolute_error: 0.0020 - val_loss: 1.2968 - val_mean_absolute_error: 0.0865\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0080 - mean_absolute_error: 0.0022 - val_loss: 1.3385 - val_mean_absolute_error: 0.0864\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0102 - mean_absolute_error: 0.0026 - val_loss: 1.2823 - val_mean_absolute_error: 0.0891\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0086 - mean_absolute_error: 0.0023 - val_loss: 1.3233 - val_mean_absolute_error: 0.0862\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0090 - mean_absolute_error: 0.0023 - val_loss: 1.2811 - val_mean_absolute_error: 0.0863\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0067 - mean_absolute_error: 0.0018 - val_loss: 1.3188 - val_mean_absolute_error: 0.0880\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0072 - mean_absolute_error: 0.0021 - val_loss: 1.3371 - val_mean_absolute_error: 0.0864\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0072 - mean_absolute_error: 0.0020 - val_loss: 1.2699 - val_mean_absolute_error: 0.0921\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0072 - mean_absolute_error: 0.0021 - val_loss: 1.3953 - val_mean_absolute_error: 0.0887\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0807 - mean_absolute_error: 0.0203 - val_loss: 0.9056 - val_mean_absolute_error: 0.0993\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0779 - mean_absolute_error: 0.0222 - val_loss: 0.9939 - val_mean_absolute_error: 0.1021\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0249 - mean_absolute_error: 0.0082 - val_loss: 1.1024 - val_mean_absolute_error: 0.0932\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0119 - mean_absolute_error: 0.0036 - val_loss: 1.1906 - val_mean_absolute_error: 0.0887\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0131 - mean_absolute_error: 0.0037 - val_loss: 1.1325 - val_mean_absolute_error: 0.0878\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0078 - mean_absolute_error: 0.0023 - val_loss: 1.1653 - val_mean_absolute_error: 0.0852\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0080 - mean_absolute_error: 0.0022 - val_loss: 1.1922 - val_mean_absolute_error: 0.0861\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0075 - mean_absolute_error: 0.0022 - val_loss: 1.2613 - val_mean_absolute_error: 0.0860\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0063 - mean_absolute_error: 0.0020 - val_loss: 1.2680 - val_mean_absolute_error: 0.0859\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0066 - mean_absolute_error: 0.0020 - val_loss: 1.2390 - val_mean_absolute_error: 0.0870\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_17 (Bidirecti  (None, 200)              490400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 491,204\n",
      "Trainable params: 491,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 24s 175ms/step - loss: 0.5870 - mean_absolute_error: 0.1465 - val_loss: 0.5758 - val_mean_absolute_error: 0.1302\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 23s 173ms/step - loss: 0.4594 - mean_absolute_error: 0.1144 - val_loss: 0.5336 - val_mean_absolute_error: 0.1403\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 23s 173ms/step - loss: 0.3942 - mean_absolute_error: 0.1030 - val_loss: 0.5055 - val_mean_absolute_error: 0.1180\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.3652 - mean_absolute_error: 0.0949 - val_loss: 0.5096 - val_mean_absolute_error: 0.1082\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.2929 - mean_absolute_error: 0.0786 - val_loss: 0.5482 - val_mean_absolute_error: 0.1109\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.2385 - mean_absolute_error: 0.0677 - val_loss: 0.5541 - val_mean_absolute_error: 0.1043\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.1981 - mean_absolute_error: 0.0583 - val_loss: 0.5804 - val_mean_absolute_error: 0.1004\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.1444 - mean_absolute_error: 0.0444 - val_loss: 0.6409 - val_mean_absolute_error: 0.0972\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0988 - mean_absolute_error: 0.0322 - val_loss: 0.7690 - val_mean_absolute_error: 0.0922\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0753 - mean_absolute_error: 0.0249 - val_loss: 0.6470 - val_mean_absolute_error: 0.0928\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0450 - mean_absolute_error: 0.0161 - val_loss: 0.8346 - val_mean_absolute_error: 0.0858\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0370 - mean_absolute_error: 0.0120 - val_loss: 0.8210 - val_mean_absolute_error: 0.0822\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0259 - mean_absolute_error: 0.0083 - val_loss: 0.8850 - val_mean_absolute_error: 0.0921\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0464 - mean_absolute_error: 0.0144 - val_loss: 0.8727 - val_mean_absolute_error: 0.0881\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0472 - mean_absolute_error: 0.0154 - val_loss: 0.8266 - val_mean_absolute_error: 0.0880\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0298 - mean_absolute_error: 0.0095 - val_loss: 0.8664 - val_mean_absolute_error: 0.0838\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0192 - mean_absolute_error: 0.0056 - val_loss: 0.9477 - val_mean_absolute_error: 0.0800\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0167 - mean_absolute_error: 0.0044 - val_loss: 1.0233 - val_mean_absolute_error: 0.0811\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0137 - mean_absolute_error: 0.0039 - val_loss: 0.9795 - val_mean_absolute_error: 0.0834\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0142 - mean_absolute_error: 0.0034 - val_loss: 1.0215 - val_mean_absolute_error: 0.0861\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0117 - mean_absolute_error: 0.0032 - val_loss: 1.0711 - val_mean_absolute_error: 0.0815\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0108 - mean_absolute_error: 0.0029 - val_loss: 1.1441 - val_mean_absolute_error: 0.0813\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0114 - mean_absolute_error: 0.0031 - val_loss: 1.0802 - val_mean_absolute_error: 0.0812\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0119 - mean_absolute_error: 0.0033 - val_loss: 1.0682 - val_mean_absolute_error: 0.0870\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0422 - mean_absolute_error: 0.0128 - val_loss: 0.8455 - val_mean_absolute_error: 0.0867\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0778 - mean_absolute_error: 0.0233 - val_loss: 0.9645 - val_mean_absolute_error: 0.0926\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0528 - mean_absolute_error: 0.0159 - val_loss: 0.7726 - val_mean_absolute_error: 0.0902\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0208 - mean_absolute_error: 0.0068 - val_loss: 0.9703 - val_mean_absolute_error: 0.0830\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0153 - mean_absolute_error: 0.0045 - val_loss: 0.9492 - val_mean_absolute_error: 0.0799\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0140 - mean_absolute_error: 0.0033 - val_loss: 1.0373 - val_mean_absolute_error: 0.0847\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0105 - mean_absolute_error: 0.0032 - val_loss: 1.1302 - val_mean_absolute_error: 0.0767\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0100 - mean_absolute_error: 0.0026 - val_loss: 1.0659 - val_mean_absolute_error: 0.0784\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0098 - mean_absolute_error: 0.0026 - val_loss: 1.0610 - val_mean_absolute_error: 0.0769\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0098 - mean_absolute_error: 0.0027 - val_loss: 1.0764 - val_mean_absolute_error: 0.0773\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0093 - mean_absolute_error: 0.0026 - val_loss: 1.1398 - val_mean_absolute_error: 0.0782\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0086 - mean_absolute_error: 0.0023 - val_loss: 1.1357 - val_mean_absolute_error: 0.0777\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0092 - mean_absolute_error: 0.0025 - val_loss: 1.1143 - val_mean_absolute_error: 0.0794\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0090 - mean_absolute_error: 0.0025 - val_loss: 1.1374 - val_mean_absolute_error: 0.0769\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 23s 173ms/step - loss: 0.0086 - mean_absolute_error: 0.0023 - val_loss: 1.1683 - val_mean_absolute_error: 0.0761\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0108 - mean_absolute_error: 0.0027 - val_loss: 1.1388 - val_mean_absolute_error: 0.0760\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0095 - mean_absolute_error: 0.0025 - val_loss: 1.1875 - val_mean_absolute_error: 0.0790\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0080 - mean_absolute_error: 0.0021 - val_loss: 1.1307 - val_mean_absolute_error: 0.0782\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0077 - mean_absolute_error: 0.0023 - val_loss: 1.2458 - val_mean_absolute_error: 0.0761\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0106 - mean_absolute_error: 0.0027 - val_loss: 1.1514 - val_mean_absolute_error: 0.0803\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0959 - mean_absolute_error: 0.0267 - val_loss: 0.8010 - val_mean_absolute_error: 0.0892\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0785 - mean_absolute_error: 0.0240 - val_loss: 0.8467 - val_mean_absolute_error: 0.0896\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0396 - mean_absolute_error: 0.0122 - val_loss: 1.1140 - val_mean_absolute_error: 0.0869\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0284 - mean_absolute_error: 0.0084 - val_loss: 0.9614 - val_mean_absolute_error: 0.0841\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0148 - mean_absolute_error: 0.0049 - val_loss: 1.0612 - val_mean_absolute_error: 0.0803\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0114 - mean_absolute_error: 0.0033 - val_loss: 1.1134 - val_mean_absolute_error: 0.0803\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0102 - mean_absolute_error: 0.0028 - val_loss: 1.0717 - val_mean_absolute_error: 0.0802\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0094 - mean_absolute_error: 0.0024 - val_loss: 1.1462 - val_mean_absolute_error: 0.0799\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0101 - mean_absolute_error: 0.0028 - val_loss: 1.1425 - val_mean_absolute_error: 0.0794\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0095 - mean_absolute_error: 0.0027 - val_loss: 1.1785 - val_mean_absolute_error: 0.0788\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0101 - mean_absolute_error: 0.0025 - val_loss: 1.1566 - val_mean_absolute_error: 0.0790\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0101 - mean_absolute_error: 0.0026 - val_loss: 1.1193 - val_mean_absolute_error: 0.0805\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0115 - mean_absolute_error: 0.0032 - val_loss: 1.1571 - val_mean_absolute_error: 0.0786\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0093 - mean_absolute_error: 0.0025 - val_loss: 1.1923 - val_mean_absolute_error: 0.0789\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0093 - mean_absolute_error: 0.0022 - val_loss: 1.1654 - val_mean_absolute_error: 0.0794\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0088 - mean_absolute_error: 0.0025 - val_loss: 1.2470 - val_mean_absolute_error: 0.0792\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0142 - mean_absolute_error: 0.0040 - val_loss: 1.1245 - val_mean_absolute_error: 0.0791\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0197 - mean_absolute_error: 0.0061 - val_loss: 1.1674 - val_mean_absolute_error: 0.0833\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0336 - mean_absolute_error: 0.0100 - val_loss: 0.9714 - val_mean_absolute_error: 0.0827\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0188 - mean_absolute_error: 0.0051 - val_loss: 1.0111 - val_mean_absolute_error: 0.0813\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0133 - mean_absolute_error: 0.0036 - val_loss: 1.1111 - val_mean_absolute_error: 0.0783\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0105 - mean_absolute_error: 0.0024 - val_loss: 1.1288 - val_mean_absolute_error: 0.0783\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0095 - mean_absolute_error: 0.0024 - val_loss: 1.1520 - val_mean_absolute_error: 0.0770\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0081 - mean_absolute_error: 0.0023 - val_loss: 1.1642 - val_mean_absolute_error: 0.0772\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0084 - mean_absolute_error: 0.0024 - val_loss: 1.1883 - val_mean_absolute_error: 0.0773\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0079 - mean_absolute_error: 0.0021 - val_loss: 1.1851 - val_mean_absolute_error: 0.0782\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0089 - mean_absolute_error: 0.0024 - val_loss: 1.2477 - val_mean_absolute_error: 0.0760\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0078 - mean_absolute_error: 0.0022 - val_loss: 1.2421 - val_mean_absolute_error: 0.0776\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0087 - mean_absolute_error: 0.0023 - val_loss: 1.2310 - val_mean_absolute_error: 0.0771\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0085 - mean_absolute_error: 0.0023 - val_loss: 1.2300 - val_mean_absolute_error: 0.0766\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0078 - mean_absolute_error: 0.0022 - val_loss: 1.2238 - val_mean_absolute_error: 0.0779\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0076 - mean_absolute_error: 0.0022 - val_loss: 1.2697 - val_mean_absolute_error: 0.0760\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0078 - mean_absolute_error: 0.0022 - val_loss: 1.2854 - val_mean_absolute_error: 0.0760\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0078 - mean_absolute_error: 0.0021 - val_loss: 1.2430 - val_mean_absolute_error: 0.0778\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0085 - mean_absolute_error: 0.0024 - val_loss: 1.2947 - val_mean_absolute_error: 0.0761\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0088 - mean_absolute_error: 0.0024 - val_loss: 1.3058 - val_mean_absolute_error: 0.0761\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0075 - mean_absolute_error: 0.0022 - val_loss: 1.2831 - val_mean_absolute_error: 0.0770\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0077 - mean_absolute_error: 0.0022 - val_loss: 1.2681 - val_mean_absolute_error: 0.0771\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 23s 173ms/step - loss: 0.0077 - mean_absolute_error: 0.0021 - val_loss: 1.3105 - val_mean_absolute_error: 0.0770\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 22s 170ms/step - loss: 0.0095 - mean_absolute_error: 0.0022 - val_loss: 1.2436 - val_mean_absolute_error: 0.0786\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0088 - mean_absolute_error: 0.0023 - val_loss: 1.2514 - val_mean_absolute_error: 0.0757\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0078 - mean_absolute_error: 0.0020 - val_loss: 1.2905 - val_mean_absolute_error: 0.0775\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0086 - mean_absolute_error: 0.0023 - val_loss: 1.2953 - val_mean_absolute_error: 0.0764\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 23s 173ms/step - loss: 0.0086 - mean_absolute_error: 0.0023 - val_loss: 1.2695 - val_mean_absolute_error: 0.0772\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0090 - mean_absolute_error: 0.0024 - val_loss: 1.3022 - val_mean_absolute_error: 0.0783\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0495 - mean_absolute_error: 0.0127 - val_loss: 0.8018 - val_mean_absolute_error: 0.0939\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 22s 173ms/step - loss: 0.0770 - mean_absolute_error: 0.0224 - val_loss: 0.8790 - val_mean_absolute_error: 0.0903\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0334 - mean_absolute_error: 0.0103 - val_loss: 0.9603 - val_mean_absolute_error: 0.0844\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0141 - mean_absolute_error: 0.0043 - val_loss: 1.0550 - val_mean_absolute_error: 0.0805\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0104 - mean_absolute_error: 0.0028 - val_loss: 1.1289 - val_mean_absolute_error: 0.0783\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0092 - mean_absolute_error: 0.0025 - val_loss: 1.1559 - val_mean_absolute_error: 0.0784\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0085 - mean_absolute_error: 0.0024 - val_loss: 1.1524 - val_mean_absolute_error: 0.0803\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0079 - mean_absolute_error: 0.0023 - val_loss: 1.1744 - val_mean_absolute_error: 0.0789\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 22s 171ms/step - loss: 0.0077 - mean_absolute_error: 0.0023 - val_loss: 1.1936 - val_mean_absolute_error: 0.0793\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 22s 172ms/step - loss: 0.0078 - mean_absolute_error: 0.0023 - val_loss: 1.2116 - val_mean_absolute_error: 0.0790\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0086 - mean_absolute_error: 0.0022 - val_loss: 1.2434 - val_mean_absolute_error: 0.0782\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_18 (Bidirecti  (None, 200)              490400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 491,204\n",
      "Trainable params: 491,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 24s 178ms/step - loss: 0.6306 - mean_absolute_error: 0.1529 - val_loss: 0.5428 - val_mean_absolute_error: 0.1294\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.5090 - mean_absolute_error: 0.1293 - val_loss: 0.5154 - val_mean_absolute_error: 0.1329\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.4491 - mean_absolute_error: 0.1153 - val_loss: 0.5062 - val_mean_absolute_error: 0.1212\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.3862 - mean_absolute_error: 0.1031 - val_loss: 0.4880 - val_mean_absolute_error: 0.1071\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.3300 - mean_absolute_error: 0.0906 - val_loss: 0.5435 - val_mean_absolute_error: 0.0950\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.2616 - mean_absolute_error: 0.0754 - val_loss: 0.5139 - val_mean_absolute_error: 0.0914\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.2095 - mean_absolute_error: 0.0622 - val_loss: 0.5557 - val_mean_absolute_error: 0.0981\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.1441 - mean_absolute_error: 0.0459 - val_loss: 0.5736 - val_mean_absolute_error: 0.0901\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.1035 - mean_absolute_error: 0.0348 - val_loss: 0.6310 - val_mean_absolute_error: 0.0923\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0732 - mean_absolute_error: 0.0245 - val_loss: 0.8055 - val_mean_absolute_error: 0.0803\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0528 - mean_absolute_error: 0.0186 - val_loss: 0.7306 - val_mean_absolute_error: 0.0825\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0366 - mean_absolute_error: 0.0128 - val_loss: 0.6845 - val_mean_absolute_error: 0.0895\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0337 - mean_absolute_error: 0.0117 - val_loss: 0.7643 - val_mean_absolute_error: 0.0820\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0252 - mean_absolute_error: 0.0079 - val_loss: 0.7815 - val_mean_absolute_error: 0.0873\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0257 - mean_absolute_error: 0.0086 - val_loss: 1.1313 - val_mean_absolute_error: 0.0738\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0256 - mean_absolute_error: 0.0084 - val_loss: 0.8388 - val_mean_absolute_error: 0.0899\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0310 - mean_absolute_error: 0.0104 - val_loss: 0.8421 - val_mean_absolute_error: 0.0811\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0162 - mean_absolute_error: 0.0045 - val_loss: 0.9170 - val_mean_absolute_error: 0.0837\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0161 - mean_absolute_error: 0.0050 - val_loss: 0.9191 - val_mean_absolute_error: 0.0782\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0162 - mean_absolute_error: 0.0051 - val_loss: 0.9260 - val_mean_absolute_error: 0.0801\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0106 - mean_absolute_error: 0.0030 - val_loss: 1.0537 - val_mean_absolute_error: 0.0790\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0071 - mean_absolute_error: 0.0019 - val_loss: 1.0041 - val_mean_absolute_error: 0.0821\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0078 - mean_absolute_error: 0.0021 - val_loss: 1.0888 - val_mean_absolute_error: 0.0770\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0104 - mean_absolute_error: 0.0028 - val_loss: 0.9387 - val_mean_absolute_error: 0.0850\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0120 - mean_absolute_error: 0.0031 - val_loss: 1.0938 - val_mean_absolute_error: 0.0810\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0554 - mean_absolute_error: 0.0176 - val_loss: 0.8999 - val_mean_absolute_error: 0.0777\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0413 - mean_absolute_error: 0.0131 - val_loss: 0.8602 - val_mean_absolute_error: 0.0850\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0248 - mean_absolute_error: 0.0087 - val_loss: 0.8725 - val_mean_absolute_error: 0.0833\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0142 - mean_absolute_error: 0.0042 - val_loss: 1.0263 - val_mean_absolute_error: 0.0737\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0104 - mean_absolute_error: 0.0028 - val_loss: 1.0565 - val_mean_absolute_error: 0.0755\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0082 - mean_absolute_error: 0.0024 - val_loss: 1.0564 - val_mean_absolute_error: 0.0759\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0072 - mean_absolute_error: 0.0017 - val_loss: 1.0541 - val_mean_absolute_error: 0.0745\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0079 - mean_absolute_error: 0.0016 - val_loss: 1.0201 - val_mean_absolute_error: 0.0761\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0057 - mean_absolute_error: 0.0015 - val_loss: 1.1036 - val_mean_absolute_error: 0.0744\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0059 - mean_absolute_error: 0.0016 - val_loss: 1.0986 - val_mean_absolute_error: 0.0756\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0059 - mean_absolute_error: 0.0016 - val_loss: 1.1521 - val_mean_absolute_error: 0.0734\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0067 - mean_absolute_error: 0.0015 - val_loss: 1.2058 - val_mean_absolute_error: 0.0725\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0065 - mean_absolute_error: 0.0016 - val_loss: 1.1334 - val_mean_absolute_error: 0.0738\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0056 - mean_absolute_error: 0.0014 - val_loss: 1.1788 - val_mean_absolute_error: 0.0734\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0060 - mean_absolute_error: 0.0015 - val_loss: 1.1837 - val_mean_absolute_error: 0.0723\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0056 - mean_absolute_error: 0.0012 - val_loss: 1.2275 - val_mean_absolute_error: 0.0736\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0066 - mean_absolute_error: 0.0017 - val_loss: 1.1979 - val_mean_absolute_error: 0.0721\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0053 - mean_absolute_error: 0.0012 - val_loss: 1.1816 - val_mean_absolute_error: 0.0721\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0058 - mean_absolute_error: 0.0014 - val_loss: 1.1927 - val_mean_absolute_error: 0.0744\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0068 - mean_absolute_error: 0.0015 - val_loss: 1.2537 - val_mean_absolute_error: 0.0723\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0069 - mean_absolute_error: 0.0016 - val_loss: 1.2276 - val_mean_absolute_error: 0.0738\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0048 - mean_absolute_error: 0.0013 - val_loss: 1.2741 - val_mean_absolute_error: 0.0729\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0053 - mean_absolute_error: 0.0013 - val_loss: 1.2236 - val_mean_absolute_error: 0.0718\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0044 - mean_absolute_error: 0.0012 - val_loss: 1.2531 - val_mean_absolute_error: 0.0723\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0052 - mean_absolute_error: 0.0012 - val_loss: 1.3118 - val_mean_absolute_error: 0.0719\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0056 - mean_absolute_error: 0.0014 - val_loss: 1.3300 - val_mean_absolute_error: 0.0732\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0057 - mean_absolute_error: 0.0014 - val_loss: 1.2945 - val_mean_absolute_error: 0.0718\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0055 - mean_absolute_error: 0.0013 - val_loss: 1.3454 - val_mean_absolute_error: 0.0723\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0056 - mean_absolute_error: 0.0013 - val_loss: 1.2130 - val_mean_absolute_error: 0.0739\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.1066 - mean_absolute_error: 0.0234 - val_loss: 0.6974 - val_mean_absolute_error: 0.0984\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.1466 - mean_absolute_error: 0.0421 - val_loss: 0.7458 - val_mean_absolute_error: 0.0887\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0547 - mean_absolute_error: 0.0185 - val_loss: 0.8431 - val_mean_absolute_error: 0.0853\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0234 - mean_absolute_error: 0.0082 - val_loss: 0.8736 - val_mean_absolute_error: 0.0801\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0117 - mean_absolute_error: 0.0038 - val_loss: 0.9962 - val_mean_absolute_error: 0.0780\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0096 - mean_absolute_error: 0.0030 - val_loss: 0.9725 - val_mean_absolute_error: 0.0787\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0065 - mean_absolute_error: 0.0019 - val_loss: 1.0070 - val_mean_absolute_error: 0.0791\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0068 - mean_absolute_error: 0.0019 - val_loss: 1.0392 - val_mean_absolute_error: 0.0773\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0065 - mean_absolute_error: 0.0017 - val_loss: 1.0773 - val_mean_absolute_error: 0.0763\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0078 - mean_absolute_error: 0.0019 - val_loss: 1.0486 - val_mean_absolute_error: 0.0786\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0054 - mean_absolute_error: 0.0015 - val_loss: 1.0926 - val_mean_absolute_error: 0.0783\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0051 - mean_absolute_error: 0.0014 - val_loss: 1.1089 - val_mean_absolute_error: 0.0766\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0050 - mean_absolute_error: 0.0015 - val_loss: 1.1579 - val_mean_absolute_error: 0.0753\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0058 - mean_absolute_error: 0.0014 - val_loss: 1.1555 - val_mean_absolute_error: 0.0755\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0057 - mean_absolute_error: 0.0016 - val_loss: 1.1587 - val_mean_absolute_error: 0.0759\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0049 - mean_absolute_error: 0.0014 - val_loss: 1.1563 - val_mean_absolute_error: 0.0767\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0063 - mean_absolute_error: 0.0015 - val_loss: 1.1566 - val_mean_absolute_error: 0.0770\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0060 - mean_absolute_error: 0.0015 - val_loss: 1.1740 - val_mean_absolute_error: 0.0782\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0065 - mean_absolute_error: 0.0017 - val_loss: 1.2679 - val_mean_absolute_error: 0.0749\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0065 - mean_absolute_error: 0.0016 - val_loss: 1.2237 - val_mean_absolute_error: 0.0748\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0059 - mean_absolute_error: 0.0015 - val_loss: 1.1821 - val_mean_absolute_error: 0.0790\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0051 - mean_absolute_error: 0.0012 - val_loss: 1.3000 - val_mean_absolute_error: 0.0750\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0047 - mean_absolute_error: 0.0014 - val_loss: 1.2591 - val_mean_absolute_error: 0.0771\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0055 - mean_absolute_error: 0.0014 - val_loss: 1.2262 - val_mean_absolute_error: 0.0783\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 23s 180ms/step - loss: 0.0047 - mean_absolute_error: 0.0012 - val_loss: 1.2443 - val_mean_absolute_error: 0.0786\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 23s 179ms/step - loss: 0.0053 - mean_absolute_error: 0.0014 - val_loss: 1.2383 - val_mean_absolute_error: 0.0805\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0059 - mean_absolute_error: 0.0013 - val_loss: 1.3079 - val_mean_absolute_error: 0.0768\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 23s 174ms/step - loss: 0.0046 - mean_absolute_error: 0.0012 - val_loss: 1.3677 - val_mean_absolute_error: 0.0759\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0043 - mean_absolute_error: 0.0013 - val_loss: 1.3300 - val_mean_absolute_error: 0.0782\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0048 - mean_absolute_error: 0.0012 - val_loss: 1.3412 - val_mean_absolute_error: 0.0774\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 23s 175ms/step - loss: 0.0056 - mean_absolute_error: 0.0013 - val_loss: 1.3045 - val_mean_absolute_error: 0.0782\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 23s 176ms/step - loss: 0.0044 - mean_absolute_error: 0.0012 - val_loss: 1.3104 - val_mean_absolute_error: 0.0800\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0046 - mean_absolute_error: 0.0012 - val_loss: 1.3017 - val_mean_absolute_error: 0.0793\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0039 - mean_absolute_error: 0.0011 - val_loss: 1.3726 - val_mean_absolute_error: 0.0768\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0044 - mean_absolute_error: 0.0013 - val_loss: 1.3839 - val_mean_absolute_error: 0.0784\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.1301 - mean_absolute_error: 0.0325 - val_loss: 0.7960 - val_mean_absolute_error: 0.0925\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0493 - mean_absolute_error: 0.0152 - val_loss: 0.8891 - val_mean_absolute_error: 0.0884\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0257 - mean_absolute_error: 0.0083 - val_loss: 1.0084 - val_mean_absolute_error: 0.0765\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0100 - mean_absolute_error: 0.0032 - val_loss: 0.9557 - val_mean_absolute_error: 0.0833\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0062 - mean_absolute_error: 0.0019 - val_loss: 1.0420 - val_mean_absolute_error: 0.0768\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0055 - mean_absolute_error: 0.0017 - val_loss: 1.0611 - val_mean_absolute_error: 0.0773\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0050 - mean_absolute_error: 0.0016 - val_loss: 1.1121 - val_mean_absolute_error: 0.0756\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0049 - mean_absolute_error: 0.0014 - val_loss: 1.0908 - val_mean_absolute_error: 0.0778\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0050 - mean_absolute_error: 0.0014 - val_loss: 1.1425 - val_mean_absolute_error: 0.0761\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 23s 177ms/step - loss: 0.0055 - mean_absolute_error: 0.0015 - val_loss: 1.1805 - val_mean_absolute_error: 0.0751\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 23s 178ms/step - loss: 0.0051 - mean_absolute_error: 0.0015 - val_loss: 1.1499 - val_mean_absolute_error: 0.0768\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_19 (Bidirecti  (None, 200)              490400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 491,204\n",
      "Trainable params: 491,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 27s 189ms/step - loss: 0.2189 - mean_absolute_error: 0.0464 - val_loss: 0.1383 - val_mean_absolute_error: 0.0308\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.1406 - mean_absolute_error: 0.0324 - val_loss: 0.1213 - val_mean_absolute_error: 0.0320\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.1124 - mean_absolute_error: 0.0275 - val_loss: 0.1316 - val_mean_absolute_error: 0.0244\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0898 - mean_absolute_error: 0.0232 - val_loss: 0.1126 - val_mean_absolute_error: 0.0237\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0690 - mean_absolute_error: 0.0188 - val_loss: 0.1194 - val_mean_absolute_error: 0.0269\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0476 - mean_absolute_error: 0.0147 - val_loss: 0.1217 - val_mean_absolute_error: 0.0189\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0324 - mean_absolute_error: 0.0101 - val_loss: 0.1150 - val_mean_absolute_error: 0.0195\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0254 - mean_absolute_error: 0.0085 - val_loss: 0.1177 - val_mean_absolute_error: 0.0201\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0190 - mean_absolute_error: 0.0062 - val_loss: 0.1617 - val_mean_absolute_error: 0.0179\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0110 - mean_absolute_error: 0.0038 - val_loss: 0.1341 - val_mean_absolute_error: 0.0187\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0067 - mean_absolute_error: 0.0022 - val_loss: 0.1423 - val_mean_absolute_error: 0.0174\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0078 - mean_absolute_error: 0.0022 - val_loss: 0.1537 - val_mean_absolute_error: 0.0163\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0062 - mean_absolute_error: 0.0018 - val_loss: 0.1765 - val_mean_absolute_error: 0.0175\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0143 - mean_absolute_error: 0.0050 - val_loss: 0.1327 - val_mean_absolute_error: 0.0168\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0099 - mean_absolute_error: 0.0033 - val_loss: 0.1671 - val_mean_absolute_error: 0.0178\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0072 - mean_absolute_error: 0.0020 - val_loss: 0.1524 - val_mean_absolute_error: 0.0168\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0060 - mean_absolute_error: 0.0017 - val_loss: 0.1463 - val_mean_absolute_error: 0.0186\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0079 - mean_absolute_error: 0.0024 - val_loss: 0.1629 - val_mean_absolute_error: 0.0155\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0087 - mean_absolute_error: 0.0024 - val_loss: 0.1686 - val_mean_absolute_error: 0.0296\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0127 - mean_absolute_error: 0.0038 - val_loss: 0.1682 - val_mean_absolute_error: 0.0175\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0137 - mean_absolute_error: 0.0041 - val_loss: 0.1500 - val_mean_absolute_error: 0.0242\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0103 - mean_absolute_error: 0.0031 - val_loss: 0.1625 - val_mean_absolute_error: 0.0166\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0059 - mean_absolute_error: 0.0014 - val_loss: 0.1878 - val_mean_absolute_error: 0.0174\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0040 - mean_absolute_error: 0.0011 - val_loss: 0.1894 - val_mean_absolute_error: 0.0169\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0039 - mean_absolute_error: 0.0010 - val_loss: 0.1903 - val_mean_absolute_error: 0.0162\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0044 - mean_absolute_error: 0.0011 - val_loss: 0.2041 - val_mean_absolute_error: 0.0156\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0041 - mean_absolute_error: 9.7029e-04 - val_loss: 0.1927 - val_mean_absolute_error: 0.0165\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0038 - mean_absolute_error: 9.9385e-04 - val_loss: 0.1924 - val_mean_absolute_error: 0.0164\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0034 - mean_absolute_error: 8.7615e-04 - val_loss: 0.2263 - val_mean_absolute_error: 0.0170\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0035 - mean_absolute_error: 9.7979e-04 - val_loss: 0.2091 - val_mean_absolute_error: 0.0163\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0035 - mean_absolute_error: 9.3993e-04 - val_loss: 0.1964 - val_mean_absolute_error: 0.0162\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0030 - mean_absolute_error: 8.8339e-04 - val_loss: 0.2031 - val_mean_absolute_error: 0.0168\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0040 - mean_absolute_error: 9.6891e-04 - val_loss: 0.1945 - val_mean_absolute_error: 0.0158\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0069 - mean_absolute_error: 0.0018 - val_loss: 0.1655 - val_mean_absolute_error: 0.0209\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0326 - mean_absolute_error: 0.0097 - val_loss: 0.1399 - val_mean_absolute_error: 0.0197\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0155 - mean_absolute_error: 0.0048 - val_loss: 0.1653 - val_mean_absolute_error: 0.0228\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0113 - mean_absolute_error: 0.0035 - val_loss: 0.1404 - val_mean_absolute_error: 0.0205\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0075 - mean_absolute_error: 0.0021 - val_loss: 0.1702 - val_mean_absolute_error: 0.0160\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0052 - mean_absolute_error: 0.0012 - val_loss: 0.1726 - val_mean_absolute_error: 0.0165\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0039 - mean_absolute_error: 9.9936e-04 - val_loss: 0.1808 - val_mean_absolute_error: 0.0161\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0037 - mean_absolute_error: 9.3324e-04 - val_loss: 0.1883 - val_mean_absolute_error: 0.0156\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0037 - mean_absolute_error: 9.7581e-04 - val_loss: 0.2000 - val_mean_absolute_error: 0.0158\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0034 - mean_absolute_error: 9.1849e-04 - val_loss: 0.1903 - val_mean_absolute_error: 0.0159\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0036 - mean_absolute_error: 8.8988e-04 - val_loss: 0.1922 - val_mean_absolute_error: 0.0157\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0036 - mean_absolute_error: 8.9733e-04 - val_loss: 0.1875 - val_mean_absolute_error: 0.0163\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0037 - mean_absolute_error: 9.7542e-04 - val_loss: 0.2185 - val_mean_absolute_error: 0.0160\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0032 - mean_absolute_error: 7.8850e-04 - val_loss: 0.1918 - val_mean_absolute_error: 0.0160\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0026 - mean_absolute_error: 7.8061e-04 - val_loss: 0.1974 - val_mean_absolute_error: 0.0161\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0034 - mean_absolute_error: 8.3353e-04 - val_loss: 0.1879 - val_mean_absolute_error: 0.0169\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0035 - mean_absolute_error: 8.7259e-04 - val_loss: 0.2080 - val_mean_absolute_error: 0.0161\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0030 - mean_absolute_error: 7.3367e-04 - val_loss: 0.1967 - val_mean_absolute_error: 0.0163\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0035 - mean_absolute_error: 9.6927e-04 - val_loss: 0.2059 - val_mean_absolute_error: 0.0159\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0031 - mean_absolute_error: 8.0018e-04 - val_loss: 0.2038 - val_mean_absolute_error: 0.0165\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0028 - mean_absolute_error: 7.5995e-04 - val_loss: 0.1922 - val_mean_absolute_error: 0.0166\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0026 - mean_absolute_error: 7.6361e-04 - val_loss: 0.2095 - val_mean_absolute_error: 0.0163\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0031 - mean_absolute_error: 7.8233e-04 - val_loss: 0.2352 - val_mean_absolute_error: 0.0159\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0031 - mean_absolute_error: 7.7542e-04 - val_loss: 0.2243 - val_mean_absolute_error: 0.0163\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0030 - mean_absolute_error: 7.5053e-04 - val_loss: 0.2193 - val_mean_absolute_error: 0.0161\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0029 - mean_absolute_error: 6.8508e-04 - val_loss: 0.2009 - val_mean_absolute_error: 0.0166\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0037 - mean_absolute_error: 9.1358e-04 - val_loss: 0.2240 - val_mean_absolute_error: 0.0166\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0041 - mean_absolute_error: 8.2479e-04 - val_loss: 0.1924 - val_mean_absolute_error: 0.0200\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0361 - mean_absolute_error: 0.0093 - val_loss: 0.1448 - val_mean_absolute_error: 0.0206\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0177 - mean_absolute_error: 0.0057 - val_loss: 0.1530 - val_mean_absolute_error: 0.0164\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0078 - mean_absolute_error: 0.0024 - val_loss: 0.1567 - val_mean_absolute_error: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0040 - mean_absolute_error: 0.0010 - val_loss: 0.1577 - val_mean_absolute_error: 0.0165\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0040 - mean_absolute_error: 9.1138e-04 - val_loss: 0.1643 - val_mean_absolute_error: 0.0163\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0028 - mean_absolute_error: 7.8523e-04 - val_loss: 0.1727 - val_mean_absolute_error: 0.0154\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0029 - mean_absolute_error: 8.3337e-04 - val_loss: 0.1803 - val_mean_absolute_error: 0.0150\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0030 - mean_absolute_error: 7.8332e-04 - val_loss: 0.1794 - val_mean_absolute_error: 0.0156\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0028 - mean_absolute_error: 7.8911e-04 - val_loss: 0.1878 - val_mean_absolute_error: 0.0150\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0037 - mean_absolute_error: 8.9106e-04 - val_loss: 0.1844 - val_mean_absolute_error: 0.0156\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0028 - mean_absolute_error: 8.1382e-04 - val_loss: 0.1861 - val_mean_absolute_error: 0.0153\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0028 - mean_absolute_error: 7.0685e-04 - val_loss: 0.1936 - val_mean_absolute_error: 0.0149\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0024 - mean_absolute_error: 7.3672e-04 - val_loss: 0.1929 - val_mean_absolute_error: 0.0150\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0030 - mean_absolute_error: 8.1921e-04 - val_loss: 0.1986 - val_mean_absolute_error: 0.0153\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0031 - mean_absolute_error: 8.1156e-04 - val_loss: 0.1886 - val_mean_absolute_error: 0.0152\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0031 - mean_absolute_error: 8.8828e-04 - val_loss: 0.2038 - val_mean_absolute_error: 0.0146\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0029 - mean_absolute_error: 7.6059e-04 - val_loss: 0.2059 - val_mean_absolute_error: 0.0149\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0028 - mean_absolute_error: 8.0178e-04 - val_loss: 0.1963 - val_mean_absolute_error: 0.0147\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0036 - mean_absolute_error: 8.1676e-04 - val_loss: 0.2095 - val_mean_absolute_error: 0.0148\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0039 - mean_absolute_error: 8.4368e-04 - val_loss: 0.2076 - val_mean_absolute_error: 0.0151\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0030 - mean_absolute_error: 8.0944e-04 - val_loss: 0.2085 - val_mean_absolute_error: 0.0152\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0031 - mean_absolute_error: 8.7518e-04 - val_loss: 0.2113 - val_mean_absolute_error: 0.0156\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0041 - mean_absolute_error: 8.3918e-04 - val_loss: 0.2020 - val_mean_absolute_error: 0.0148\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0035 - mean_absolute_error: 7.3146e-04 - val_loss: 0.2135 - val_mean_absolute_error: 0.0145\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0039 - mean_absolute_error: 8.6759e-04 - val_loss: 0.2005 - val_mean_absolute_error: 0.0149\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0031 - mean_absolute_error: 7.4087e-04 - val_loss: 0.2035 - val_mean_absolute_error: 0.0154\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0030 - mean_absolute_error: 7.5934e-04 - val_loss: 0.2100 - val_mean_absolute_error: 0.0143\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0036 - mean_absolute_error: 9.1146e-04 - val_loss: 0.2125 - val_mean_absolute_error: 0.0156\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0035 - mean_absolute_error: 8.3109e-04 - val_loss: 0.2125 - val_mean_absolute_error: 0.0153\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 25s 189ms/step - loss: 0.0030 - mean_absolute_error: 7.1006e-04 - val_loss: 0.2139 - val_mean_absolute_error: 0.0137\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0034 - mean_absolute_error: 9.5447e-04 - val_loss: 0.2135 - val_mean_absolute_error: 0.0149\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0028 - mean_absolute_error: 7.4041e-04 - val_loss: 0.2027 - val_mean_absolute_error: 0.0144\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0029 - mean_absolute_error: 7.3237e-04 - val_loss: 0.2073 - val_mean_absolute_error: 0.0152\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 24s 188ms/step - loss: 0.0028 - mean_absolute_error: 6.9534e-04 - val_loss: 0.2034 - val_mean_absolute_error: 0.0151\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0031 - mean_absolute_error: 8.0374e-04 - val_loss: 0.2285 - val_mean_absolute_error: 0.0148\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0026 - mean_absolute_error: 6.8502e-04 - val_loss: 0.2039 - val_mean_absolute_error: 0.0156\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0031 - mean_absolute_error: 8.1167e-04 - val_loss: 0.2235 - val_mean_absolute_error: 0.0155\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0029 - mean_absolute_error: 7.2046e-04 - val_loss: 0.2302 - val_mean_absolute_error: 0.0151\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0032 - mean_absolute_error: 7.7890e-04 - val_loss: 0.2143 - val_mean_absolute_error: 0.0147\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_20 (Bidirecti  (None, 200)              490400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 491,204\n",
      "Trainable params: 491,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 26s 186ms/step - loss: 0.4648 - mean_absolute_error: 0.1029 - val_loss: 0.4439 - val_mean_absolute_error: 0.1316\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.3892 - mean_absolute_error: 0.0951 - val_loss: 0.4038 - val_mean_absolute_error: 0.0945\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.3556 - mean_absolute_error: 0.0897 - val_loss: 0.3976 - val_mean_absolute_error: 0.0973\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.3056 - mean_absolute_error: 0.0809 - val_loss: 0.3941 - val_mean_absolute_error: 0.1011\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.2631 - mean_absolute_error: 0.0732 - val_loss: 0.4034 - val_mean_absolute_error: 0.0926\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.2110 - mean_absolute_error: 0.0618 - val_loss: 0.4364 - val_mean_absolute_error: 0.1049\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.1716 - mean_absolute_error: 0.0528 - val_loss: 0.4571 - val_mean_absolute_error: 0.0746\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.1117 - mean_absolute_error: 0.0373 - val_loss: 0.5521 - val_mean_absolute_error: 0.0711\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0772 - mean_absolute_error: 0.0271 - val_loss: 0.5840 - val_mean_absolute_error: 0.0714\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 25s 189ms/step - loss: 0.0578 - mean_absolute_error: 0.0204 - val_loss: 0.6168 - val_mean_absolute_error: 0.0768\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 24s 188ms/step - loss: 0.0376 - mean_absolute_error: 0.0138 - val_loss: 0.7495 - val_mean_absolute_error: 0.0661\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0272 - mean_absolute_error: 0.0100 - val_loss: 0.7076 - val_mean_absolute_error: 0.0766\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0188 - mean_absolute_error: 0.0067 - val_loss: 0.7641 - val_mean_absolute_error: 0.0739\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0212 - mean_absolute_error: 0.0066 - val_loss: 0.8452 - val_mean_absolute_error: 0.0655\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0136 - mean_absolute_error: 0.0047 - val_loss: 0.8554 - val_mean_absolute_error: 0.0645\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0097 - mean_absolute_error: 0.0035 - val_loss: 0.8647 - val_mean_absolute_error: 0.0667\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0117 - mean_absolute_error: 0.0035 - val_loss: 0.8693 - val_mean_absolute_error: 0.0688\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0100 - mean_absolute_error: 0.0031 - val_loss: 0.8762 - val_mean_absolute_error: 0.0701\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0090 - mean_absolute_error: 0.0028 - val_loss: 0.8971 - val_mean_absolute_error: 0.0686\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0083 - mean_absolute_error: 0.0027 - val_loss: 0.9020 - val_mean_absolute_error: 0.0706\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 25s 189ms/step - loss: 0.0368 - mean_absolute_error: 0.0096 - val_loss: 0.6223 - val_mean_absolute_error: 0.0724\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 24s 188ms/step - loss: 0.0487 - mean_absolute_error: 0.0159 - val_loss: 0.7810 - val_mean_absolute_error: 0.0710\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0251 - mean_absolute_error: 0.0077 - val_loss: 0.8099 - val_mean_absolute_error: 0.0676\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0135 - mean_absolute_error: 0.0045 - val_loss: 0.9394 - val_mean_absolute_error: 0.0634\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 24s 188ms/step - loss: 0.0123 - mean_absolute_error: 0.0040 - val_loss: 0.8771 - val_mean_absolute_error: 0.0691\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 24s 188ms/step - loss: 0.0096 - mean_absolute_error: 0.0030 - val_loss: 0.9122 - val_mean_absolute_error: 0.0849\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0275 - mean_absolute_error: 0.0089 - val_loss: 0.8840 - val_mean_absolute_error: 0.0677\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0127 - mean_absolute_error: 0.0041 - val_loss: 0.9894 - val_mean_absolute_error: 0.0648\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 25s 189ms/step - loss: 0.0080 - mean_absolute_error: 0.0025 - val_loss: 1.1515 - val_mean_absolute_error: 0.0613\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 24s 188ms/step - loss: 0.0071 - mean_absolute_error: 0.0019 - val_loss: 1.1090 - val_mean_absolute_error: 0.0636\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0048 - mean_absolute_error: 0.0013 - val_loss: 0.9960 - val_mean_absolute_error: 0.0678\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0049 - mean_absolute_error: 0.0014 - val_loss: 0.9952 - val_mean_absolute_error: 0.0697\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 24s 189ms/step - loss: 0.0041 - mean_absolute_error: 0.0012 - val_loss: 1.0148 - val_mean_absolute_error: 0.0681\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 24s 188ms/step - loss: 0.0045 - mean_absolute_error: 0.0013 - val_loss: 0.9827 - val_mean_absolute_error: 0.0691\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0040 - mean_absolute_error: 0.0012 - val_loss: 1.1476 - val_mean_absolute_error: 0.0641\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0042 - mean_absolute_error: 0.0012 - val_loss: 1.2856 - val_mean_absolute_error: 0.0619\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0061 - mean_absolute_error: 0.0017 - val_loss: 1.1047 - val_mean_absolute_error: 0.0660\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0340 - mean_absolute_error: 0.0094 - val_loss: 0.7591 - val_mean_absolute_error: 0.0750\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 0.0633 - mean_absolute_error: 0.0197 - val_loss: 0.8129 - val_mean_absolute_error: 0.0780\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 24s 182ms/step - loss: 0.0231 - mean_absolute_error: 0.0077 - val_loss: 0.8278 - val_mean_absolute_error: 0.0907\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 0.0143 - mean_absolute_error: 0.0049 - val_loss: 0.8810 - val_mean_absolute_error: 0.0679\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 23s 181ms/step - loss: 0.0084 - mean_absolute_error: 0.0025 - val_loss: 0.8980 - val_mean_absolute_error: 0.0700\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 24s 181ms/step - loss: 0.0059 - mean_absolute_error: 0.0016 - val_loss: 0.9864 - val_mean_absolute_error: 0.0673\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 24s 183ms/step - loss: 0.0046 - mean_absolute_error: 0.0014 - val_loss: 1.0218 - val_mean_absolute_error: 0.0657\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0040 - mean_absolute_error: 0.0012 - val_loss: 1.0425 - val_mean_absolute_error: 0.0653\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0049 - mean_absolute_error: 0.0013 - val_loss: 1.0486 - val_mean_absolute_error: 0.0649\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0039 - mean_absolute_error: 0.0011 - val_loss: 1.0782 - val_mean_absolute_error: 0.0644\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0042 - mean_absolute_error: 0.0012 - val_loss: 1.0231 - val_mean_absolute_error: 0.0679\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0043 - mean_absolute_error: 0.0012 - val_loss: 1.1088 - val_mean_absolute_error: 0.0632\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0041 - mean_absolute_error: 0.0011 - val_loss: 1.1361 - val_mean_absolute_error: 0.0622\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0035 - mean_absolute_error: 0.0011 - val_loss: 1.0641 - val_mean_absolute_error: 0.0664\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0043 - mean_absolute_error: 0.0012 - val_loss: 1.1204 - val_mean_absolute_error: 0.0638\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0043 - mean_absolute_error: 0.0012 - val_loss: 1.1790 - val_mean_absolute_error: 0.0626\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0036 - mean_absolute_error: 0.0011 - val_loss: 1.1128 - val_mean_absolute_error: 0.0667\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0033 - mean_absolute_error: 9.8864e-04 - val_loss: 1.1533 - val_mean_absolute_error: 0.0644\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0032 - mean_absolute_error: 0.0010 - val_loss: 1.1572 - val_mean_absolute_error: 0.0644\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0038 - mean_absolute_error: 0.0011 - val_loss: 1.1193 - val_mean_absolute_error: 0.0651\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0037 - mean_absolute_error: 0.0011 - val_loss: 1.1282 - val_mean_absolute_error: 0.0653\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0043 - mean_absolute_error: 0.0011 - val_loss: 1.1053 - val_mean_absolute_error: 0.0649\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0037 - mean_absolute_error: 0.0011 - val_loss: 1.1707 - val_mean_absolute_error: 0.0633\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0040 - mean_absolute_error: 0.0011 - val_loss: 1.1797 - val_mean_absolute_error: 0.0634\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0031 - mean_absolute_error: 0.0010 - val_loss: 1.1663 - val_mean_absolute_error: 0.0646\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0034 - mean_absolute_error: 0.0010 - val_loss: 1.1662 - val_mean_absolute_error: 0.0635\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0035 - mean_absolute_error: 0.0010 - val_loss: 1.1295 - val_mean_absolute_error: 0.0665\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0044 - mean_absolute_error: 0.0012 - val_loss: 1.1000 - val_mean_absolute_error: 0.0704\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0039 - mean_absolute_error: 0.0012 - val_loss: 1.1866 - val_mean_absolute_error: 0.0641\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0038 - mean_absolute_error: 0.0011 - val_loss: 1.1249 - val_mean_absolute_error: 0.0707\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0034 - mean_absolute_error: 0.0010 - val_loss: 1.1665 - val_mean_absolute_error: 0.0662\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0036 - mean_absolute_error: 0.0010 - val_loss: 1.2404 - val_mean_absolute_error: 0.0627\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0032 - mean_absolute_error: 9.3528e-04 - val_loss: 1.1946 - val_mean_absolute_error: 0.0647\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0036 - mean_absolute_error: 0.0010 - val_loss: 1.1811 - val_mean_absolute_error: 0.0691\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0033 - mean_absolute_error: 9.8175e-04 - val_loss: 1.1991 - val_mean_absolute_error: 0.0679\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0028 - mean_absolute_error: 9.1795e-04 - val_loss: 1.2586 - val_mean_absolute_error: 0.0650\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0030 - mean_absolute_error: 9.3984e-04 - val_loss: 1.2737 - val_mean_absolute_error: 0.0653\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0039 - mean_absolute_error: 0.0011 - val_loss: 1.3094 - val_mean_absolute_error: 0.0635\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0027 - mean_absolute_error: 8.6607e-04 - val_loss: 1.2927 - val_mean_absolute_error: 0.0650\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0031 - mean_absolute_error: 9.4700e-04 - val_loss: 1.2783 - val_mean_absolute_error: 0.0658\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0031 - mean_absolute_error: 9.9754e-04 - val_loss: 1.2495 - val_mean_absolute_error: 0.0642\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0031 - mean_absolute_error: 9.5887e-04 - val_loss: 1.2720 - val_mean_absolute_error: 0.0669\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0031 - mean_absolute_error: 9.3556e-04 - val_loss: 1.1395 - val_mean_absolute_error: 0.0743\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.1725 - mean_absolute_error: 0.0423 - val_loss: 0.6291 - val_mean_absolute_error: 0.0821\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0572 - mean_absolute_error: 0.0185 - val_loss: 0.7823 - val_mean_absolute_error: 0.0781\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0146 - mean_absolute_error: 0.0056 - val_loss: 0.8068 - val_mean_absolute_error: 0.0774\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0110 - mean_absolute_error: 0.0039 - val_loss: 0.9031 - val_mean_absolute_error: 0.0690\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0060 - mean_absolute_error: 0.0021 - val_loss: 0.9648 - val_mean_absolute_error: 0.0690\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0035 - mean_absolute_error: 0.0014 - val_loss: 0.9637 - val_mean_absolute_error: 0.0701\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0051 - mean_absolute_error: 0.0015 - val_loss: 1.0416 - val_mean_absolute_error: 0.0688\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0043 - mean_absolute_error: 0.0014 - val_loss: 1.0050 - val_mean_absolute_error: 0.0694\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0041 - mean_absolute_error: 0.0013 - val_loss: 1.0280 - val_mean_absolute_error: 0.0692\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0050 - mean_absolute_error: 0.0013 - val_loss: 1.0683 - val_mean_absolute_error: 0.0681\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0036 - mean_absolute_error: 0.0011 - val_loss: 1.0567 - val_mean_absolute_error: 0.0690\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0034 - mean_absolute_error: 0.0011 - val_loss: 1.0376 - val_mean_absolute_error: 0.0699\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0044 - mean_absolute_error: 0.0012 - val_loss: 1.1161 - val_mean_absolute_error: 0.0674\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0046 - mean_absolute_error: 0.0012 - val_loss: 1.0962 - val_mean_absolute_error: 0.0687\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0032 - mean_absolute_error: 0.0010 - val_loss: 1.1837 - val_mean_absolute_error: 0.0667\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0025 - mean_absolute_error: 8.9464e-04 - val_loss: 1.1201 - val_mean_absolute_error: 0.0694\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 24s 184ms/step - loss: 0.0041 - mean_absolute_error: 0.0012 - val_loss: 1.2024 - val_mean_absolute_error: 0.0660\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 24s 187ms/step - loss: 0.0039 - mean_absolute_error: 0.0011 - val_loss: 1.1868 - val_mean_absolute_error: 0.0673\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 24s 186ms/step - loss: 0.0034 - mean_absolute_error: 0.0011 - val_loss: 1.1363 - val_mean_absolute_error: 0.0689\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 24s 185ms/step - loss: 0.0032 - mean_absolute_error: 9.0709e-04 - val_loss: 1.2147 - val_mean_absolute_error: 0.0673\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_21 (Bidirecti  (None, 200)              490400    \n",
      " onal)                                                           \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_21 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 491,204\n",
      "Trainable params: 491,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 27s 197ms/step - loss: 0.1372 - mean_absolute_error: 0.0230 - val_loss: 0.1219 - val_mean_absolute_error: 0.0184\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.1037 - mean_absolute_error: 0.0198 - val_loss: 0.1250 - val_mean_absolute_error: 0.0321\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 25s 192ms/step - loss: 0.0939 - mean_absolute_error: 0.0192 - val_loss: 0.1128 - val_mean_absolute_error: 0.0194\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 25s 192ms/step - loss: 0.0739 - mean_absolute_error: 0.0177 - val_loss: 0.1485 - val_mean_absolute_error: 0.0128\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0619 - mean_absolute_error: 0.0151 - val_loss: 0.1149 - val_mean_absolute_error: 0.0206\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0474 - mean_absolute_error: 0.0132 - val_loss: 0.1322 - val_mean_absolute_error: 0.0151\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0284 - mean_absolute_error: 0.0093 - val_loss: 0.1377 - val_mean_absolute_error: 0.0230\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0184 - mean_absolute_error: 0.0065 - val_loss: 0.1502 - val_mean_absolute_error: 0.0182\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 25s 192ms/step - loss: 0.0093 - mean_absolute_error: 0.0038 - val_loss: 0.1879 - val_mean_absolute_error: 0.0132\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0052 - mean_absolute_error: 0.0021 - val_loss: 0.1932 - val_mean_absolute_error: 0.0135\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0024 - mean_absolute_error: 0.0011 - val_loss: 0.1958 - val_mean_absolute_error: 0.0166\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0028 - mean_absolute_error: 0.0011 - val_loss: 0.2045 - val_mean_absolute_error: 0.0135\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 8.9447e-04 - mean_absolute_error: 4.3146e-04 - val_loss: 0.2247 - val_mean_absolute_error: 0.0140\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 4.5089e-04 - mean_absolute_error: 2.2022e-04 - val_loss: 0.2464 - val_mean_absolute_error: 0.0135\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 2.7887e-04 - mean_absolute_error: 1.3851e-04 - val_loss: 0.2530 - val_mean_absolute_error: 0.0135\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 25s 192ms/step - loss: 2.1687e-04 - mean_absolute_error: 1.0783e-04 - val_loss: 0.2589 - val_mean_absolute_error: 0.0136\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 1.6048e-04 - mean_absolute_error: 7.9955e-05 - val_loss: 0.2725 - val_mean_absolute_error: 0.0131\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 1.2562e-04 - mean_absolute_error: 6.2608e-05 - val_loss: 0.2646 - val_mean_absolute_error: 0.0138\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 1.5945e-04 - mean_absolute_error: 7.7140e-05 - val_loss: 0.2686 - val_mean_absolute_error: 0.0139\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0044 - mean_absolute_error: 4.0016e-04 - val_loss: 0.2019 - val_mean_absolute_error: 0.0289\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0313 - mean_absolute_error: 0.0088 - val_loss: 0.1552 - val_mean_absolute_error: 0.0274\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0178 - mean_absolute_error: 0.0057 - val_loss: 0.1639 - val_mean_absolute_error: 0.0162\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0042 - mean_absolute_error: 0.0018 - val_loss: 0.2004 - val_mean_absolute_error: 0.0143\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 8.5798e-04 - mean_absolute_error: 4.1343e-04 - val_loss: 0.2252 - val_mean_absolute_error: 0.0134\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 4.6706e-04 - mean_absolute_error: 2.2104e-04 - val_loss: 0.2328 - val_mean_absolute_error: 0.0132\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 2.8698e-04 - mean_absolute_error: 1.4045e-04 - val_loss: 0.2377 - val_mean_absolute_error: 0.0132\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 1.8922e-04 - mean_absolute_error: 9.4047e-05 - val_loss: 0.2481 - val_mean_absolute_error: 0.0130\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 1.5345e-04 - mean_absolute_error: 7.6374e-05 - val_loss: 0.2485 - val_mean_absolute_error: 0.0131\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 1.1794e-04 - mean_absolute_error: 5.8785e-05 - val_loss: 0.2548 - val_mean_absolute_error: 0.0129\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 9.3308e-05 - mean_absolute_error: 4.6568e-05 - val_loss: 0.2610 - val_mean_absolute_error: 0.0128\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 9.3945e-05 - mean_absolute_error: 4.6823e-05 - val_loss: 0.2617 - val_mean_absolute_error: 0.0129\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 8.1002e-05 - mean_absolute_error: 4.0405e-05 - val_loss: 0.2635 - val_mean_absolute_error: 0.0129\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 7.4355e-05 - mean_absolute_error: 3.7096e-05 - val_loss: 0.2660 - val_mean_absolute_error: 0.0130\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 6.5195e-05 - mean_absolute_error: 3.2544e-05 - val_loss: 0.2725 - val_mean_absolute_error: 0.0128\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 5.2662e-05 - mean_absolute_error: 2.6299e-05 - val_loss: 0.2749 - val_mean_absolute_error: 0.0128\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 5.3925e-05 - mean_absolute_error: 2.6924e-05 - val_loss: 0.2756 - val_mean_absolute_error: 0.0129\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 4.4979e-05 - mean_absolute_error: 2.2463e-05 - val_loss: 0.2805 - val_mean_absolute_error: 0.0128\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 4.6605e-05 - mean_absolute_error: 2.3268e-05 - val_loss: 0.2853 - val_mean_absolute_error: 0.0127\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 3.8052e-05 - mean_absolute_error: 1.8998e-05 - val_loss: 0.2866 - val_mean_absolute_error: 0.0127\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 3.0110e-05 - mean_absolute_error: 1.5047e-05 - val_loss: 0.2892 - val_mean_absolute_error: 0.0127\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 3.0213e-05 - mean_absolute_error: 1.5098e-05 - val_loss: 0.2890 - val_mean_absolute_error: 0.0127\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 2.5837e-05 - mean_absolute_error: 1.2912e-05 - val_loss: 0.2926 - val_mean_absolute_error: 0.0127\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 26s 196ms/step - loss: 2.6722e-05 - mean_absolute_error: 1.3354e-05 - val_loss: 0.2971 - val_mean_absolute_error: 0.0127\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 2.4157e-05 - mean_absolute_error: 1.2069e-05 - val_loss: 0.2998 - val_mean_absolute_error: 0.0126\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 2.0721e-05 - mean_absolute_error: 1.0354e-05 - val_loss: 0.3033 - val_mean_absolute_error: 0.0126\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 1.9665e-05 - mean_absolute_error: 9.8284e-06 - val_loss: 0.3026 - val_mean_absolute_error: 0.0126\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 1.7014e-05 - mean_absolute_error: 8.5064e-06 - val_loss: 0.2998 - val_mean_absolute_error: 0.0128\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 1.7110e-05 - mean_absolute_error: 8.5498e-06 - val_loss: 0.3059 - val_mean_absolute_error: 0.0126\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 1.7094e-05 - mean_absolute_error: 8.5451e-06 - val_loss: 0.3073 - val_mean_absolute_error: 0.0126\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 1.3347e-05 - mean_absolute_error: 6.6732e-06 - val_loss: 0.3096 - val_mean_absolute_error: 0.0126\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 1.2078e-05 - mean_absolute_error: 6.0395e-06 - val_loss: 0.3093 - val_mean_absolute_error: 0.0126\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 1.1616e-05 - mean_absolute_error: 5.8084e-06 - val_loss: 0.3102 - val_mean_absolute_error: 0.0126\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 1.1709e-05 - mean_absolute_error: 5.8549e-06 - val_loss: 0.3161 - val_mean_absolute_error: 0.0126\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 9.7394e-06 - mean_absolute_error: 4.8705e-06 - val_loss: 0.3213 - val_mean_absolute_error: 0.0125\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 1.0226e-05 - mean_absolute_error: 5.1139e-06 - val_loss: 0.3190 - val_mean_absolute_error: 0.0126\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 8.6947e-06 - mean_absolute_error: 4.3481e-06 - val_loss: 0.3204 - val_mean_absolute_error: 0.0126\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 9.0754e-06 - mean_absolute_error: 4.5377e-06 - val_loss: 0.3264 - val_mean_absolute_error: 0.0125\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 7.7836e-06 - mean_absolute_error: 3.8928e-06 - val_loss: 0.3273 - val_mean_absolute_error: 0.0125\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 6.3944e-06 - mean_absolute_error: 3.1985e-06 - val_loss: 0.3290 - val_mean_absolute_error: 0.0125\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 6.1688e-06 - mean_absolute_error: 3.0857e-06 - val_loss: 0.3329 - val_mean_absolute_error: 0.0125\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 6.2199e-06 - mean_absolute_error: 3.1110e-06 - val_loss: 0.3326 - val_mean_absolute_error: 0.0125\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 4.9958e-06 - mean_absolute_error: 2.4993e-06 - val_loss: 0.3377 - val_mean_absolute_error: 0.0124\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 4.2937e-06 - mean_absolute_error: 2.1485e-06 - val_loss: 0.3363 - val_mean_absolute_error: 0.0125\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 4.2326e-06 - mean_absolute_error: 2.1180e-06 - val_loss: 0.3362 - val_mean_absolute_error: 0.0125\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 4.3556e-06 - mean_absolute_error: 2.1794e-06 - val_loss: 0.3417 - val_mean_absolute_error: 0.0124\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 4.5657e-06 - mean_absolute_error: 2.2837e-06 - val_loss: 0.3429 - val_mean_absolute_error: 0.0124\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 3.7254e-06 - mean_absolute_error: 1.8643e-06 - val_loss: 0.3440 - val_mean_absolute_error: 0.0124\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 3.3654e-06 - mean_absolute_error: 1.6843e-06 - val_loss: 0.3479 - val_mean_absolute_error: 0.0124\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 25s 191ms/step - loss: 3.3672e-06 - mean_absolute_error: 1.6849e-06 - val_loss: 0.3469 - val_mean_absolute_error: 0.0124\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 25s 190ms/step - loss: 2.4784e-06 - mean_absolute_error: 1.2409e-06 - val_loss: 0.3528 - val_mean_absolute_error: 0.0124\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 25s 191ms/step - loss: 2.8697e-06 - mean_absolute_error: 1.4364e-06 - val_loss: 0.3547 - val_mean_absolute_error: 0.0123\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 25s 191ms/step - loss: 2.5166e-06 - mean_absolute_error: 1.2599e-06 - val_loss: 0.3549 - val_mean_absolute_error: 0.0123\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 25s 191ms/step - loss: 2.6627e-06 - mean_absolute_error: 1.3328e-06 - val_loss: 0.3588 - val_mean_absolute_error: 0.0123\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 25s 190ms/step - loss: 2.0454e-06 - mean_absolute_error: 1.0240e-06 - val_loss: 0.3559 - val_mean_absolute_error: 0.0124\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 25s 192ms/step - loss: 2.3319e-06 - mean_absolute_error: 1.1672e-06 - val_loss: 0.3570 - val_mean_absolute_error: 0.0123\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 1.9185e-06 - mean_absolute_error: 9.6078e-07 - val_loss: 0.3599 - val_mean_absolute_error: 0.0124\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 1.6535e-06 - mean_absolute_error: 8.2821e-07 - val_loss: 0.3678 - val_mean_absolute_error: 0.0123\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 0.0340 - mean_absolute_error: 0.0064 - val_loss: 0.1281 - val_mean_absolute_error: 0.0217\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0450 - mean_absolute_error: 0.0117 - val_loss: 0.1845 - val_mean_absolute_error: 0.0127\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0158 - mean_absolute_error: 0.0056 - val_loss: 0.1803 - val_mean_absolute_error: 0.0137\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0042 - mean_absolute_error: 0.0018 - val_loss: 0.2086 - val_mean_absolute_error: 0.0134\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0013 - mean_absolute_error: 6.0033e-04 - val_loss: 0.2199 - val_mean_absolute_error: 0.0129\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 5.5664e-04 - mean_absolute_error: 2.7359e-04 - val_loss: 0.2256 - val_mean_absolute_error: 0.0131\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 4.4741e-04 - mean_absolute_error: 2.2012e-04 - val_loss: 0.2336 - val_mean_absolute_error: 0.0132\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 3.8451e-04 - mean_absolute_error: 1.8925e-04 - val_loss: 0.2457 - val_mean_absolute_error: 0.0128\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 3.2296e-04 - mean_absolute_error: 1.5904e-04 - val_loss: 0.2492 - val_mean_absolute_error: 0.0128\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 2.2785e-04 - mean_absolute_error: 1.1332e-04 - val_loss: 0.2540 - val_mean_absolute_error: 0.0128\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 1.8151e-04 - mean_absolute_error: 9.0183e-05 - val_loss: 0.2552 - val_mean_absolute_error: 0.0128\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 1.6969e-04 - mean_absolute_error: 8.4364e-05 - val_loss: 0.2553 - val_mean_absolute_error: 0.0128\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 1.4453e-04 - mean_absolute_error: 7.2023e-05 - val_loss: 0.2636 - val_mean_absolute_error: 0.0126\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 25s 194ms/step - loss: 1.2696e-04 - mean_absolute_error: 6.3277e-05 - val_loss: 0.2575 - val_mean_absolute_error: 0.0129\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 1.3602e-04 - mean_absolute_error: 6.7659e-05 - val_loss: 0.2672 - val_mean_absolute_error: 0.0128\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 9.8714e-05 - mean_absolute_error: 4.9209e-05 - val_loss: 0.2754 - val_mean_absolute_error: 0.0127\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 8.8077e-05 - mean_absolute_error: 4.3862e-05 - val_loss: 0.2683 - val_mean_absolute_error: 0.0129\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 7.6469e-05 - mean_absolute_error: 3.8128e-05 - val_loss: 0.2701 - val_mean_absolute_error: 0.0130\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 6.3086e-05 - mean_absolute_error: 3.1499e-05 - val_loss: 0.2836 - val_mean_absolute_error: 0.0128\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 5.5152e-05 - mean_absolute_error: 2.7544e-05 - val_loss: 0.2816 - val_mean_absolute_error: 0.0128\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 5.3813e-05 - mean_absolute_error: 2.6869e-05 - val_loss: 0.2886 - val_mean_absolute_error: 0.0128\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 4.6933e-05 - mean_absolute_error: 2.3441e-05 - val_loss: 0.2928 - val_mean_absolute_error: 0.0127\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 4.0406e-05 - mean_absolute_error: 2.0178e-05 - val_loss: 0.2934 - val_mean_absolute_error: 0.0126\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_22 (Bidirecti  (None, 200)              490400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 491,204\n",
      "Trainable params: 491,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 28s 202ms/step - loss: 0.1459 - mean_absolute_error: 0.0260 - val_loss: 0.1404 - val_mean_absolute_error: 0.0205\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.1070 - mean_absolute_error: 0.0219 - val_loss: 0.1442 - val_mean_absolute_error: 0.0282\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0957 - mean_absolute_error: 0.0215 - val_loss: 0.1452 - val_mean_absolute_error: 0.0196\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0815 - mean_absolute_error: 0.0194 - val_loss: 0.1555 - val_mean_absolute_error: 0.0360\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0669 - mean_absolute_error: 0.0169 - val_loss: 0.1422 - val_mean_absolute_error: 0.0286\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0570 - mean_absolute_error: 0.0153 - val_loss: 0.1394 - val_mean_absolute_error: 0.0232\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0380 - mean_absolute_error: 0.0113 - val_loss: 0.1691 - val_mean_absolute_error: 0.0202\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0257 - mean_absolute_error: 0.0085 - val_loss: 0.1716 - val_mean_absolute_error: 0.0194\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0159 - mean_absolute_error: 0.0057 - val_loss: 0.1811 - val_mean_absolute_error: 0.0210\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0106 - mean_absolute_error: 0.0042 - val_loss: 0.2122 - val_mean_absolute_error: 0.0173\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0060 - mean_absolute_error: 0.0025 - val_loss: 0.2380 - val_mean_absolute_error: 0.0174\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0033 - mean_absolute_error: 0.0015 - val_loss: 0.2466 - val_mean_absolute_error: 0.0199\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0014 - mean_absolute_error: 6.6379e-04 - val_loss: 0.2802 - val_mean_absolute_error: 0.0172\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0020 - mean_absolute_error: 9.0112e-04 - val_loss: 0.2603 - val_mean_absolute_error: 0.0177\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0029 - mean_absolute_error: 0.0012 - val_loss: 0.2911 - val_mean_absolute_error: 0.0168\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0024 - mean_absolute_error: 0.0011 - val_loss: 0.2525 - val_mean_absolute_error: 0.0182\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 6.1235e-04 - mean_absolute_error: 3.0046e-04 - val_loss: 0.3041 - val_mean_absolute_error: 0.0178\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 2.8570e-04 - mean_absolute_error: 1.4193e-04 - val_loss: 0.3131 - val_mean_absolute_error: 0.0180\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 1.7374e-04 - mean_absolute_error: 8.6488e-05 - val_loss: 0.3262 - val_mean_absolute_error: 0.0180\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 1.4227e-04 - mean_absolute_error: 7.0938e-05 - val_loss: 0.3318 - val_mean_absolute_error: 0.0181\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 1.2062e-04 - mean_absolute_error: 6.0103e-05 - val_loss: 0.3424 - val_mean_absolute_error: 0.0179\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 1.0347e-04 - mean_absolute_error: 5.1624e-05 - val_loss: 0.3479 - val_mean_absolute_error: 0.0179\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 26s 196ms/step - loss: 8.9126e-05 - mean_absolute_error: 4.4457e-05 - val_loss: 0.3472 - val_mean_absolute_error: 0.0180\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 7.5268e-05 - mean_absolute_error: 3.7567e-05 - val_loss: 0.3566 - val_mean_absolute_error: 0.0179\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 6.8586e-05 - mean_absolute_error: 3.4219e-05 - val_loss: 0.3642 - val_mean_absolute_error: 0.0178\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 5.7001e-05 - mean_absolute_error: 2.8462e-05 - val_loss: 0.3719 - val_mean_absolute_error: 0.0178\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 4.4718e-05 - mean_absolute_error: 2.2337e-05 - val_loss: 0.3748 - val_mean_absolute_error: 0.0178\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 4.7741e-05 - mean_absolute_error: 2.3844e-05 - val_loss: 0.3897 - val_mean_absolute_error: 0.0177\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 4.0887e-05 - mean_absolute_error: 2.0418e-05 - val_loss: 0.3845 - val_mean_absolute_error: 0.0178\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 3.3561e-05 - mean_absolute_error: 1.6771e-05 - val_loss: 0.3935 - val_mean_absolute_error: 0.0177\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 3.2012e-05 - mean_absolute_error: 1.5991e-05 - val_loss: 0.4051 - val_mean_absolute_error: 0.0176\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 2.6773e-05 - mean_absolute_error: 1.3379e-05 - val_loss: 0.3974 - val_mean_absolute_error: 0.0177\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 26s 198ms/step - loss: 2.7387e-05 - mean_absolute_error: 1.3682e-05 - val_loss: 0.4029 - val_mean_absolute_error: 0.0177\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 2.0644e-05 - mean_absolute_error: 1.0319e-05 - val_loss: 0.4169 - val_mean_absolute_error: 0.0176\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 1.9047e-05 - mean_absolute_error: 9.5215e-06 - val_loss: 0.4139 - val_mean_absolute_error: 0.0177\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 1.6967e-05 - mean_absolute_error: 8.4809e-06 - val_loss: 0.4223 - val_mean_absolute_error: 0.0177\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 1.6354e-05 - mean_absolute_error: 8.1767e-06 - val_loss: 0.4265 - val_mean_absolute_error: 0.0176\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 26s 196ms/step - loss: 1.3706e-05 - mean_absolute_error: 6.8533e-06 - val_loss: 0.4187 - val_mean_absolute_error: 0.0175\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 1.8071e-05 - mean_absolute_error: 9.0274e-06 - val_loss: 0.4268 - val_mean_absolute_error: 0.0175\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 1.3565e-05 - mean_absolute_error: 6.7826e-06 - val_loss: 0.4306 - val_mean_absolute_error: 0.0174\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 1.1510e-05 - mean_absolute_error: 5.7561e-06 - val_loss: 0.4574 - val_mean_absolute_error: 0.0173\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 26s 196ms/step - loss: 1.1362e-05 - mean_absolute_error: 5.6799e-06 - val_loss: 0.4396 - val_mean_absolute_error: 0.0174\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 1.0274e-05 - mean_absolute_error: 5.1383e-06 - val_loss: 0.4537 - val_mean_absolute_error: 0.0172\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 8.8020e-06 - mean_absolute_error: 4.4025e-06 - val_loss: 0.4570 - val_mean_absolute_error: 0.0173\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 6.3280e-06 - mean_absolute_error: 3.1661e-06 - val_loss: 0.4641 - val_mean_absolute_error: 0.0172\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 6.0775e-06 - mean_absolute_error: 3.0409e-06 - val_loss: 0.4701 - val_mean_absolute_error: 0.0171\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 5.5643e-06 - mean_absolute_error: 2.7844e-06 - val_loss: 0.4686 - val_mean_absolute_error: 0.0172\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 6.1398e-06 - mean_absolute_error: 3.0716e-06 - val_loss: 0.4671 - val_mean_absolute_error: 0.0176\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 4.6488e-06 - mean_absolute_error: 2.3269e-06 - val_loss: 0.4972 - val_mean_absolute_error: 0.0172\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 26s 196ms/step - loss: 4.0288e-06 - mean_absolute_error: 2.0166e-06 - val_loss: 0.4934 - val_mean_absolute_error: 0.0174\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 3.4363e-06 - mean_absolute_error: 1.7204e-06 - val_loss: 0.4945 - val_mean_absolute_error: 0.0174\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 3.7446e-06 - mean_absolute_error: 1.8743e-06 - val_loss: 0.4970 - val_mean_absolute_error: 0.0175\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 3.0841e-06 - mean_absolute_error: 1.5443e-06 - val_loss: 0.5024 - val_mean_absolute_error: 0.0172\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 4.1276e-06 - mean_absolute_error: 2.0653e-06 - val_loss: 0.4990 - val_mean_absolute_error: 0.0172\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 2.8425e-06 - mean_absolute_error: 1.4235e-06 - val_loss: 0.5049 - val_mean_absolute_error: 0.0170\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 2.3309e-06 - mean_absolute_error: 1.1676e-06 - val_loss: 0.5094 - val_mean_absolute_error: 0.0170\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0177 - mean_absolute_error: 0.0034 - val_loss: 0.1541 - val_mean_absolute_error: 0.0180\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0629 - mean_absolute_error: 0.0152 - val_loss: 0.1633 - val_mean_absolute_error: 0.0181\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0239 - mean_absolute_error: 0.0074 - val_loss: 0.1988 - val_mean_absolute_error: 0.0199\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0097 - mean_absolute_error: 0.0038 - val_loss: 0.2614 - val_mean_absolute_error: 0.0178\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0027 - mean_absolute_error: 0.0013 - val_loss: 0.2727 - val_mean_absolute_error: 0.0175\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 8.7203e-04 - mean_absolute_error: 4.2545e-04 - val_loss: 0.2804 - val_mean_absolute_error: 0.0180\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 5.7588e-04 - mean_absolute_error: 2.8379e-04 - val_loss: 0.3115 - val_mean_absolute_error: 0.0177\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 3.6760e-04 - mean_absolute_error: 1.8165e-04 - val_loss: 0.3172 - val_mean_absolute_error: 0.0178\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 2.9042e-04 - mean_absolute_error: 1.4419e-04 - val_loss: 0.3316 - val_mean_absolute_error: 0.0177\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 2.3921e-04 - mean_absolute_error: 1.1889e-04 - val_loss: 0.3345 - val_mean_absolute_error: 0.0178\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 2.0644e-04 - mean_absolute_error: 1.0254e-04 - val_loss: 0.3449 - val_mean_absolute_error: 0.0180\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 2.2665e-04 - mean_absolute_error: 1.1228e-04 - val_loss: 0.3589 - val_mean_absolute_error: 0.0179\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 1.4283e-04 - mean_absolute_error: 7.1164e-05 - val_loss: 0.3561 - val_mean_absolute_error: 0.0180\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 1.2873e-04 - mean_absolute_error: 6.4102e-05 - val_loss: 0.3617 - val_mean_absolute_error: 0.0179\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 1.0394e-04 - mean_absolute_error: 5.1822e-05 - val_loss: 0.3738 - val_mean_absolute_error: 0.0179\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 8.3902e-05 - mean_absolute_error: 4.1833e-05 - val_loss: 0.3862 - val_mean_absolute_error: 0.0178\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 26s 196ms/step - loss: 8.7661e-05 - mean_absolute_error: 4.3714e-05 - val_loss: 0.3829 - val_mean_absolute_error: 0.0180\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 7.8079e-05 - mean_absolute_error: 3.8933e-05 - val_loss: 0.3848 - val_mean_absolute_error: 0.0180\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 7.5839e-05 - mean_absolute_error: 3.7811e-05 - val_loss: 0.3833 - val_mean_absolute_error: 0.0180\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 7.1732e-05 - mean_absolute_error: 3.5777e-05 - val_loss: 0.4090 - val_mean_absolute_error: 0.0179\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 5.0497e-05 - mean_absolute_error: 2.5211e-05 - val_loss: 0.4156 - val_mean_absolute_error: 0.0180\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 4.5566e-05 - mean_absolute_error: 2.2749e-05 - val_loss: 0.4152 - val_mean_absolute_error: 0.0180\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 3.9874e-05 - mean_absolute_error: 1.9917e-05 - val_loss: 0.4105 - val_mean_absolute_error: 0.0180\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 3.2788e-05 - mean_absolute_error: 1.6379e-05 - val_loss: 0.4220 - val_mean_absolute_error: 0.0179\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 3.3941e-05 - mean_absolute_error: 1.6958e-05 - val_loss: 0.4274 - val_mean_absolute_error: 0.0179\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 2.7785e-05 - mean_absolute_error: 1.3885e-05 - val_loss: 0.4360 - val_mean_absolute_error: 0.0179\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 2.6365e-05 - mean_absolute_error: 1.3168e-05 - val_loss: 0.4402 - val_mean_absolute_error: 0.0179\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 2.5305e-05 - mean_absolute_error: 1.2646e-05 - val_loss: 0.4507 - val_mean_absolute_error: 0.0178\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 2.3315e-05 - mean_absolute_error: 1.1650e-05 - val_loss: 0.4453 - val_mean_absolute_error: 0.0179\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 2.0224e-05 - mean_absolute_error: 1.0108e-05 - val_loss: 0.4496 - val_mean_absolute_error: 0.0179\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 1.6071e-05 - mean_absolute_error: 8.0340e-06 - val_loss: 0.4593 - val_mean_absolute_error: 0.0179\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 26s 196ms/step - loss: 1.4229e-05 - mean_absolute_error: 7.1132e-06 - val_loss: 0.4595 - val_mean_absolute_error: 0.0180\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 1.5921e-05 - mean_absolute_error: 7.9579e-06 - val_loss: 0.4696 - val_mean_absolute_error: 0.0179\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 1.3091e-05 - mean_absolute_error: 6.5451e-06 - val_loss: 0.4721 - val_mean_absolute_error: 0.0179\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 1.0834e-05 - mean_absolute_error: 5.4173e-06 - val_loss: 0.4767 - val_mean_absolute_error: 0.0178\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 1.2486e-05 - mean_absolute_error: 6.2425e-06 - val_loss: 0.4703 - val_mean_absolute_error: 0.0181\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 1.6523e-05 - mean_absolute_error: 8.2596e-06 - val_loss: 0.4681 - val_mean_absolute_error: 0.0182\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0343 - mean_absolute_error: 0.0054 - val_loss: 0.1667 - val_mean_absolute_error: 0.0192\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0277 - mean_absolute_error: 0.0080 - val_loss: 0.2129 - val_mean_absolute_error: 0.0190\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0086 - mean_absolute_error: 0.0032 - val_loss: 0.2662 - val_mean_absolute_error: 0.0171\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0019 - mean_absolute_error: 8.7532e-04 - val_loss: 0.2756 - val_mean_absolute_error: 0.0184\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 8.0900e-04 - mean_absolute_error: 3.8927e-04 - val_loss: 0.2859 - val_mean_absolute_error: 0.0170\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 7.6773e-04 - mean_absolute_error: 3.0894e-04 - val_loss: 0.2598 - val_mean_absolute_error: 0.0188\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 5.6972e-04 - mean_absolute_error: 2.7570e-04 - val_loss: 0.2918 - val_mean_absolute_error: 0.0174\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_23 (Bidirecti  (None, 200)              490400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 491,204\n",
      "Trainable params: 491,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 27s 199ms/step - loss: 0.4076 - mean_absolute_error: 0.0982 - val_loss: 0.3452 - val_mean_absolute_error: 0.1049\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.3068 - mean_absolute_error: 0.0808 - val_loss: 0.2868 - val_mean_absolute_error: 0.0703\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.2666 - mean_absolute_error: 0.0712 - val_loss: 0.3076 - val_mean_absolute_error: 0.0807\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.2360 - mean_absolute_error: 0.0646 - val_loss: 0.3304 - val_mean_absolute_error: 0.0837\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.1943 - mean_absolute_error: 0.0564 - val_loss: 0.3028 - val_mean_absolute_error: 0.0687\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.1582 - mean_absolute_error: 0.0492 - val_loss: 0.3404 - val_mean_absolute_error: 0.0563\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.1182 - mean_absolute_error: 0.0375 - val_loss: 0.3220 - val_mean_absolute_error: 0.0578\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.1008 - mean_absolute_error: 0.0324 - val_loss: 0.3531 - val_mean_absolute_error: 0.0573\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0701 - mean_absolute_error: 0.0240 - val_loss: 0.3824 - val_mean_absolute_error: 0.0555\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0643 - mean_absolute_error: 0.0209 - val_loss: 0.4256 - val_mean_absolute_error: 0.0541\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0504 - mean_absolute_error: 0.0172 - val_loss: 0.3777 - val_mean_absolute_error: 0.0544\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0409 - mean_absolute_error: 0.0130 - val_loss: 0.4446 - val_mean_absolute_error: 0.0515\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0396 - mean_absolute_error: 0.0133 - val_loss: 0.4235 - val_mean_absolute_error: 0.0566\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0344 - mean_absolute_error: 0.0111 - val_loss: 0.4307 - val_mean_absolute_error: 0.0563\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0335 - mean_absolute_error: 0.0100 - val_loss: 0.4445 - val_mean_absolute_error: 0.0580\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0326 - mean_absolute_error: 0.0102 - val_loss: 0.4576 - val_mean_absolute_error: 0.0552\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0266 - mean_absolute_error: 0.0087 - val_loss: 0.4938 - val_mean_absolute_error: 0.0476\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0363 - mean_absolute_error: 0.0111 - val_loss: 0.4899 - val_mean_absolute_error: 0.0657\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0231 - mean_absolute_error: 0.0069 - val_loss: 0.4923 - val_mean_absolute_error: 0.0527\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0203 - mean_absolute_error: 0.0058 - val_loss: 0.5237 - val_mean_absolute_error: 0.0534\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0170 - mean_absolute_error: 0.0053 - val_loss: 0.5656 - val_mean_absolute_error: 0.0497\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0225 - mean_absolute_error: 0.0068 - val_loss: 0.4930 - val_mean_absolute_error: 0.0527\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0229 - mean_absolute_error: 0.0070 - val_loss: 0.5227 - val_mean_absolute_error: 0.0530\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0252 - mean_absolute_error: 0.0067 - val_loss: 0.4832 - val_mean_absolute_error: 0.0518\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0161 - mean_absolute_error: 0.0047 - val_loss: 0.5241 - val_mean_absolute_error: 0.0507\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0167 - mean_absolute_error: 0.0046 - val_loss: 0.5694 - val_mean_absolute_error: 0.0494\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0149 - mean_absolute_error: 0.0037 - val_loss: 0.5844 - val_mean_absolute_error: 0.0505\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0151 - mean_absolute_error: 0.0039 - val_loss: 0.5629 - val_mean_absolute_error: 0.0488\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0134 - mean_absolute_error: 0.0036 - val_loss: 0.5349 - val_mean_absolute_error: 0.0537\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0136 - mean_absolute_error: 0.0037 - val_loss: 0.5466 - val_mean_absolute_error: 0.0541\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0126 - mean_absolute_error: 0.0035 - val_loss: 0.5704 - val_mean_absolute_error: 0.0498\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0120 - mean_absolute_error: 0.0033 - val_loss: 0.6108 - val_mean_absolute_error: 0.0574\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0115 - mean_absolute_error: 0.0032 - val_loss: 0.6122 - val_mean_absolute_error: 0.0536\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0187 - mean_absolute_error: 0.0054 - val_loss: 0.5745 - val_mean_absolute_error: 0.0534\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0457 - mean_absolute_error: 0.0142 - val_loss: 0.4684 - val_mean_absolute_error: 0.0562\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0305 - mean_absolute_error: 0.0099 - val_loss: 0.5150 - val_mean_absolute_error: 0.0515\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0244 - mean_absolute_error: 0.0066 - val_loss: 0.5240 - val_mean_absolute_error: 0.0495\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0263 - mean_absolute_error: 0.0075 - val_loss: 0.5650 - val_mean_absolute_error: 0.0499\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0199 - mean_absolute_error: 0.0054 - val_loss: 0.5464 - val_mean_absolute_error: 0.0547\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0194 - mean_absolute_error: 0.0054 - val_loss: 0.5044 - val_mean_absolute_error: 0.0528\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0211 - mean_absolute_error: 0.0064 - val_loss: 0.5789 - val_mean_absolute_error: 0.0580\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0146 - mean_absolute_error: 0.0043 - val_loss: 0.5647 - val_mean_absolute_error: 0.0557\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0126 - mean_absolute_error: 0.0038 - val_loss: 0.5943 - val_mean_absolute_error: 0.0484\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0123 - mean_absolute_error: 0.0034 - val_loss: 0.5853 - val_mean_absolute_error: 0.0496\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0108 - mean_absolute_error: 0.0030 - val_loss: 0.5988 - val_mean_absolute_error: 0.0522\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0099 - mean_absolute_error: 0.0030 - val_loss: 0.6098 - val_mean_absolute_error: 0.0492\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0101 - mean_absolute_error: 0.0029 - val_loss: 0.6154 - val_mean_absolute_error: 0.0509\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0100 - mean_absolute_error: 0.0028 - val_loss: 0.6204 - val_mean_absolute_error: 0.0509\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0098 - mean_absolute_error: 0.0029 - val_loss: 0.6399 - val_mean_absolute_error: 0.0518\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0096 - mean_absolute_error: 0.0027 - val_loss: 0.6410 - val_mean_absolute_error: 0.0484\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0103 - mean_absolute_error: 0.0030 - val_loss: 0.6468 - val_mean_absolute_error: 0.0493\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0097 - mean_absolute_error: 0.0026 - val_loss: 0.6685 - val_mean_absolute_error: 0.0480\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0097 - mean_absolute_error: 0.0028 - val_loss: 0.6542 - val_mean_absolute_error: 0.0482\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0095 - mean_absolute_error: 0.0027 - val_loss: 0.6589 - val_mean_absolute_error: 0.0492\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0089 - mean_absolute_error: 0.0028 - val_loss: 0.6528 - val_mean_absolute_error: 0.0508\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0097 - mean_absolute_error: 0.0026 - val_loss: 0.6534 - val_mean_absolute_error: 0.0488\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0099 - mean_absolute_error: 0.0028 - val_loss: 0.6167 - val_mean_absolute_error: 0.0512\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0098 - mean_absolute_error: 0.0029 - val_loss: 0.6415 - val_mean_absolute_error: 0.0492\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0111 - mean_absolute_error: 0.0032 - val_loss: 0.6119 - val_mean_absolute_error: 0.0527\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0132 - mean_absolute_error: 0.0038 - val_loss: 0.6450 - val_mean_absolute_error: 0.0493\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0625 - mean_absolute_error: 0.0175 - val_loss: 0.5285 - val_mean_absolute_error: 0.0640\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0426 - mean_absolute_error: 0.0128 - val_loss: 0.6218 - val_mean_absolute_error: 0.0513\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0221 - mean_absolute_error: 0.0071 - val_loss: 0.5985 - val_mean_absolute_error: 0.0526\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 0.0159 - mean_absolute_error: 0.0046 - val_loss: 0.6186 - val_mean_absolute_error: 0.0511\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0103 - mean_absolute_error: 0.0031 - val_loss: 0.6298 - val_mean_absolute_error: 0.0526\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0096 - mean_absolute_error: 0.0027 - val_loss: 0.6530 - val_mean_absolute_error: 0.0514\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0099 - mean_absolute_error: 0.0030 - val_loss: 0.6525 - val_mean_absolute_error: 0.0528\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0091 - mean_absolute_error: 0.0027 - val_loss: 0.6764 - val_mean_absolute_error: 0.0494\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0096 - mean_absolute_error: 0.0027 - val_loss: 0.6542 - val_mean_absolute_error: 0.0524\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0106 - mean_absolute_error: 0.0029 - val_loss: 0.6654 - val_mean_absolute_error: 0.0536\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0090 - mean_absolute_error: 0.0027 - val_loss: 0.6886 - val_mean_absolute_error: 0.0493\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0085 - mean_absolute_error: 0.0026 - val_loss: 0.6952 - val_mean_absolute_error: 0.0495\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 0.0101 - mean_absolute_error: 0.0027 - val_loss: 0.6785 - val_mean_absolute_error: 0.0518\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0095 - mean_absolute_error: 0.0027 - val_loss: 0.6898 - val_mean_absolute_error: 0.0496\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0093 - mean_absolute_error: 0.0026 - val_loss: 0.6978 - val_mean_absolute_error: 0.0514\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0090 - mean_absolute_error: 0.0026 - val_loss: 0.6864 - val_mean_absolute_error: 0.0536\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0086 - mean_absolute_error: 0.0025 - val_loss: 0.6942 - val_mean_absolute_error: 0.0504\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0092 - mean_absolute_error: 0.0026 - val_loss: 0.7000 - val_mean_absolute_error: 0.0497\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0097 - mean_absolute_error: 0.0027 - val_loss: 0.7344 - val_mean_absolute_error: 0.0488\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0089 - mean_absolute_error: 0.0025 - val_loss: 0.7335 - val_mean_absolute_error: 0.0494\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0087 - mean_absolute_error: 0.0026 - val_loss: 0.7148 - val_mean_absolute_error: 0.0500\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 25s 193ms/step - loss: 0.0094 - mean_absolute_error: 0.0027 - val_loss: 0.7326 - val_mean_absolute_error: 0.0493\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0100 - mean_absolute_error: 0.0028 - val_loss: 0.6660 - val_mean_absolute_error: 0.0497\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 0.0668 - mean_absolute_error: 0.0166 - val_loss: 0.4725 - val_mean_absolute_error: 0.0596\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0545 - mean_absolute_error: 0.0163 - val_loss: 0.5828 - val_mean_absolute_error: 0.0512\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0234 - mean_absolute_error: 0.0076 - val_loss: 0.5880 - val_mean_absolute_error: 0.0513\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0147 - mean_absolute_error: 0.0043 - val_loss: 0.6001 - val_mean_absolute_error: 0.0524\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0108 - mean_absolute_error: 0.0033 - val_loss: 0.6366 - val_mean_absolute_error: 0.0496\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0135 - mean_absolute_error: 0.0037 - val_loss: 0.6250 - val_mean_absolute_error: 0.0484\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 25s 194ms/step - loss: 0.0100 - mean_absolute_error: 0.0029 - val_loss: 0.6413 - val_mean_absolute_error: 0.0484\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 0.0102 - mean_absolute_error: 0.0029 - val_loss: 0.6224 - val_mean_absolute_error: 0.0490\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 0.0095 - mean_absolute_error: 0.0028 - val_loss: 0.6384 - val_mean_absolute_error: 0.0492\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 0.0093 - mean_absolute_error: 0.0028 - val_loss: 0.6614 - val_mean_absolute_error: 0.0487\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 25s 196ms/step - loss: 0.0087 - mean_absolute_error: 0.0027 - val_loss: 0.6590 - val_mean_absolute_error: 0.0484\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0102 - mean_absolute_error: 0.0029 - val_loss: 0.6830 - val_mean_absolute_error: 0.0487\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 26s 196ms/step - loss: 0.0094 - mean_absolute_error: 0.0026 - val_loss: 0.6412 - val_mean_absolute_error: 0.0500\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0101 - mean_absolute_error: 0.0029 - val_loss: 0.6881 - val_mean_absolute_error: 0.0490\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0094 - mean_absolute_error: 0.0027 - val_loss: 0.6570 - val_mean_absolute_error: 0.0493\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 25s 195ms/step - loss: 0.0095 - mean_absolute_error: 0.0027 - val_loss: 0.6941 - val_mean_absolute_error: 0.0487\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 26s 197ms/step - loss: 0.0081 - mean_absolute_error: 0.0026 - val_loss: 0.6962 - val_mean_absolute_error: 0.0487\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_24 (Bidirecti  (None, 200)              490400    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 200)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 491,204\n",
      "Trainable params: 491,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 28s 208ms/step - loss: 0.5087 - mean_absolute_error: 0.1232 - val_loss: 0.4220 - val_mean_absolute_error: 0.1038\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.3914 - mean_absolute_error: 0.0993 - val_loss: 0.4614 - val_mean_absolute_error: 0.1311\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.3509 - mean_absolute_error: 0.0921 - val_loss: 0.4297 - val_mean_absolute_error: 0.0858\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 26s 200ms/step - loss: 0.3065 - mean_absolute_error: 0.0807 - val_loss: 0.3982 - val_mean_absolute_error: 0.0974\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.2561 - mean_absolute_error: 0.0717 - val_loss: 0.4386 - val_mean_absolute_error: 0.0832\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.1996 - mean_absolute_error: 0.0587 - val_loss: 0.4382 - val_mean_absolute_error: 0.0765\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.1461 - mean_absolute_error: 0.0454 - val_loss: 0.4435 - val_mean_absolute_error: 0.0804\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 26s 200ms/step - loss: 0.1096 - mean_absolute_error: 0.0354 - val_loss: 0.4803 - val_mean_absolute_error: 0.0803\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0914 - mean_absolute_error: 0.0300 - val_loss: 0.4994 - val_mean_absolute_error: 0.0741\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0648 - mean_absolute_error: 0.0222 - val_loss: 0.5695 - val_mean_absolute_error: 0.0684\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 26s 200ms/step - loss: 0.0426 - mean_absolute_error: 0.0146 - val_loss: 0.6415 - val_mean_absolute_error: 0.0721\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130/130 [==============================] - 26s 200ms/step - loss: 0.0380 - mean_absolute_error: 0.0123 - val_loss: 0.6253 - val_mean_absolute_error: 0.0723\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0316 - mean_absolute_error: 0.0099 - val_loss: 0.6291 - val_mean_absolute_error: 0.0787\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0276 - mean_absolute_error: 0.0092 - val_loss: 0.6677 - val_mean_absolute_error: 0.0700\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 26s 200ms/step - loss: 0.0324 - mean_absolute_error: 0.0099 - val_loss: 0.6442 - val_mean_absolute_error: 0.0727\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 26s 200ms/step - loss: 0.0326 - mean_absolute_error: 0.0110 - val_loss: 0.6827 - val_mean_absolute_error: 0.0739\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0278 - mean_absolute_error: 0.0089 - val_loss: 0.6753 - val_mean_absolute_error: 0.0711\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0207 - mean_absolute_error: 0.0063 - val_loss: 0.8064 - val_mean_absolute_error: 0.0668\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 26s 200ms/step - loss: 0.0254 - mean_absolute_error: 0.0082 - val_loss: 0.7483 - val_mean_absolute_error: 0.0763\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 26s 200ms/step - loss: 0.0160 - mean_absolute_error: 0.0048 - val_loss: 0.8649 - val_mean_absolute_error: 0.0695\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0163 - mean_absolute_error: 0.0048 - val_loss: 0.8026 - val_mean_absolute_error: 0.0666\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0138 - mean_absolute_error: 0.0037 - val_loss: 0.7703 - val_mean_absolute_error: 0.0701\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 26s 200ms/step - loss: 0.0130 - mean_absolute_error: 0.0035 - val_loss: 0.8218 - val_mean_absolute_error: 0.0688\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0117 - mean_absolute_error: 0.0032 - val_loss: 0.9230 - val_mean_absolute_error: 0.0684\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0128 - mean_absolute_error: 0.0037 - val_loss: 0.8761 - val_mean_absolute_error: 0.0665\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0130 - mean_absolute_error: 0.0038 - val_loss: 0.8460 - val_mean_absolute_error: 0.0684\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0215 - mean_absolute_error: 0.0067 - val_loss: 0.6458 - val_mean_absolute_error: 0.0766\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0756 - mean_absolute_error: 0.0226 - val_loss: 0.6594 - val_mean_absolute_error: 0.0827\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0241 - mean_absolute_error: 0.0079 - val_loss: 0.7147 - val_mean_absolute_error: 0.0705\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0148 - mean_absolute_error: 0.0050 - val_loss: 0.7886 - val_mean_absolute_error: 0.0725\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0144 - mean_absolute_error: 0.0039 - val_loss: 0.8186 - val_mean_absolute_error: 0.0693\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0128 - mean_absolute_error: 0.0033 - val_loss: 0.8007 - val_mean_absolute_error: 0.0715\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0106 - mean_absolute_error: 0.0031 - val_loss: 0.8298 - val_mean_absolute_error: 0.0671\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0103 - mean_absolute_error: 0.0030 - val_loss: 0.8312 - val_mean_absolute_error: 0.0731\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0099 - mean_absolute_error: 0.0029 - val_loss: 0.8676 - val_mean_absolute_error: 0.0675\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0109 - mean_absolute_error: 0.0030 - val_loss: 0.8488 - val_mean_absolute_error: 0.0668\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0106 - mean_absolute_error: 0.0030 - val_loss: 0.8706 - val_mean_absolute_error: 0.0669\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0095 - mean_absolute_error: 0.0027 - val_loss: 0.8375 - val_mean_absolute_error: 0.0675\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0089 - mean_absolute_error: 0.0027 - val_loss: 0.8604 - val_mean_absolute_error: 0.0681\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0103 - mean_absolute_error: 0.0030 - val_loss: 0.8777 - val_mean_absolute_error: 0.0655\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0122 - mean_absolute_error: 0.0030 - val_loss: 0.8294 - val_mean_absolute_error: 0.0701\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0109 - mean_absolute_error: 0.0029 - val_loss: 0.8736 - val_mean_absolute_error: 0.0682\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0353 - mean_absolute_error: 0.0103 - val_loss: 0.6034 - val_mean_absolute_error: 0.0791\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0624 - mean_absolute_error: 0.0194 - val_loss: 0.7775 - val_mean_absolute_error: 0.0667\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 26s 200ms/step - loss: 0.0391 - mean_absolute_error: 0.0126 - val_loss: 0.7475 - val_mean_absolute_error: 0.0789\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0202 - mean_absolute_error: 0.0062 - val_loss: 0.8536 - val_mean_absolute_error: 0.0660\n",
      "Epoch 47/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0123 - mean_absolute_error: 0.0033 - val_loss: 0.8458 - val_mean_absolute_error: 0.0664\n",
      "Epoch 48/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0107 - mean_absolute_error: 0.0029 - val_loss: 0.8736 - val_mean_absolute_error: 0.0653\n",
      "Epoch 49/100\n",
      "130/130 [==============================] - 26s 200ms/step - loss: 0.0088 - mean_absolute_error: 0.0026 - val_loss: 0.8988 - val_mean_absolute_error: 0.0652\n",
      "Epoch 50/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0083 - mean_absolute_error: 0.0025 - val_loss: 0.8768 - val_mean_absolute_error: 0.0648\n",
      "Epoch 51/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0101 - mean_absolute_error: 0.0028 - val_loss: 0.8961 - val_mean_absolute_error: 0.0634\n",
      "Epoch 52/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0081 - mean_absolute_error: 0.0025 - val_loss: 0.9181 - val_mean_absolute_error: 0.0633\n",
      "Epoch 53/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0099 - mean_absolute_error: 0.0027 - val_loss: 0.8946 - val_mean_absolute_error: 0.0638\n",
      "Epoch 54/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0087 - mean_absolute_error: 0.0026 - val_loss: 0.9475 - val_mean_absolute_error: 0.0618\n",
      "Epoch 55/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0088 - mean_absolute_error: 0.0023 - val_loss: 0.9722 - val_mean_absolute_error: 0.0647\n",
      "Epoch 56/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0091 - mean_absolute_error: 0.0027 - val_loss: 0.9412 - val_mean_absolute_error: 0.0649\n",
      "Epoch 57/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0094 - mean_absolute_error: 0.0025 - val_loss: 0.9533 - val_mean_absolute_error: 0.0639\n",
      "Epoch 58/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0083 - mean_absolute_error: 0.0025 - val_loss: 0.9811 - val_mean_absolute_error: 0.0627\n",
      "Epoch 59/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0074 - mean_absolute_error: 0.0023 - val_loss: 0.9169 - val_mean_absolute_error: 0.0662\n",
      "Epoch 60/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0088 - mean_absolute_error: 0.0025 - val_loss: 0.9451 - val_mean_absolute_error: 0.0649\n",
      "Epoch 61/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0092 - mean_absolute_error: 0.0026 - val_loss: 0.9451 - val_mean_absolute_error: 0.0658\n",
      "Epoch 62/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0079 - mean_absolute_error: 0.0024 - val_loss: 0.9911 - val_mean_absolute_error: 0.0644\n",
      "Epoch 63/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0072 - mean_absolute_error: 0.0023 - val_loss: 1.0190 - val_mean_absolute_error: 0.0633\n",
      "Epoch 64/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0079 - mean_absolute_error: 0.0023 - val_loss: 1.0991 - val_mean_absolute_error: 0.0667\n",
      "Epoch 65/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0088 - mean_absolute_error: 0.0026 - val_loss: 1.0223 - val_mean_absolute_error: 0.0645\n",
      "Epoch 66/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0121 - mean_absolute_error: 0.0035 - val_loss: 0.8094 - val_mean_absolute_error: 0.0796\n",
      "Epoch 67/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0905 - mean_absolute_error: 0.0258 - val_loss: 0.6707 - val_mean_absolute_error: 0.0736\n",
      "Epoch 68/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0224 - mean_absolute_error: 0.0075 - val_loss: 0.7902 - val_mean_absolute_error: 0.0728\n",
      "Epoch 69/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0157 - mean_absolute_error: 0.0047 - val_loss: 0.8822 - val_mean_absolute_error: 0.0649\n",
      "Epoch 70/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0112 - mean_absolute_error: 0.0036 - val_loss: 0.8840 - val_mean_absolute_error: 0.0649\n",
      "Epoch 71/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0097 - mean_absolute_error: 0.0030 - val_loss: 0.8716 - val_mean_absolute_error: 0.0648\n",
      "Epoch 72/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0087 - mean_absolute_error: 0.0027 - val_loss: 0.9214 - val_mean_absolute_error: 0.0631\n",
      "Epoch 73/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0086 - mean_absolute_error: 0.0023 - val_loss: 0.9451 - val_mean_absolute_error: 0.0630\n",
      "Epoch 74/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0073 - mean_absolute_error: 0.0024 - val_loss: 0.9404 - val_mean_absolute_error: 0.0628\n",
      "Epoch 75/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0074 - mean_absolute_error: 0.0023 - val_loss: 0.9648 - val_mean_absolute_error: 0.0628\n",
      "Epoch 76/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0089 - mean_absolute_error: 0.0026 - val_loss: 0.9751 - val_mean_absolute_error: 0.0627\n",
      "Epoch 77/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0086 - mean_absolute_error: 0.0025 - val_loss: 0.9946 - val_mean_absolute_error: 0.0631\n",
      "Epoch 78/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0078 - mean_absolute_error: 0.0024 - val_loss: 0.9774 - val_mean_absolute_error: 0.0634\n",
      "Epoch 79/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0076 - mean_absolute_error: 0.0024 - val_loss: 1.0154 - val_mean_absolute_error: 0.0611\n",
      "Epoch 80/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0085 - mean_absolute_error: 0.0025 - val_loss: 0.9930 - val_mean_absolute_error: 0.0615\n",
      "Epoch 81/100\n",
      "130/130 [==============================] - 26s 200ms/step - loss: 0.0086 - mean_absolute_error: 0.0023 - val_loss: 1.0132 - val_mean_absolute_error: 0.0621\n",
      "Epoch 82/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0071 - mean_absolute_error: 0.0022 - val_loss: 0.9559 - val_mean_absolute_error: 0.0636\n",
      "Epoch 83/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0072 - mean_absolute_error: 0.0022 - val_loss: 1.0469 - val_mean_absolute_error: 0.0628\n",
      "Epoch 84/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0075 - mean_absolute_error: 0.0023 - val_loss: 0.9802 - val_mean_absolute_error: 0.0622\n",
      "Epoch 85/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0075 - mean_absolute_error: 0.0024 - val_loss: 0.9902 - val_mean_absolute_error: 0.0629\n",
      "Epoch 86/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0084 - mean_absolute_error: 0.0024 - val_loss: 1.0291 - val_mean_absolute_error: 0.0634\n",
      "Epoch 87/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0131 - mean_absolute_error: 0.0039 - val_loss: 0.9115 - val_mean_absolute_error: 0.0678\n",
      "Epoch 88/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0791 - mean_absolute_error: 0.0206 - val_loss: 0.7340 - val_mean_absolute_error: 0.0783\n",
      "Epoch 89/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0321 - mean_absolute_error: 0.0104 - val_loss: 0.8602 - val_mean_absolute_error: 0.0740\n",
      "Epoch 90/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0208 - mean_absolute_error: 0.0065 - val_loss: 0.8443 - val_mean_absolute_error: 0.0707\n",
      "Epoch 91/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0127 - mean_absolute_error: 0.0041 - val_loss: 0.9019 - val_mean_absolute_error: 0.0668\n",
      "Epoch 92/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0088 - mean_absolute_error: 0.0026 - val_loss: 0.9487 - val_mean_absolute_error: 0.0674\n",
      "Epoch 93/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0087 - mean_absolute_error: 0.0025 - val_loss: 0.9899 - val_mean_absolute_error: 0.0672\n",
      "Epoch 94/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0081 - mean_absolute_error: 0.0024 - val_loss: 0.9726 - val_mean_absolute_error: 0.0661\n",
      "Epoch 95/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0080 - mean_absolute_error: 0.0024 - val_loss: 1.0126 - val_mean_absolute_error: 0.0648\n",
      "Epoch 96/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0085 - mean_absolute_error: 0.0025 - val_loss: 0.9987 - val_mean_absolute_error: 0.0660\n",
      "Epoch 97/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0068 - mean_absolute_error: 0.0022 - val_loss: 0.9980 - val_mean_absolute_error: 0.0674\n",
      "Epoch 98/100\n",
      "130/130 [==============================] - 26s 200ms/step - loss: 0.0074 - mean_absolute_error: 0.0022 - val_loss: 1.0202 - val_mean_absolute_error: 0.0656\n",
      "Epoch 99/100\n",
      "130/130 [==============================] - 26s 198ms/step - loss: 0.0074 - mean_absolute_error: 0.0023 - val_loss: 1.0404 - val_mean_absolute_error: 0.0658\n",
      "Epoch 100/100\n",
      "130/130 [==============================] - 26s 199ms/step - loss: 0.0082 - mean_absolute_error: 0.0024 - val_loss: 1.0237 - val_mean_absolute_error: 0.0666\n",
      "Wall time: 6h 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "directory_name = \"Data/PSMs/per_schema_models_bert\"\n",
    "for i in range(9):\n",
    "    train_label_schema = np_utils.to_categorical(train_labels[:,i])\n",
    "    val_label_schema = np_utils.to_categorical(val_labels[:,i])\n",
    "    val_output_slm, model = perschema_models_bert(train_outputs[\"sequence_output\"],train_label_schema,val_outputs[\"sequence_output\"],val_label_schema)\n",
    "    #we write trained models to files to free up working memory\n",
    "    model_name = '/schema_model_' + schemas[i]\n",
    "    save_model_under = directory_name + model_name\n",
    "    model.save(save_model_under + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load single models\n",
    "def load_single_models(directory):\n",
    "    single_models = []\n",
    "    for i in range(9):\n",
    "        model_name ='/schema_model_' + schemas[i]\n",
    "        get_from = directory + model_name\n",
    "        model = keras.models.load_model(get_from + '.h5')\n",
    "        single_models.append(model)\n",
    "    return single_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate predictions with the per-schema models\n",
    "def predict_schema_psm(test_text, test_labels, model_name):\n",
    "    directory_name= \"Data/PSMs/per_schema_models_\" + model_name\n",
    "    all_preds = np.zeros(test_labels.shape)\n",
    "    all_gofs = []\n",
    "    single_models = load_single_models(directory_name)\n",
    "    for i in range(9):\n",
    "        model = single_models[i]\n",
    "        out = model.predict(test_text)\n",
    "        out = out.argmax(axis=1)\n",
    "        all_preds[:,i] = out\n",
    "        gof,p=scipy.stats.spearmanr(out,test_labels[:,i])\n",
    "        all_gofs.append(gof)\n",
    "    return all_gofs,all_preds    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Testset Predictions with the RNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_rnn(test_X,test_y,single, model_name):\n",
    "    if single:\n",
    "        gof,preds=predict_schema_psm(test_X,test_y, model_name)\n",
    "    else:\n",
    "        gof,preds=predict_schema_mlm(test_X,test_y, model_name)\n",
    "    return gof, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# wall time to run: ~  43.2 s\n",
    "# predicting testset with multilabel model\n",
    "output_mlm_glove,idx_mlm_glove = my_rnn(padded_test,test_labels, 0, \"glove\")\n",
    "# predicting testset with multilabel model\n",
    "output_mlm_bert,idx_mlm_bert = my_rnn(test_outputs[\"sequence_output\"],test_labels, 0, \"bert\")\n",
    "# predicting testset with perschema models\n",
    "output_psm_glove,idx_psm_glove = my_rnn(padded_test,test_labels, 1, \"glove\")\n",
    "\n",
    "# predicting testset with perschema models\n",
    "output_psm_bert,idx_psm_bert = my_rnn(test_outputs[\"sequence_output\"],test_labels, 1, \"bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN Multilabel Model Testset Output GLoVE\n",
      "          estimate\n",
      "Attach         NaN\n",
      "Comp           NaN\n",
      "Global         NaN\n",
      "Health         NaN\n",
      "Control        NaN\n",
      "MetaCog        NaN\n",
      "Others         NaN\n",
      "Hopeless       NaN\n",
      "OthViews       NaN\n"
     ]
    }
   ],
   "source": [
    "print('RNN Multilabel Model Testset Output GLoVE')\n",
    "print(pd.DataFrame(data=output_mlm_glove,index=schemas,columns=['estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN Multilabel Model Testset Output BERT\n",
      "          estimate\n",
      "Attach         NaN\n",
      "Comp           NaN\n",
      "Global         NaN\n",
      "Health         NaN\n",
      "Control        NaN\n",
      "MetaCog        NaN\n",
      "Others         NaN\n",
      "Hopeless       NaN\n",
      "OthViews       NaN\n"
     ]
    }
   ],
   "source": [
    "print('RNN Multilabel Model Testset Output BERT')\n",
    "print(pd.DataFrame(data=output_mlm_bert,index=schemas,columns=['estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN Per-Schema Testset Output GLoVE\n",
      "          estimate\n",
      "Attach    0.689987\n",
      "Comp      0.720595\n",
      "Global    0.565708\n",
      "Health    0.780698\n",
      "Control   0.277295\n",
      "MetaCog  -0.009075\n",
      "Others    0.180899\n",
      "Hopeless  0.590422\n",
      "OthViews  0.600660\n"
     ]
    }
   ],
   "source": [
    "print('RNN Per-Schema Testset Output GLoVE')\n",
    "print(pd.DataFrame(data=output_psm_glove,index=schemas,columns=['estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN Per-Schema Testset Output BERT\n",
      "          estimate\n",
      "Attach    0.737940\n",
      "Comp      0.767731\n",
      "Global    0.565223\n",
      "Health    0.747472\n",
      "Control   0.213274\n",
      "MetaCog   0.178619\n",
      "Others    0.177825\n",
      "Hopeless  0.639479\n",
      "OthViews  0.621209\n"
     ]
    }
   ],
   "source": [
    "print('RNN Per-Schema Testset Output BERT')\n",
    "print(pd.DataFrame(data=output_psm_bert,index=schemas,columns=['estimate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_rnn_fixed(test_X,test_y,single, model_name):\n",
    "    if single:\n",
    "        gof,preds=predict_schema_psm(test_X,test_y,\"glove\")\n",
    "    else:\n",
    "        gof,preds=predict_schema_mlm(test_X,test_y,idx_mlm[0])\n",
    "    return gof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# wall time to run: ~ 37min\n",
    "#bootstrapping the 95% confidence intervals\n",
    "#bs_mlm = bootstrap(n_iterations,n_size,padded_test,test_labels,0,\"rnn\")\n",
    "bs_psm = bootstrap(n_iterations,n_size,padded_test,test_labels,1,\"rnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Results for quick loading later if project stops\n",
    "joblib.dump(bs_svc_glove, 'Data/BootstrapResults/RNN/bs_svc_glove.pkl')\n",
    "joblib.dump(bs_svr_glove, 'Data/BootstrapResults/RNN/bs_svr_glove.pkl')\n",
    "joblib.dump(bs_svc_bert, 'Data/BootstrapResults/RNN/bs_svc_bert.pkl')\n",
    "joblib.dump(bs_svr_bert, 'Data/BootstrapResults/RNN/bs_svr_bert.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Multilabel RNN Classification 95% Confidence Intervals')\n",
    "print(pd.DataFrame(data=np.transpose(bs_mlm),index=schemas,columns=['low','high']))\n",
    "print(f'Per-Schema RNN Classification 95% Confidence Intervals')\n",
    "print(pd.DataFrame(data=np.transpose(bs_psm),index=schemas,columns=['low','high']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of Hypothesis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12108/2039024429.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput_psm_glove_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput_psm_glove\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#output_mlm_flat = [item for sublist in output_mlm for item in sublist]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12108/2039024429.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutput_psm_glove_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msublist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput_psm_glove\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msublist\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#output_mlm_flat = [item for sublist in output_mlm for item in sublist]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "output_psm_glove_flat = [item for sublist in output_psm_glove for item in sublist]\n",
    "#output_mlm_flat = [item for sublist in output_mlm for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimates of all models with GLoVE Embeddings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kNN_class</th>\n",
       "      <th>kNN_reg</th>\n",
       "      <th>SVC</th>\n",
       "      <th>SVR</th>\n",
       "      <th>PSM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attach</th>\n",
       "      <td>0.130606</td>\n",
       "      <td>0.606499</td>\n",
       "      <td>0.647714</td>\n",
       "      <td>0.675340</td>\n",
       "      <td>0.689987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comp</th>\n",
       "      <td>0.135201</td>\n",
       "      <td>0.701906</td>\n",
       "      <td>0.684661</td>\n",
       "      <td>0.640866</td>\n",
       "      <td>0.720595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Global</th>\n",
       "      <td>0.204418</td>\n",
       "      <td>0.417896</td>\n",
       "      <td>0.357601</td>\n",
       "      <td>0.489372</td>\n",
       "      <td>0.565708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health</th>\n",
       "      <td>0.249344</td>\n",
       "      <td>0.656053</td>\n",
       "      <td>0.729181</td>\n",
       "      <td>0.349064</td>\n",
       "      <td>0.780698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Control</th>\n",
       "      <td>-0.011459</td>\n",
       "      <td>0.216933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.310007</td>\n",
       "      <td>0.277295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetaCog</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114894</td>\n",
       "      <td>-0.009075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.237087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.185827</td>\n",
       "      <td>0.180899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hopeless</th>\n",
       "      <td>0.167857</td>\n",
       "      <td>0.534698</td>\n",
       "      <td>0.489903</td>\n",
       "      <td>0.535979</td>\n",
       "      <td>0.590422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OthViews</th>\n",
       "      <td>0.157289</td>\n",
       "      <td>0.461305</td>\n",
       "      <td>0.476297</td>\n",
       "      <td>0.516635</td>\n",
       "      <td>0.600660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          kNN_class   kNN_reg       SVC       SVR       PSM\n",
       "Attach     0.130606  0.606499  0.647714  0.675340  0.689987\n",
       "Comp       0.135201  0.701906  0.684661  0.640866  0.720595\n",
       "Global     0.204418  0.417896  0.357601  0.489372  0.565708\n",
       "Health     0.249344  0.656053  0.729181  0.349064  0.780698\n",
       "Control   -0.011459  0.216933       NaN  0.310007  0.277295\n",
       "MetaCog         NaN  0.019173       NaN  0.114894 -0.009075\n",
       "Others          NaN  0.237087       NaN  0.185827  0.180899\n",
       "Hopeless   0.167857  0.534698  0.489903  0.535979  0.590422\n",
       "OthViews   0.157289  0.461305  0.476297  0.516635  0.600660"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Estimates of all models with GLoVE Embeddings')\n",
    "outputs = np.concatenate((output_kNN_class_glove,output_kNN_reg_glove,output_SVC_glove, output_SVR_glove, output_psm_glove))#, output_mlm_glove))\n",
    "outputs=np.reshape(outputs,(9,5),order='F')\n",
    "pd.DataFrame(data=outputs,index=schemas,columns=['kNN_class','kNN_reg','SVC','SVR','PSM'])#,'MLM']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimates of all models with BERT Embeddings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kNN_class</th>\n",
       "      <th>kNN_reg</th>\n",
       "      <th>SVC</th>\n",
       "      <th>SVR</th>\n",
       "      <th>PSM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Attach</th>\n",
       "      <td>0.531913</td>\n",
       "      <td>0.527163</td>\n",
       "      <td>0.577022</td>\n",
       "      <td>0.663786</td>\n",
       "      <td>0.737940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comp</th>\n",
       "      <td>0.587256</td>\n",
       "      <td>0.604087</td>\n",
       "      <td>0.689898</td>\n",
       "      <td>0.672748</td>\n",
       "      <td>0.767731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Global</th>\n",
       "      <td>0.375899</td>\n",
       "      <td>0.399843</td>\n",
       "      <td>0.373424</td>\n",
       "      <td>0.506108</td>\n",
       "      <td>0.565223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health</th>\n",
       "      <td>0.500031</td>\n",
       "      <td>0.406143</td>\n",
       "      <td>0.561481</td>\n",
       "      <td>0.305131</td>\n",
       "      <td>0.747472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Control</th>\n",
       "      <td>0.102623</td>\n",
       "      <td>0.198838</td>\n",
       "      <td>-0.011459</td>\n",
       "      <td>0.306820</td>\n",
       "      <td>0.213274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetaCog</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042465</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.141697</td>\n",
       "      <td>0.178619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>0.183972</td>\n",
       "      <td>0.142093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114909</td>\n",
       "      <td>0.177825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hopeless</th>\n",
       "      <td>0.491567</td>\n",
       "      <td>0.459757</td>\n",
       "      <td>0.517952</td>\n",
       "      <td>0.521259</td>\n",
       "      <td>0.639479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OthViews</th>\n",
       "      <td>0.401721</td>\n",
       "      <td>0.437244</td>\n",
       "      <td>0.471861</td>\n",
       "      <td>0.491448</td>\n",
       "      <td>0.621209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          kNN_class   kNN_reg       SVC       SVR       PSM\n",
       "Attach     0.531913  0.527163  0.577022  0.663786  0.737940\n",
       "Comp       0.587256  0.604087  0.689898  0.672748  0.767731\n",
       "Global     0.375899  0.399843  0.373424  0.506108  0.565223\n",
       "Health     0.500031  0.406143  0.561481  0.305131  0.747472\n",
       "Control    0.102623  0.198838 -0.011459  0.306820  0.213274\n",
       "MetaCog         NaN  0.042465       NaN  0.141697  0.178619\n",
       "Others     0.183972  0.142093       NaN  0.114909  0.177825\n",
       "Hopeless   0.491567  0.459757  0.517952  0.521259  0.639479\n",
       "OthViews   0.401721  0.437244  0.471861  0.491448  0.621209"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Estimates of all models with BERT Embeddings')\n",
    "outputs = np.concatenate((output_kNN_class_bert,output_kNN_reg_bert,output_SVC_bert, output_SVR_bert, output_psm_bert))#, output_mlm_glove))\n",
    "outputs=np.reshape(outputs,(9,5),order='F')\n",
    "pd.DataFrame(data=outputs,index=schemas,columns=['kNN_class','kNN_reg','SVC','SVR','PSM'])#)#,'MLM']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Lower CIs of all models')\n",
    "lower_cis = np.concatenate((bs_knn_class[0],bs_knn_reg[0],bs_svc[0], bs_svr[0], bs_psm[0], bs_mlm[0]))\n",
    "lower_cis=np.reshape(lower_cis,(9,6),order='F')\n",
    "print(pd.DataFrame(data=lower_cis,index=schemas,columns=['kNN_class','kNN_reg','SVC','SVR','PSM','MLM']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Upper CIs of all models')\n",
    "upper_cis = np.concatenate((bs_knn_class[1],bs_knn_reg[1],bs_svc[1], bs_svr[1], bs_psm[1], bs_mlm[1]))\n",
    "upper_cis=np.reshape(upper_cis,(9,6),order='F')\n",
    "print(pd.DataFrame(data=upper_cis,index=schemas,columns=['kNN_class','kNN_reg','SVC','SVR','PSM','MLM']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset for Testing Hypothesis 2\n",
    "Finally, we need to use the best-performing algorithm, the per-schema RNNs, to generate the predictions on the testset and write these to a file so that we can use them to test Hypothesis 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gofH2,predsH2=predict_schema_psm(padded_test,test_labels,idx_psm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predsH2 = predsH2.astype(int)\n",
    "print(predsH2[:,0:5])\n",
    "diag_rho = [scipy.stats.spearmanr(predsH2[i,:], test_labels[i,0:9], nan_policy='omit')[0] for i in range(predsH2.shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predsH2 = pd.DataFrame(data=predsH2,columns=['AttachPred','CompPred',\"GlobalPred\",\"HealthPred\",\"ControlPred\",\"MetaCogPred\",\"OthersPred\",\"HopelessPred\",\"OthViewsPred\"])\n",
    "df_predsH2[\"Corr\"] = pd.DataFrame(diag_rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_predsH2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predsH2.to_csv(\"Data/PredictionsH2.csv\", sep=';', header=True, index=False, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
