require(philentropy)
require(lm.beta)
require(extrafont)
require(rstudioapi)
font_import(pattern="[A/a]rial", prompt=FALSE)
# #set working directory to data folder (using rstudioapi)
# filepath = rstudioapi::getActiveDocumentContext()$path
# setwd(dirname(filepath))
#set working directory otherwise
setwd("~/surfdrive/Documents/Projects/ThoughtRecordChatbot/Experiments/Exploratory_TRs/Documents/DataRepository/Analysis")
#print session info
sessionInfo()
#set seed for everything to follow
char2seed("Burger",set=TRUE)
# #set working directory to data folder (using rstudioapi)
# filepath = rstudioapi::getActiveDocumentContext()$path
# setwd(dirname(filepath))
#set working directory otherwise
setwd("~/surfdrive/Documents/Projects/ThoughtRecordChatbot/Experiments/Exploratory_TRs/Documents/DataRepository/Analysis")
# #set working directory to data folder (using rstudioapi)
# filepath = rstudioapi::getActiveDocumentContext()$path
# setwd(dirname(filepath))
#set working directory otherwise
setwd("~/surfdrive/Documents/Projects/ThoughtRecordChatbot/Experiments/Exploratory_TRs/Documents/DataRepository/AnalysisArticle")
df.datademo <- read.csv("Data/Demographics.csv",
na.strings = "", header=TRUE,
sep=";",fill=TRUE)
#select only the interesting columns
df.datademo <- df.datademo[,c("Duration","Gender","Age")]
#calculate average duration in minutes
durinmin <- mean(as.numeric(as.character(df.datademo$Duration)))/60
#distribution of genders
df.gender <- df.datademo %>%
group_by(Gender) %>%
summarise(genders=n())
print(df.gender)
#distribution of age
psych::describe(as.numeric(as.character(df.datademo$Age)))
df.subset_100_test <-
read.csv("Data/IRR/c1c4/Testing/testset.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
#we collapse the final 3 categories of original dataset to one
#"Other" category
df.subset_100_test$Other2 <- apply(df.subset_100_test[3:11],1,sum)
df.subset_100_test$Other <- ifelse(df.subset_100_test$Other2==0, 1,0)
df1 <- df.subset_100_test[3:11]
df.test.recoded_c1 <-
read.csv("Data/IRR/c1c4/Testing/testset_recoding_c1.csv",
na.strings = "",
header=FALSE,
sep=";",
fill=TRUE)
#copy header from test df
df2 <- df.test.recoded_c1[2:10]
colnames(df2) <- colnames(df1)
df.test_c4 <-
read.csv("Data/IRR/c1c4/Testing/testset_coded_c4.csv",
na.strings = "",
header=FALSE,
sep=";",
fill=TRUE)
#copy header from test df
df3 <- df.test_c4[2:10]
colnames(df3) <- colnames(df1)
#change dataframes to long format
df1.long <- gather(df1,schema,rating,Attach:OthViews,
factor_key = TRUE)
df2.long <- gather(df2,schema,rating,Attach:OthViews,
factor_key = TRUE)
df3.long <- gather(df3,schema,rating,Attach:OthViews,
factor_key = TRUE)
#calculate IRR as weighted cohen's kappa
wkappa_c1c1 <- kappa2(data.frame(df1.long$rating,df2.long$rating),
weight="squared")
wkappa_c1c4 <- kappa2(data.frame(df1.long$rating,df3.long$rating),
weight="squared")
#read in the core thought record data
df <- read.csv("Data/CoreData.csv",na.strings = "", header=TRUE, sep=";",fill=TRUE)
schemas <- c("Attach","Comp","Global","Health","Control","MetaCog","Others","Hopeless","OthViews")
#select only relevant columns and rows
df <- df[which(df$UttEnum!="NA"),c("Reply",schemas,"Exclude","UttEnum","Scenario","Depth","Participant.ID")] %>%
na.omit(.)
#rename Reply column to Utterance
names(df)[names(df) == "Reply"] <- "Utterance"
# we remove the exclude sentences from the set
df <- df[which(df$Exclude==0),]
# then we can also remove the exclude column
df$Exclude <- NULL
# we also want a column that says whether the thought
# record was scenario-based (closed) or a personal one (open)
df$TRtype <- ifelse(df$Scenario=="PTR","open","closed")
df$TRtype <- as.factor(df$TRtype)
#we recode from the ordinal scale into two binominal ones.
#we do this to look at the distributions and to
#split the set into training, validation, and test set later
dfbin <- df
dfbin[,2:10] <- ifelse(dfbin[,2:10] == 2 | dfbin[,2:10]== 3, 1, 0)
dfbin2 <- df
dfbin2[,2:10] <- ifelse(dfbin2[,2:10] > 0, 1, 0)
df <- read.csv("Data/CoreData.csv",na.strings = "", header=TRUE, sep=";",fill=TRUE)
schemas <- c("Attach","Comp","Global","Health","Control","MetaCog","Others","Hopeless","OthViews")
#select only relevant columns and rows
df <- df[which(df$UttEnum!="NA"),c("Reply",schemas,"Exclude","UttEnum","Scenario","Depth","Participant.ID")] %>%
na.omit(.)
View(df)
#rename Reply column to Utterance
names(df)[names(df) == "Reply"] <- "Utterance"
df[,2:10] <- as.numeric(as.character(df[,2:11]))
#rename Reply column to Utterance
names(df)[names(df) == "Reply"] <- "Utterance"
df[,2:11] <- as.numeric(as.character(df[,2:11]))
df[,2:11] <- lapply(df[,2:11], function(x) as.numeric(as.character(x)))
# we remove the exclude sentences from the set
df <- df[which(df$Exclude==0),]
# then we can also remove the exclude column
df$Exclude <- NULL
# we also want a column that says whether the thought
# record was scenario-based (closed) or a personal one (open)
df$TRtype <- ifelse(df$Scenario=="PTR","open","closed")
df$TRtype <- as.factor(df$TRtype)
#we recode from the ordinal scale into two binominal ones.
#we do this to look at the distributions and to
#split the set into training, validation, and test set later
dfbin <- df
dfbin[,2:10] <- ifelse(dfbin[,2:10] == 2 | dfbin[,2:10]== 3, 1, 0)
dfbin2 <- df
dfbin2[,2:10] <- ifelse(dfbin2[,2:10] > 0, 1, 0)
df <- read.csv("Data/CoreData.csv",na.strings = "", header=TRUE, sep=";",fill=TRUE)
schemas <- c("Attach","Comp","Global","Health","Control","MetaCog","Others","Hopeless","OthViews")
#select only relevant columns and rows
df <- df[which(df$UttEnum!="NA"),c("Reply",schemas,"Exclude","UttEnum","Scenario","Depth","Participant.ID")] %>%
na.omit(.)
#rename Reply column to Utterance
names(df)[names(df) == "Reply"] <- "Utterance"
df[,2:11] <- lapply(df[,2:11], function(x) as.numeric(as.character(x)))
# we remove the exclude sentences from the set
df <- df[which(df$Exclude==0),]
# then we can also remove the exclude column
df$Exclude <- NULL
# we also want a column that says whether the thought
# record was scenario-based (closed) or a personal one (open)
df$TRtype <- ifelse(df$Scenario=="PTR","open","closed")
df$TRtype <- as.factor(df$TRtype)
#we recode from the ordinal scale into two binominal ones.
#we do this to look at the distributions and to
#split the set into training, validation, and test set later
dfbin <- df
dfbin[,2:10] <- ifelse(dfbin[,2:10] == 2 | dfbin[,2:10]== 3, 1, 0)
dfbin2 <- df
dfbin2[,2:10] <- ifelse(dfbin2[,2:10] > 0, 1, 0)
#read in the testset to have manually assigned labels
df.H2GT <- read.csv("Data/DatasetsForH1/H1_test_labels.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
#read in the predictions generated by the per-schema RNNs trained in Python
df.H2Preds <- read.csv("Data/PredictionsH2.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
df.H2Preds$UttEnum <- df.H2GT$UttEnum
#compute the row-wise correlations between the two dataframes
#df.H2GT$Corr <- diag(cor(t(df.H2GT[,1:9]), t(df.H2Preds), method="spearman"))
df.H2 <- merge(df.H2Preds[,c("UttEnum","Corr")],df[,c("UttEnum","Scenario","Depth","Participant.ID")],by="UttEnum")
#taking the predictor into account
#random slope at level 3
df.H2$Depth <- as.numeric(as.character(df.H2$Depth))
Model.1<-lmer(Corr ~ Depth
+(1|Participant.ID)
+(1|Participant.ID:Scenario),
data=df.H2, REML=FALSE)
summary(Model.1)
confint(Model.1,method="boot")
#read in the testset to have manually assigned labels
df.H2GT <- read.csv("Data/DatasetsForH1/H1_test_labels.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
#read in the predictions generated by the per-schema RNNs trained in Python
df.H2Preds <- read.csv("Data/PredictionsH2.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
df.H2Preds$UttEnum <- df.H2GT$UttEnum
#compute the row-wise correlations between the two dataframes
#df.H2GT$Corr <- diag(cor(t(df.H2GT[,1:9]), t(df.H2Preds), method="spearman"))
df.H2 <- merge(df.H2Preds[,c("UttEnum","Corr")],df[,c("UttEnum","Scenario","Depth","Participant.ID")],by="UttEnum")
df.H2$Depth <- as.numeric(as.character(df.H2$Depth))
Model.1<-lmer(Corr ~ Depth
+(1|Participant.ID)
+(1|Participant.ID:Scenario),
data=df.H2, REML=FALSE)
summary(Model.1)
confint(Model.1,method="boot")
#read in the testset to have manually assigned labels
df.H2GT <- read.csv("Data/DatasetsForH1/H1_test_labels.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
#read in the predictions generated by the per-schema RNNs trained in Python
df.H2Preds <- read.csv("Data/PredictionsH2.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
df.H2Preds$UttEnum <- df.H2GT$UttEnum
#compute the row-wise correlations between the two dataframes
#df.H2GT$Corr <- diag(cor(t(df.H2GT[,1:9]), t(df.H2Preds), method="spearman"))
df.H2 <- merge(df.H2Preds[,c("UttEnum","Corr")],df[,c("UttEnum","Scenario","Depth","Participant.ID")],by="UttEnum")
df.H2$Depth <- as.numeric(as.character(df.H2$Depth))
Model.1<-lmer(Corr ~ Depth
+(1|Participant.ID)
+(1|Participant.ID:Scenario),
data=df.H2, REML=FALSE)
summary(Model.1)
#read in the testset to have manually assigned labels
df.H2GT <- read.csv("Data/DatasetsForH1/H1_test_labels.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
#read in the predictions generated by the per-schema RNNs trained in Python
df.H2Preds <- read.csv("Data/PredictionsH2.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
df.H2Preds$UttEnum <- df.H2GT$UttEnum
#compute the row-wise correlations between the two dataframes
#df.H2GT$Corr <- diag(cor(t(df.H2GT[,1:9]), t(df.H2Preds), method="spearman"))
df.H2 <- merge(df.H2Preds[,c("UttEnum","Corr")],df[,c("UttEnum","Scenario","Depth","Participant.ID")],by="UttEnum")
df.H2$Depth <- as.numeric(as.character(df.H2$Depth))
Model.1<-lmer(Corr ~ Depth
+(1|Participant.ID)
+(1|Participant.ID:Scenario),
data=df.H2, REML=FALSE)
summary(Model.1)
#read in the testset to have manually assigned labels
df.H2GT <- read.csv("Data/DatasetsForH1/H1_test_labels.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
#read in the predictions generated by the per-schema RNNs trained in Python
df.H2Preds <- read.csv("Data/PredictionsH2.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
df.H2Preds$UttEnum <- df.H2GT$UttEnum
#compute the row-wise correlations between the two dataframes
#df.H2GT$Corr <- diag(cor(t(df.H2GT[,1:9]), t(df.H2Preds), method="spearman"))
df.H2 <- merge(df.H2Preds[,c("UttEnum","Corr")],df[,c("UttEnum","Scenario","Depth","Participant.ID")],by="UttEnum")
df.H2$Depth <- as.numeric(as.character(df.H2$Depth))
Model.1<-lmer(Corr ~ Depth
+(1|Participant.ID)
+(1|Participant.ID:Scenario),
data=df.H2, REML=FALSE)
summary(Model.1)
#read in the testset to have manually assigned labels
df.H2GT <- read.csv("Data/DatasetsForH1/H1_test_labels.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
#read in the predictions generated by the per-schema RNNs trained in Python
df.H2Preds <- read.csv("Data/PredictionsH2.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
df.H2Preds$UttEnum <- df.H2GT$UttEnum
#compute the row-wise correlations between the two dataframes
#df.H2GT$Corr <- diag(cor(t(df.H2GT[,1:9]), t(df.H2Preds), method="spearman"))
df.H2 <- merge(df.H2Preds[,c("UttEnum","Corr")],df[,c("UttEnum","Scenario","Depth","Participant.ID")],by="UttEnum")
##Only level-1 mean but nesting structure
#baseline
Model.0<-lmer(Corr ~ 1
+(1|Participant.ID)
+(1|Participant.ID:Scenario),
data=df.H2, REML=FALSE)
summary(Model.0)
confint(Model.0,method="boot")
#taking the predictor into account
#random slope at level 3
df.H2$Depth <- as.numeric(as.character(df.H2$Depth))
Model.1<-lmer(Corr ~ Depth
+(1|Participant.ID)
+(1|Participant.ID:Scenario),
data=df.H2, REML=FALSE)
summary(Model.1)
confint(Model.1,method="boot")
anova(Model.0,Model.1)
schemas <- c("Attach","Comp","Global","Health","Control",
"MetaCog","Others","Hopeless","OthViews")
df.PTRlabeled <- read.csv("Data/IRR/c1c6/labeling_PTR_scen_c1_labeled.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
df.PTRlabeled$scen <- "PTR"
#append scentype to current dataframe
#interpersonal
df$scentype[df$scen %in% c('Waving','Lover','FA','CW','Party')] <- 1
#achievement-related
df$scentype[df$scen %in% c('Essay','CB','JA','Fired','Dieting')] <- 2
#fill missing scentypes with newly loaded data
df.dataH3 <- merge(df,
df.PTRlabeled[,c("Participant.ID",
"scentype",
"scen")],
by=c("Participant.ID","scen"),
all.x=TRUE)
schemas <- c("Attach","Comp","Global","Health","Control",
"MetaCog","Others","Hopeless","OthViews")
df.PTRlabeled <- read.csv("Data/IRR/c1c6/labeling_PTR_scen_c1_labeled.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
df.PTRlabeled$Scenario <- "PTR"
#append scentype to current dataframe
#interpersonal
df$scentype[df$Scenario %in% c('Waving','Lover','FA','CW','Party')] <- 1
#achievement-related
df$scentype[df$Scenario %in% c('Essay','CB','JA','Fired','Dieting')] <- 2
#fill missing scentypes with newly loaded data
df.dataH3 <- merge(df,
df.PTRlabeled[,c("Participant.ID",
"scentype",
"Scenario")],
by=c("Participant.ID","Scenario"),
all.x=TRUE)
df.dataH3$scentype <- ifelse(is.na(df.dataH3$scentype.x),
df.dataH3$scentype.y,
df.dataH3$scentype.x)
df.dataH3$scentype.x <- NULL
df.dataH3$scentype.y <- NULL
df.mentalh <- read.csv("Data/MentalHealth.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
df.mentalh <- df.mentalh[56:61]
View(df.mentalh)
df.H4 <- df %>%
dplyr::group_by(Participant.ID,Scenario) %>%
dplyr::summarise_at(schemas,max) %>%
dplyr::mutate_at(schemas,
function(x) ifelse(x > 2, 1,0)) %>%
dplyr::group_by(Participant.ID) %>%
dplyr::summarise_at(schemas,sum)
df.H4 <- df.H4[,c('Participant.ID',schemas)]
df.H4 <- merge(df.mentalh,df.H4,by="Participant.ID",all.y=TRUE)
View(df.H4)
#compare frequency of schemas in open and closed thought records
#recode to binary
df.dataH3bin <- df.dataH3
View(df.dataH3bin)
df.dataH3bin <- df.dataH3
df.dataH3bin[,4:12] <- ifelse(df.dataH3[,4:12] > 0, 1, 0)
df.H3long <- df.dataH3bin[,c(1,2,seq(4,12,1),17)] %>%
gather(cb,label,3:11)
df.schematrtype <- df.H3long %>%
dplyr::group_by(TRtype,cb) %>%
dplyr::summarise(count=sum(label),perc=count/n())
View(df.dataH3bin)
df.dataH3bin <- df.dataH3
df.dataH3bin[,4:12] <- ifelse(df.dataH3[,4:12] > 0, 1, 0)
df.H3long <- df.dataH3bin[,c(1,2,seq(4,12,1),16)] %>%
gather(cb,label,3:11)
df.schematrtype <- df.H3long %>%
dplyr::group_by(TRtype,cb) %>%
dplyr::summarise(count=sum(label),perc=count/n())
df.dataH3bin <- df.dataH3
df.dataH3bin[,4:12] <- ifelse(df.dataH3[,4:12] > 0, 1, 0)
df.H3long <- df.dataH3bin[,c(1,2,seq(4,12,1),15)] %>%
gather(cb,label,3:11)
df.schematrtype <- df.H3long %>%
dplyr::group_by(TRtype,cb) %>%
dplyr::summarise(count=sum(label),perc=count/n())
schemas <- c("Attach","Comp","Global","Health","Control",
"MetaCog","Others","Hopeless","OthViews")
df.PTRlabeled <- read.csv("Data/IRR/c1c6/labeling_PTR_scen_c1_labeled.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
df.PTRlabeled$Scenario <- "PTR"
#append scentype to current dataframe
#interpersonal
df$scentype[df$Scenario %in% c('Waving','Lover','FA','CW','Party')] <- 1
#achievement-related
df$scentype[df$Scenario %in% c('Essay','CB','JA','Fired','Dieting')] <- 2
#fill missing scentypes with newly loaded data
df.dataH3 <- merge(df,
df.PTRlabeled[,c("Participant.ID",
"scentype",
"Scenario")],
by=c("Participant.ID","Scenario"),
all.x=TRUE)
df.dataH3$scentype <- ifelse(is.na(df.dataH3$scentype.x),
df.dataH3$scentype.y,
df.dataH3$scentype.x)
df.dataH3$scentype.x <- NULL
df.dataH3$scentype.y <- NULL
View(df.dataH3)
#get max value per schema for the open thought record
df.openTR <- df.dataH3[df.dataH3$Scenario == 'PTR',
c('Participant.ID',schemas,"scentype")] %>%
dplyr::group_by_('Participant.ID') %>%
summarise_all(funs(max))
View(df.openTR)
df.openTR <- df.dataH3[df.dataH3$Scenario == 'PTR',
c('Participant.ID',schemas,"scentype")] %>%
dplyr::group_by_('Participant.ID') %>%
summarise_all(funs(max))
View(df.openTR)
#get the closed TRs that match with the open TR in scentype
df.closedTR <- merge(df.openTR[,c("Participant.ID","scentype")],
df.dataH3,
by=c("Participant.ID","scentype"))
#remove the PTRs
df.closedTR <- df.closedTR[!df.closedTR$Scenario=="PTR",]
View(df.closedTR)
#get max value per schema and thought record for the
#closed thought records
df.closedTRagg <- df.closedTR[,c('Participant.ID',schemas,"Scenario")] %>%
dplyr::group_by_('Participant.ID','Scenario') %>%
summarise_all(funs(max))
#get average value per schema for both closed thought records
df.closedTRagg <- df.closedTRagg %>%
dplyr::group_by_('Participant.ID') %>%
summarise_all(funs(mean))
df.closedTRagg$Scenario <- NULL
#merge the two dataframes
df.H3lms <- merge(df.closedTRagg,df.openTR,by="Participant.ID")
View(df.H3lms)
lmAttach <- lm(Attach.y ~ Attach.x, data = df.H3lms)
summary(lmAttach)
confint(lmAttach)
lmComp <- lm(Comp.y ~ Comp.x, data = df.H3lms)
summary(lmComp)
confint(lmComp)
df.dataH3bin <- df.dataH3
df.dataH3bin[,4:12] <- ifelse(df.dataH3[,4:12] > 0, 1, 0)
df.H3long <- df.dataH3bin[,c(1,2,seq(4,12,1),15)] %>%
gather(cb,label,3:11)
df.schematrtype <- df.H3long %>%
dplyr::group_by(TRtype,cb) %>%
dplyr::summarise(count=sum(label),perc=count/n())
schemas <- c("Attach","Comp","Global","Health","Control",
"MetaCog","Others","Hopeless","OthViews")
df.PTRlabeled <- read.csv("Data/IRR/c1c6/labeling_PTR_scen_c1_labeled.csv",
na.strings = "",
header=TRUE,
sep=";",
fill=TRUE)
df.PTRlabeled$Scenario <- "PTR"
#append scentype to current dataframe
#interpersonal
df$scentype[df$Scenario %in% c('Waving','Lover','FA','CW','Party')] <- 0
#achievement-related
df$scentype[df$Scenario %in% c('Essay','CB','JA','Fired','Dieting')] <- 1
#fill missing scentypes with newly loaded data
df.dataH3 <- merge(df,
df.PTRlabeled[,c("Participant.ID",
"scentype",
"Scenario")],
by=c("Participant.ID","Scenario"),
all.x=TRUE)
df.dataH3$scentype <- ifelse(is.na(df.dataH3$scentype.x),
df.dataH3$scentype.y,
df.dataH3$scentype.x)
df.dataH3$scentype.x <- NULL
df.dataH3$scentype.y <- NULL
df.openTR <- df.dataH3[df.dataH3$Scenario == 'PTR',
c('Participant.ID',schemas,"scentype")] %>%
dplyr::group_by_('Participant.ID') %>%
summarise_all(funs(max))
#get the closed TRs that match with the open TR in scentype
df.closedTR <- merge(df.openTR[,c("Participant.ID","scentype")],
df.dataH3,
by=c("Participant.ID","scentype"))
#remove the PTRs
df.closedTR <- df.closedTR[!df.closedTR$Scenario=="PTR",]
# ####alternative test with all closed thought records,
# ####meaning we do not split according to scentype
# df.closedTR <- df.dataH3[!df.dataH3$Scenario=="PTR",]
#get max value per schema and thought record for the
#closed thought records
df.closedTRagg <- df.closedTR[,c('Participant.ID',schemas,"Scenario")] %>%
dplyr::group_by_('Participant.ID','Scenario') %>%
summarise_all(funs(max))
#get average value per schema for both closed thought records
df.closedTRagg <- df.closedTRagg %>%
dplyr::group_by_('Participant.ID') %>%
summarise_all(funs(mean))
df.closedTRagg$Scenario <- NULL
#merge the two dataframes
df.H3lms <- merge(df.closedTRagg,df.openTR,by="Participant.ID")
lmAttach <- lm(Attach.y ~ Attach.x, data = df.H3lms)
summary(lmAttach)
confint(lmAttach)
